---
title: TensorFlow2笔记-LeNet(经典卷积网络)
categories: 
    - 深度学习
    - TensorFlow2
tags: 
    - TensorFlow2
    - CNN
---

### 介绍

这里主要介绍卷积神经网络的经典网络，然后通过tensorflow进行实现（以上章的卷积神经网络实现代码为基础，进行实现）。

统计卷积网络神经网络层数一般只统计卷积计算层和全连接计算层。

>ImageNet

ImageNet 是一个计算机视觉系统识别项目,是目前世界上图像识别最大的数据库。是美国斯坦福的计算机科学家，模拟人类的识别系统建立的。能够从图片识别物体。ImageNet是一个非常有前景的研究项目，未来用在机器人身上，就可以直接辨认物品和人了。

### 经典卷积网络

```mermaid
   graph LR
    A(LeNet 1998) --> B(AlexNet 2012)
    B --> C(VGGNet 2014) 
    C --> D(Inception Net 2014) 
    D --> E(ResNet 2015)
```

#### LeNet

由Yann LeCun于1998年提出，卷积网络开篇之作。通过共享卷积核减少了网络的参数。LeNet如下所示(C5画错了是F5)

![aaa](/images/LeNet.PNG)

LeNet提出的时候还没提出BN和Dropout层，所以LeNet网络不具有BN和Dropout层。

根据上图实现LeNet代码如下：

```Python
class MyLeNet(Model):
    def __init__(self):
        super(MyLeNet, self).__init__()
        self.c1 = Conv2D(filters=6,kernel_size=(5,5),activation='sigmoid')
        self.p1 = MaxPool2D(pool_size=(2,2),strides=2)

        self.c2 = Conv2D(filters=16,kernel_size=(5,5),activation='sigmoid')
        self.p2 = MaxPool2D(pool_size=(2,2),strides=2)

        self.flatten = Flatten()
        self.f1 = Dense(120,activation='sigmoid')
        self.f2 = Dense(84,activation='sigmoid')
        self.f3 = Dense(10,activation='softmax')
    def call(self,x):
        x = self.c1(x)
        x = self.p1(x)
        x = self.c2(x)
        x = self.p2(x)

        # 提取的特征作为神经网络的输入特征
        x = self.flatten(x)
        x = self.f1(x)
        x = self.f2(x)
        y = self.f3(x)
        return y
```

#### AlexNet

AlexNet网络诞生于2012年，是Hinton代表作之一。使用relu激活函数，提升训练速度，使用Dropout缓解过拟合。
![a2](/images/AlexNet.PNG)
AlexNet实现代码如下：

```python
class AlexNet(Model):
    def __init__(self):
        super(AlexNet, self).__init__()
        # 第一层
        self.c1 = Conv2D(filters=96,kernel_size=(3,3))
        self.b1 = BatchNormalization()
        self.a1 = Activation('relu')
        self.p1 = MaxPool2D(pool_size=(3,3),strides=2)

        #第二层
        self.c2 = Conv2D(filters=256,kernel_size=(3,3))
        self.b2 = BatchNormalization()
        self.a2 = Activation('relu')
        self.p2 = MaxPool2D(pool_size=(3,3),strides=2)

        #第三层
        self.c3 = Conv2D(filters=384,kernel_size=(3,3),padding='same',activation='relu')

        #第四层
        self.c4 = Conv2D(filters=384,kernel_size=(3,3),padding='same',activation='relu')

        #第五层
        self.c5 = Conv2D(filters=256,kernel_size=(3,3),padding='same',activation='relu')
        self.p3 = MaxPool2D(pool_size=(3,3),strides=2)

        #神经网络计算层
        self.flatten = Flatten()
        self.f1 = Dense(2048,activation='relu')
        self.d1 = Dropout(0.5)
        self.f2 = Dense(84,activation='relu')
        self.d1 = Dropout(0.5)
        self.f3 = Dense(10,activation='softmax')

    def call(self,x):
        x = self.c1(x)
        x = self.b1(x)
        x = self.a1(x)
        x = self.p1(x)

        x = self.c2(x)
        x = self.b2(x)
        x = self.a2(x)
        x = self.p2(x)

        x = self.c3(x)

        x = self.c4(x)

        x = self.c5(x)
        x = self.p3(x)

        # 提取的特征作为神经网络的输入特征
        x = self.flatten(x)
        x = self.f1(x)
        x = self.d1(x)
        x = self.f2(x)
        x = self.d2(x)
        y = self.f3(x)
        return y
```
#### VGGNet

CGGNet诞生于2014年，当年ImageNet竞赛的亚军。使用小尺寸卷积核，在减少的参数的同时，提高了识别准确率。VGGNet网络结构框图如下所示。
![a3](/images/VGGnet.PNG)

VGGNet的网络结构是：两次CBA，CBAPD，三次CBA , CBA,CBAPD。
实现代码如下所示：
```python
class VGGNet(Model):
    def __init__(self):
        super(VGGNet, self).__init__()
        # 首先重复两次CBA CBAPD
        #1
        self.c1 = Conv2D(filters=64,kernel_size=(3,3),padding='same')
        self.b1 = BatchNormalization()
        self.a1 = Activation('relu')

        self.c2 = Conv2D(filters=64, kernel_size=(3, 3), padding='same')
        self.b2 = BatchNormalization()
        self.a2 = Activation('relu')
        self.p1 = MaxPool2D(pool_size=(2,2),strides=2,padding='same')
        self.d1 = Dropout(0.2)
        #2
        self.c3 = Conv2D(filters=128, kernel_size=(3, 3), padding='same')
        self.b3 = BatchNormalization()
        self.a3 = Activation('relu')

        self.c4 = Conv2D(filters=128, kernel_size=(3, 3), padding='same')
        self.b4 = BatchNormalization()
        self.a4 = Activation('relu')
        self.p2 = MaxPool2D(pool_size=(2, 2), strides=2, padding='same')
        self.d2 = Dropout(0.2)

        # 再重复三次 CBA CBA CBAPD
        # 1
        self.c5 = Conv2D(filters=256, kernel_size=(3, 3), padding='same')
        self.b5 = BatchNormalization()
        self.a5 = Activation('relu')

        self.c6 = Conv2D(filters=256, kernel_size=(3, 3), padding='same')
        self.b6 = BatchNormalization()
        self.a6 = Activation('relu')

        self.c7 = Conv2D(filters=256, kernel_size=(3, 3), padding='same')
        self.b7 = BatchNormalization()
        self.a7 = Activation('relu')
        self.p3 = MaxPool2D(pool_size=(2, 2), strides=2, padding='same')
        self.d3 = Dropout(0.2)
        # 2
        self.c8 = Conv2D(filters=512, kernel_size=(3, 3), padding='same')
        self.b8 = BatchNormalization()
        self.a8 = Activation('relu')

        self.c9 = Conv2D(filters=512, kernel_size=(3, 3), padding='same')
        self.b9 = BatchNormalization()
        self.a9 = Activation('relu')

        self.c10 = Conv2D(filters=512, kernel_size=(3, 3), padding='same')
        self.b10 = BatchNormalization()
        self.a10 = Activation('relu')
        self.p4 = MaxPool2D(pool_size=(2, 2), strides=2, padding='same')
        self.d4 = Dropout(0.2)

        # 3
        self.c11 = Conv2D(filters=512, kernel_size=(3, 3), padding='same')
        self.b11 = BatchNormalization()
        self.a11 = Activation('relu')

        self.c12 = Conv2D(filters=512, kernel_size=(3, 3), padding='same')
        self.b12 = BatchNormalization()
        self.a12 = Activation('relu')

        self.c13 = Conv2D(filters=512, kernel_size=(3, 3), padding='same')
        self.b13 = BatchNormalization()
        self.a13 = Activation('relu')
        self.p5 = MaxPool2D(pool_size=(2, 2), strides=2, padding='same')
        self.d5 = Dropout(0.2)

        # 三个全连接层
        self.flatten = Flatten()
        self.f1 = Dense(512,activation='relu')
        self.d6 = Dropout(0.2)
        self.f2 = Dense(512,activation='relu')
        self.d6 = Dropout(0.2)
        self.f3 = Dense(10,activation='softmax')
    def call(self,x):
        # 两次CBA CBAPD
        #1
        x = self.c1(x)
        x = self.b1(x)
        x = self.a1(x)

        x = self.c2(x)
        x = self.b2(x)
        x = self.a2(x)
        x = self.p1(x)
        x = self.d1(x)

        #2
        x = self.c3(x)
        x = self.b3(x)
        x = self.a3(x)

        x = self.c4(x)
        x = self.b4(x)
        x = self.a4(x)
        x = self.p2(x)
        x = self.d2(x)

        #三次 CBA CBA CBAPD

        # 1
        x = self.c5(x)
        x = self.b5(x)
        x = self.a5(x)

        x = self.c6(x)
        x = self.b6(x)
        x = self.a6(x)

        x = self.c7(x)
        x = self.b7(x)
        x = self.a7(x)
        x = self.p3(x)
        x = self.d3(x)

        # 2
        x = self.c8(x)
        x = self.b8(x)
        x = self.a8(x)

        x = self.c9(x)
        x = self.b9(x)
        x = self.a9(x)

        x = self.c10(x)
        x = self.b10(x)
        x = self.a10(x)
        x = self.p4(x)
        x = self.d4(x)

        # 3

        x = self.c11(x)
        x = self.b11(x)
        x = self.a11(x)

        x = self.c12(x)
        x = self.b12(x)
        x = self.a12(x)

        x = self.c13(x)
        x = self.b13(x)
        x = self.a13(x)
        x = self.p5(x)
        x = self.d5(x)

        # 提取的特征作为神经网络的输入特征
        x = self.flatten(x)
        x = self.f1(x)
        x = self.d5(x)
        x = self.f2(x)
        x = self.d6(x)
        y = self.f3(x)
        return y
```

#### Inception Net

InceptionNet诞生于2014年。当年ImageNet冠军。Inception引入了Inception结构快。
同一层网络使用不同尺寸的卷积核，提升了模型感知力，使用了批标准化，缓解了梯度消失。

>Inception结构快如图所示

![a14](/images/inter.PNG)

从图中可以看出，Inception包含四个卷积过程，分成四个不同的卷积核进行卷积操作。
>1. 1×1的卷积核
>2. 1×1的卷积核+3×3的卷积核
>3. 1×1的卷积核+5×5的卷积核
>4. 3×3的最大池+1×1的卷积核
>5. 最后将四个部分的输出结果，按照深度方向堆叠在一起，作为一个Inception结构快输出。

#### ResNet

ResNet（何凯明）于2015年提出，是当时的ImageNet竞赛冠军。ResNet提出了层间残差跳连，引入了前方信息，缓解梯度消失，使神经网络层数增加称为可能。

>单纯堆叠神经网络层数，会使神经网络模型退化，以致于后面的特征丢失了前边特征的原本模样。

ResNet块的结构如下所示：
![ar](/images/ResNet块.PNG)

ResNet的输出值包括两部分组成，一部分是由卷积过程提取出的特征输出F(x)，另一部分是直接由输入X得到的恒等映射X组成。将F(x)和x的对应元素相加得到输出特征H(x)。这样可以缓解神经网络堆叠导致的退化。使得神经网络层数增加称为可能。

对于X到跳过卷积层直接到输出特征有两种处理方式。

![ar1](/images/两种ResNet块.PNG)

>1. 不做任何处理
H(x) = F(x) + x
由于不做任何处理，所以维度没有改变。
>2. 通过函数W(x)进行处理，其中W是1×1的卷积操作，用于调整X的维度。
H(x) = F(x) + W(x)
其中通过卷积步长可以改变输出特征图尺寸，通过卷积核的个数可以改变特征图的深度（类似Inception结构，多个卷积核，该变深度）。

ResNet网络结构如下所示：

![ar1](/images/ResNet.PNG)

实现代码：
```Python
class ResentBlock(Model):
    def __init__(self,filters,strides=1,residual_path=False):
        super(ResentBlock, self).__init__()
        self.filters = filters
        self.strides = strides
        self.residual_path = residual_path

        self.c1 = Conv2D(filters,(3,3),strides=strides,padding='same',use_bias=False)
        self.b1 = BatchNormalization()
        self.a1 = Activation('relu')

        self.c2 = Conv2D(filters,(3,3),strides=1,padding='same',use_bias=False)
        self.b2 = BatchNormalization()

        #fesiders_path 为True时候，对输入进行采样，都用1×1的卷积核做卷积操作，保证x能和F(x)维度相同，顺利相加
        if residual_path:
            self.down_c1 = Conv2D(filters,(1,1),strides=strides,padding='same',use_bias=False)
            self.down_b1 = BatchNormalization()
        self.a2 = Activation('relu')

    def call(self,inputs):
        residual = inputs # residual等于输入本身

        #将输入通过卷积层，BN层，激活层计算F(x)
        x = self.c1(inputs)
        x = self.b1(x)
        x = self.a1(x)

        x = self.c2(x)
        y = self.b2(x)

        if self.residual_path:
            residual = self.down_c1(inputs)
            residual = self.down_b1(residual)

        # 最后输出是两部分的和，即F(x)+x或F(x)+W(x),然后再过激活函数。
        out = self.a2(y + residual)

        return out

# 由一层卷积网络+八个ResNet块组成
# 神经网络由一个全连接层构成
class ResNet(Model):
    # block_list表示每个block有几个卷积层
    def __init__(self,block_list,initial_filters=64):
        super(ResNet, self).__init__()
        self.num_blocks = len(block_list)
        self.block_list = block_list
        self.out_filters = initial_filters
        # 对应图中第一个卷几层
        self.c1 = Conv2D(self.out_filters,(3,3),strides=1,padding='same',use_bias=False,kernel_initializer='he_normal')
        self.b1 = BatchNormalization()
        self.a1 = Activation('relu')
        self.blocks = tf.keras.models.Sequential()

        # 对应图中的八个ResNet块
        #构建ResNet网络结构 4*2 = 8
        for block_id in range(len(block_list)):#第几个resnet block
            for layer_id in range(block_list[block_id]):# 第几个卷层

                if block_id != 0 and layer_id == 0 : #对除第一个block以外的每个Block的输入进行采样
                    block = ResentBlock(self.out_filters,strides=2,residual_path=True)
                else:
                    block = ResentBlock(self.out_filters,residual_path=False)

                self.blocks.add(block)  # 将构建好的blcok加入到renset
            self.out_filters *=2  #下一个block卷积核数是上一个block的两倍

        # 平均池
        self.p1 = tf.keras.layers.GlobalAveragePooling2D()
        # 全连接层
        self.f1 = tf.keras.layers.Dense(10)

    def call(self,inputs):
        x = self.c1(inputs)
        x = self.b1(x)
        x = self.a1(x)
        x = self.blocks(x)
        x = self.p1(x)
        y = self.f1(x)
        return y

model = ResNet([2,2,2,2])
```

# 总结

1. LeNet
   通过共享卷积核，减少网络参数
2. AlexNet
    通过使用relu激活函数，提升训练速度。
    使用Dropout缓解过拟合。
3. VGGNet
    小尺寸卷积核减少参数，网络结构规整，适合并行加速。
4. InceptionNet
    一层内使用不同尺寸卷积核，提升感知力。使用批标准化，缓解梯度消失。
5. ResNet
    层间残差跳连，引入前方信息，缓解模型退化，使神经网络层数加深成为可能。

>训练优化

&nbsp;&nbsp;&nbsp;&nbsp;一些训练方法和超参数的设定对模型训练结果的影响是相当显著的，如数据增强（对训练集图像进行旋转、偏移、翻转等多种操作，目的是增强训练集的随机性）、学习率策略（一般的策略是在训练过程中逐步减小学习率）、Batch size 的大小设置（每个 batch 包含训练集图片的数量）、模型参数初始化的方式等等。。所以，在神经网络的训练中，除了选择合适的模型以外，如何更好地训练一个模型也是一个非常值得探究的问题。

