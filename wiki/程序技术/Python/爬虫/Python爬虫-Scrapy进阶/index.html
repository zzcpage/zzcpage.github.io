<!DOCTYPE html>
<html lang=en>
<head>
    <meta charset="utf-8">
    
    <title>Python爬虫-Scrapy进阶 | 个人博客</title>
    
    
        <meta name="keywords" content="Python,爬虫" />
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="1.Spider模块2.Item Loader深入Scrapy爬虫框架 1.Spider模块 Spider模块是定义爬虫的动作及分析网页结构的地方，我们容易看出，在这里给出了解析网页获取元素，并进行是否继续爬取下一个网页的操作(也就是爬虫的动作)。Spider的执行流程   从入口URL初始化Request并设置回调函数。这个Reuquest下载完毕返回Response，并作为参数传送给回调函数，">
<meta property="og:type" content="article">
<meta property="og:title" content="Python爬虫-Scrapy进阶">
<meta property="og:url" content="http://example.com/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E7%88%AC%E8%99%AB/Python%E7%88%AC%E8%99%AB-Scrapy%E8%BF%9B%E9%98%B6/index.html">
<meta property="og:site_name" content="个人博客">
<meta property="og:description" content="1.Spider模块2.Item Loader深入Scrapy爬虫框架 1.Spider模块 Spider模块是定义爬虫的动作及分析网页结构的地方，我们容易看出，在这里给出了解析网页获取元素，并进行是否继续爬取下一个网页的操作(也就是爬虫的动作)。Spider的执行流程   从入口URL初始化Request并设置回调函数。这个Reuquest下载完毕返回Response，并作为参数传送给回调函数，">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2021-12-09T09:00:55.657Z">
<meta property="article:modified_time" content="2021-12-10T06:39:40.879Z">
<meta property="article:author" content="ZZC">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="爬虫">
<meta name="twitter:card" content="summary">
    

    
        <link rel="alternate" href="/atom.xml" title="个人博客" type="application/atom+xml" />
    

    
        <link rel="icon" href="/favicon.ico" />
    

    
<link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">

    
<link rel="stylesheet" href="/libs/open-sans/styles.css">

    
<link rel="stylesheet" href="/libs/source-code-pro/styles.css">


    
<link rel="stylesheet" href="/css/style.css">

    
<script src="/libs/jquery/2.1.3/jquery.min.js"></script>

    
<script src="/libs/jquery/plugins/cookie/1.4.1/jquery.cookie.js"></script>

    
    
        
<link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">

    
    
        
<link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">

    
    
    
    


    
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
    <div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">个人博客</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/">首页</a>
                
                    <a class="main-nav-link" href="/archives">归档</a>
                
                    <a class="main-nav-link" href="/categories">分类</a>
                
                    <a class="main-nav-link" href="/tags">标签</a>
                
                    <a class="main-nav-link" href="/about">关于</a>
                
            </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>


</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/">首页</a></td>
                
                    <td><a class="main-nav-link" href="/archives">归档</a></td>
                
                    <td><a class="main-nav-link" href="/categories">分类</a></td>
                
                    <td><a class="main-nav-link" href="/tags">标签</a></td>
                
                    <td><a class="main-nav-link" href="/about">关于</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
            
                <aside id="sidebar">
   
        
    <div class="widget-wrap" id='categories'>
        <h3 class="widget-title">
            <span>categories</span>
            &nbsp;
            <a id='allExpand' href="#">
                <i class="fa fa-angle-double-down fa-2x"></i>
            </a>
        </h3>
        
        
        
         <ul class="unstyled" id="tree" > 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            JavaEE
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Java/JavaWeb/%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA/">JavaWeb后端数据导出</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            JavaSE
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Java/JavaSE/%E7%AC%AC%E4%B8%89%E7%AB%A0-Java%E5%9F%BA%E6%9C%AC%E7%A8%8B%E5%BA%8F%E7%BB%93%E6%9E%84/java%20introduce/">1. Java介绍</a></li>  <li class="file"><a href="/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Java/JavaSE/%E7%AC%AC%E4%B8%89%E7%AB%A0-Java%E5%9F%BA%E6%9C%AC%E7%A8%8B%E5%BA%8F%E7%BB%93%E6%9E%84/java%20basic%20statment/">2. Java基本语法</a></li>  <li class="file"><a href="/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Java/JavaSE/%E7%AC%AC%E4%B8%89%E7%AB%A0-Java%E5%9F%BA%E6%9C%AC%E7%A8%8B%E5%BA%8F%E7%BB%93%E6%9E%84/java%20controll%20followe/">3. Java控制流程</a></li>  <li class="file"><a href="/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Java/JavaSE/%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%AF%B9%E8%B1%A1%E4%B8%8E%E7%B1%BB/class/">4. Java对象与类</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            JavaWeb
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Java/JavaWeb/%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2/">Web项目部署</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            Python
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/">Python常见问题</a></li>  <li class="file"><a href="/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/CV2/">CV2的常用方法</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            抖店
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/%E6%8A%96%E5%BA%97API%E5%BC%80%E5%8F%91/%E8%AE%A2%E5%8D%95%E5%AF%BC%E5%87%BA/">抖店开发--订单导出之信息获取</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            深度学习
                        </a>
                         <ul class="unstyled" id="tree" > 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            TensorFlow2
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Tensorflow%E7%AC%94%E8%AE%B0/CNN/">TensorFlow2笔记-CNN(卷积神经网络)</a></li>  <li class="file"><a href="/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Tensorflow%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E8%AE%B2-%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%89%A9%E5%B1%95/">TensorFlow2笔记-第四讲(网络八股扩展)</a></li>  <li class="file"><a href="/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Tensorflow%E7%AC%94%E8%AE%B0/NN/">TensorFlow2笔记-NN(全连接)</a></li>  <li class="file"><a href="/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Tensorflow%E7%AC%94%E8%AE%B0/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/">TensorFlow2笔记-LeNet(经典卷积网络)</a></li>  </ul> 
                    </li> 
                     </ul> 
                    </li> 
                    
                    <li class="directory open">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            爬虫
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E7%88%AC%E8%99%AB/Python%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E4%B8%8E%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/">Python爬虫与开发项目实战——第一回合</a></li>  <li class="file"><a href="/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E7%88%AC%E8%99%AB/Python%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E4%B8%8E%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98-%E7%AC%AC%E4%BA%8C%E5%9B%9E%E5%90%88/">Python爬虫开发与项目实战-第二回合</a></li>  <li class="file"><a href="/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E7%88%AC%E8%99%AB/Python%E7%88%AC%E8%99%AB2.1/">Python爬虫开发与项目实战-第二回合（实战）</a></li>  <li class="file"><a href="/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E7%88%AC%E8%99%AB/Python%E7%88%AC%E8%99%AB-%E4%B8%AD%E7%BA%A7/">Python爬虫-中级</a></li>  <li class="file"><a href="/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E7%88%AC%E8%99%AB/selenium%E5%8F%8D%E7%88%AC/">selenium+Chrome(79版本以上)反爬</a></li>  <li class="file active"><a href="/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E7%88%AC%E8%99%AB/Python%E7%88%AC%E8%99%AB-Scrapy%E8%BF%9B%E9%98%B6/">Python爬虫-Scrapy进阶</a></li>  <li class="file"><a href="/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E7%88%AC%E8%99%AB/debug%E5%8F%8D%E7%88%AC/">debug反爬</a></li>  <li class="file"><a href="/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E7%88%AC%E8%99%AB/%E5%8F%8D%E7%88%AC%E6%8A%80%E5%B7%A7/">反爬技巧</a></li>  <li class="file"><a href="/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E7%88%AC%E8%99%AB/%E6%BB%91%E5%9D%97%E7%A0%B4%E8%A7%A3/">滑块验证码破解</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            程序技术
                        </a>
                         <ul class="unstyled" id="tree" > 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            Git
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Git/%E9%97%AE%E9%A2%98/">Git常见的问题及解决方案</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            Java
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Java/JAVA-Json/">Java中对JSON的操作</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            Python
                        </a>
                         <ul class="unstyled" id="tree" > 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            爬虫
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E7%88%AC%E8%99%AB/Untitled-1/"></a></li>  </ul> 
                    </li> 
                     </ul> 
                    </li> 
                     </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            算法
                        </a>
                         <ul class="unstyled" id="tree" > 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            Leetcode
                        </a>
                         <ul class="unstyled" id="tree" > 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            数组
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/%E7%AE%97%E6%B3%95/Leetcode/%E6%95%B0%E7%BB%84/36.%E6%9C%89%E6%95%88%E6%95%B0%E7%8B%AC/">36.有效数独</a></li>  <li class="file"><a href="/wiki/%E7%AE%97%E6%B3%95/Leetcode/%E6%95%B0%E7%BB%84/48.%E6%97%8B%E8%BD%AC%E6%95%B0%E7%BB%84/">48.旋转数组</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            链表
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/%E7%AE%97%E6%B3%95/Leetcode/%E9%93%BE%E8%A1%A8/19.%E5%88%A0%E9%99%A4%E9%93%BE%E8%A1%A8%E7%9A%84%E5%80%92%E6%95%B0%E7%AC%ACN%E4%B8%AA%E7%BB%93%E7%82%B9/">48.旋转数组</a></li>  </ul> 
                    </li> 
                     </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            经典算法
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/%E7%AE%97%E6%B3%95/Leetcode/%E5%AD%97%E7%AC%A6%E4%B8%B2/KMP/">KMP算法</a></li>  </ul> 
                    </li> 
                     </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            软件配置
                        </a>
                         <ul class="unstyled" id="tree" > 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            hexo
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/%E8%BD%AF%E4%BB%B6%E9%85%8D%E7%BD%AE/hexo/%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/">hexo使用问题</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            python配置
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/wiki/%E8%BD%AF%E4%BB%B6%E9%85%8D%E7%BD%AE/python/Anaconda/">Anaconda配置</a></li>  </ul> 
                    </li> 
                     </ul> 
                    </li> 
                     <li class="file"><a href="/wiki/hello-world/">Hello World</a></li>  </ul> 
    </div>
    <script>
        $(document).ready(function() {
            var iconFolderOpenClass  = 'fa-folder-open';
            var iconFolderCloseClass = 'fa-folder';
            var iconAllExpandClass = 'fa-angle-double-down';
            var iconAllPackClass = 'fa-angle-double-up';
            // Handle directory-tree expansion:
            // 左键单独展开目录
            $(document).on('click', '#categories a[data-role="directory"]', function (event) {
                event.preventDefault();

                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconFolderOpenClass);
                var subtree = $(this).siblings('ul');
                icon.removeClass(iconFolderOpenClass).removeClass(iconFolderCloseClass);
                if (expanded) {
                    if (typeof subtree != 'undefined') {
                        subtree.slideUp({ duration: 100 });
                    }
                    icon.addClass(iconFolderCloseClass);
                } else {
                    if (typeof subtree != 'undefined') {
                        subtree.slideDown({ duration: 100 });
                    }
                    icon.addClass(iconFolderOpenClass);
                }
            });
            // 右键展开下属所有目录
            $('#categories a[data-role="directory"]').bind("contextmenu", function(event){
                event.preventDefault();
                
                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconFolderOpenClass);
                var listNode = $(this).siblings('ul');
                var subtrees = $.merge(listNode.find('li ul'), listNode);
                var icons = $.merge(listNode.find('.fa'), icon);
                icons.removeClass(iconFolderOpenClass).removeClass(iconFolderCloseClass);
                if(expanded) {
                    subtrees.slideUp({ duration: 100 });
                    icons.addClass(iconFolderCloseClass);
                } else {
                    subtrees.slideDown({ duration: 100 });
                    icons.addClass(iconFolderOpenClass);
                }
            })
            // 展开关闭所有目录按钮
            $(document).on('click', '#allExpand', function (event) {
                event.preventDefault();
                
                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconAllExpandClass);
                icon.removeClass(iconAllExpandClass).removeClass(iconAllPackClass);
                if(expanded) {
                    $('#sidebar .fa.fa-folder').removeClass('fa-folder').addClass('fa-folder-open')
                    $('#categories li ul').slideDown({ duration: 100 });
                    icon.addClass(iconAllPackClass);
                } else {
                    $('#sidebar .fa.fa-folder-open').removeClass('fa-folder-open').addClass('fa-folder')
                    $('#categories li ul').slideUp({ duration: 100 });
                    icon.addClass(iconAllExpandClass);
                }
            });  
        });
    </script>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title"><span>archives</span></h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/12/">December 2021</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">November 2021</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/10/">October 2021</a><span class="archive-list-count">12</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title"><span>tags</span></h3>
        <div class="widget">
            <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bug%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/" rel="tag">Bug解决方案</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN/" rel="tag">CNN</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Git/" rel="tag">Git</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JAVA/" rel="tag">JAVA</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JAVASE/" rel="tag">JAVASE</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Java/" rel="tag">Java</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JavaWeb/" rel="tag">JavaWeb</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a><span class="tag-list-count">11</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TensorFlow2/" rel="tag">TensorFlow2</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/bug/" rel="tag">bug</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hexo/" rel="tag">hexo</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" rel="tag">图像处理</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/" rel="tag">字符串</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E7%BB%84/" rel="tag">数组</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a><span class="tag-list-count">9</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%85%8D%E7%BD%AE/" rel="tag">配置</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%93%BE%E8%A1%A8/" rel="tag">链表</a><span class="tag-list-count">1</span></li></ul>
        </div>
    </div>

    
    <div id="toTop" class="fa fa-angle-up"></div>
</aside>
            
            <section id="main"><article id="post-程序技术/Python/爬虫/Python爬虫-Scrapy进阶" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
                    <div class="article-meta">
                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/%E7%88%AC%E8%99%AB/">爬虫</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link-link" href="/tags/Python/" rel="tag">Python</a>, <a class="tag-link-link" href="/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a>
    </div>

                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E7%88%AC%E8%99%AB/Python%E7%88%AC%E8%99%AB-Scrapy%E8%BF%9B%E9%98%B6/">
            <time datetime="2021-12-09T09:00:55.657Z" itemprop="datePublished">2021-12-09</time>
        </a>
    </div>


                        
                            <i class="fa fa-bar-chart"></i>
                            <span id="busuanzi_container_site_pv"><span id="busuanzi_value_page_pv"></span></span>    
                        
                        
                            <div class="article-meta-button">
                                <a target="_blank" rel="noopener" href='https://github.com/zthxxx/Wiki-site/raw/writing/source/_posts/程序技术/Python/爬虫/Python爬虫-Scrapy进阶.md'> Source </a>
                            </div>
                            <div class="article-meta-button">
                                <a target="_blank" rel="noopener" href='https://github.com/zthxxx/Wiki-site/edit/writing/source/_posts/程序技术/Python/爬虫/Python爬虫-Scrapy进阶.md'> Edit </a>
                            </div>
                            <div class="article-meta-button">
                                <a target="_blank" rel="noopener" href='https://github.com/zthxxx/Wiki-site/commits/writing/source/_posts/程序技术/Python/爬虫/Python爬虫-Scrapy进阶.md'> History </a>
                            </div>
                        
                    </div>
                
                
    
        <h1 class="article-title" itemprop="name">
            Python爬虫-Scrapy进阶
        </h1>
    

            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
        
            
        
        
            <h3 id="1-Spider模块"><a href="#1-Spider模块" class="headerlink" title="1.Spider模块"></a><a href="#one">1.Spider模块</a></h3><h3 id="2-Item-Loader"><a href="#2-Item-Loader" class="headerlink" title="2.Item Loader"></a><a href="#two">2.Item Loader</a></h3><h2 id="深入Scrapy爬虫框架"><a href="#深入Scrapy爬虫框架" class="headerlink" title="深入Scrapy爬虫框架"></a>深入Scrapy爬虫框架</h2><blockquote>
<h4 id="1-Spider模块-1"><a href="#1-Spider模块-1" class="headerlink" title="1.Spider模块"></a><a id="one"></a>1.Spider模块</h4></blockquote>
<p>Spider模块是定义爬虫的动作及分析网页结构的地方，我们容易看出，在这里给出了解析网页获取元素，并进行是否继续爬取下一个网页的操作(也就是爬虫的动作)。Spider的执行流程</p>
<blockquote>
<ol>
<li><p>从入口URL初始化Request并设置回调函数。这个Reuquest下载完毕返回Response，并作为参数传送给回调函数，Spider初始的Request是通过调用start_requests()方法获取。start_requests()读取start_urls中的URL，并以parse为回调函数生成Request。也就是说初始的URL，只需要在start_urls加入，系统会自动的获取response，并以parse()为解析函数。</p>
</li>
<li><p>在回调函数分析Response，返回Item对象，dict,ruquest或者一个包括三者的可迭代容器。其中返回的Request对象会经过Scrapy处理，下载相应内容，并调用设置相应的解析函数。例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">request = scrapy.Request(url=url,callback=self.parse_body) <span class="comment">#调用Request方法，并设置解析函数</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>在解析函数内，可以使用页面解析技术，对页面元素进行解析，可以用BeautifuleSoup等等技术。通过response可以获取到响应的内容。将分析的数据生成item</p>
</li>
<li><p>由spider返回item,可以经过Item Pipeline被存到数据库或使用Feed exports存入到文件中。</p>
</li>
</ol>
</blockquote>
<h5 id="Spider类的成员变量"><a href="#Spider类的成员变量" class="headerlink" title="Spider类的成员变量"></a>Spider类的成员变量</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"> @:param name 定义spider名字的字符串，名字必须唯一。可以生成多个相同的spider实例</span></span><br><span class="line"><span class="string"> 通常可以用网站域名命名spider</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> @:param allowed_domains: 包含了spder允许爬取的域名列表。</span></span><br><span class="line"><span class="string"> 当OffsiteMiddleware组件启用时，域名不在列表中的URL不会被跟进。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> @:param statr_urls:URL列表，当没有配置statr_requests9）f方法的时候，spider会从该列表开始进行爬取。也就是说爬虫开始爬取的</span></span><br><span class="line"><span class="string"> URL就是从start_urls中获取。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> @:param custom_setting：该设置是一个dict,当启动spider时，该设置将会覆盖项目级的设置。也就是</span></span><br><span class="line"><span class="string"> 说可以在这里对spider单独定义。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> @:param crawler 该属性在初始化class后，由类方法from_crawler()设置。并且链接了</span></span><br><span class="line"><span class="string"> 本spider实例羽Crawler对象。</span></span><br><span class="line"><span class="string"> &#x27;&#x27;&#x27;</span></span><br><span class="line"> name = <span class="string">&#x27;myspider&#x27;</span></span><br><span class="line"> allowed_domains = [<span class="string">&quot;www.baidu.com&quot;</span>]</span><br><span class="line"> start_urls = [</span><br><span class="line">     <span class="string">&quot;https://www.baidu.com&quot;</span></span><br><span class="line"> ]</span><br><span class="line"> custom_settings = &#123;&#125;</span><br><span class="line"> crawler = <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="Spider类的方法"><a href="#Spider类的方法" class="headerlink" title="Spider类的方法"></a>Spider类的方法</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 常用的Spider方法</span></span><br><span class="line"><span class="comment"># 该方法必须返回一个可迭代对象，对象包含spider用于爬虫的第一个request。</span></span><br><span class="line"><span class="comment"># 也就是说 start_requests是项目启动的开始，是根据start_url作为项目启动URL</span></span><br><span class="line"><span class="comment"># 如果没有设置start_requests方法，就会默认从start_urls的url生成Request。</span></span><br><span class="line"><span class="comment"># 如果需要定制最初爬取的Request对象，可以重写方法。</span></span><br><span class="line"><span class="comment"># 例如通过POST登录</span></span><br><span class="line"><span class="comment"># 总结来说：strt_request就是整个程序的入口，如果不指定就是直接从start_ruls中获取url，以parse()为回调函数进行解析。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">start_requests</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="keyword">return</span> [scrapy.FormRequest(<span class="string">&quot;http://www.example.com/login&quot;</span>,formdata=&#123;</span><br><span class="line">        <span class="string">&#x27;user&#x27;</span>:<span class="string">&#x27;john&#x27;</span>,<span class="string">&#x27;pass&#x27;</span>:<span class="string">&#x27;secret&#x27;</span></span><br><span class="line">    &#125;,callback=self.login)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># start_requests对url请求后的响应，会通过login进行处理</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">login</span>(<span class="params">self,response</span>):</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_requests_from_url</span>(<span class="params">self, url</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    接受一个URL并返回用于爬取的Request对象</span></span><br><span class="line"><span class="string">    :param url:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response, **kwargs</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    用于解析网页内容，一般作为初始URL解析的回调函数</span></span><br><span class="line"><span class="string">    :param response:</span></span><br><span class="line"><span class="string">    :param kwargs:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">close</span>(<span class="params">spider, reason</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    当Spider关闭时，该函数被调用。可以用来在spider关闭时，释放占用的资源。</span></span><br><span class="line"><span class="string">    :param reason:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>Scrapy除了Spider类作为基类进行扩展，还提供了CrawlSpider，XMLFeedSpider,CSVFeedSpider和SitemapSpider等类来实现不同的爬虫任务。</p>
<h6 id="CrawlSpider"><a href="#CrawlSpider" class="headerlink" title="CrawlSpider"></a>CrawlSpider</h6><p>CrawlSpider类常用于爬取一般的网站。其中定义了一些规则(rule)来提供跟进链接功能。<br>CrawlSpider提供了新的属性rules。rules包含一个或多个Rule对象的集合。每个Rule对爬取网站的动作定义了特定的规则。如果多个Rule匹配相同的链接，则先定义的被调用。<br>CrawlSpider提供的初始URL解析方法，parse_start_url(response)。该方法返回一个Item对象或者一个Request对象或者包含二者的对象。使用示例如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyCrawlSpider</span>(<span class="params">CrawlSpider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;crawlSpider&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&quot;cnblogs.com&quot;</span>]<span class="comment">#域名</span></span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">&quot;http://www.cnblogs.com/qiyeboy/default.html?page=1&quot;</span></span><br><span class="line">    ]</span><br><span class="line">    <span class="comment"># Rule原型</span></span><br><span class="line">    <span class="comment"># scrapy.contrib.spiders.Rule(link_exactor,callback=None,cb_kwargs=None,</span></span><br><span class="line">    <span class="comment"># follow=None,process_links=None,process_request=None)</span></span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(allow=(<span class="string">&quot;/qiyeboy/default.html\?page=\d&#123;1,&#125;&quot;</span>,)),</span><br><span class="line">                    follow=<span class="literal">True</span>,</span><br><span class="line">                    callback=<span class="string">&#x27;parse_item&#x27;</span></span><br><span class="line">                           ),</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># LinkExtractor对象的构造</span></span><br><span class="line">    <span class="comment"># allow: 用于匹配满足正则表达式的链接</span></span><br><span class="line">    <span class="comment"># deny: 排除正则表达式匹配的链接，优先级高于allow</span></span><br><span class="line">    <span class="comment"># allow_domains：允许的域名，可以是list或str</span></span><br><span class="line">    <span class="comment"># deny_domains:排除的域名</span></span><br><span class="line">    <span class="comment"># restrict_xpaths:提取满足Xpath选择条件的链接。</span></span><br><span class="line">    <span class="comment"># restrict_css:xxxCSSxxx的链接</span></span><br><span class="line">    <span class="comment"># tags: 提取指定标签下的链接。</span></span><br><span class="line">    <span class="comment"># unique:链接是否去重</span></span><br><span class="line">    <span class="comment"># process_value:值处理函数。</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response, **kwargs</span>):</span></span><br><span class="line">        papers = response.xpath(<span class="string">&quot;.//*[@class=&#x27;day&#x27;]&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> paper <span class="keyword">in</span> papers:</span><br><span class="line">            url = paper.xpath(<span class="string">&quot;.//*[@class=&#x27;postTitle&#x27;]/a/@href&quot;</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            title = paper.xpath(<span class="string">&quot;.//*[@class=&#x27;postTitle&#x27;]/a/text()&quot;</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            time = paper.xpath(<span class="string">&quot;.//*[@class=&#x27;dayTitle&#x27;]/a/text()&quot;</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            content = paper.xpath(<span class="string">&quot;.//*[@class=&#x27;postTitle&#x27;]/a/text()&quot;</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            item = MyCrawlSpider(url=url, title=title, time=time, content=content)</span><br><span class="line">            request = scrapy.Request(url=url, callback=self.parse_body)  <span class="comment"># 调用Request方法，并设置解析函数</span></span><br><span class="line">            request.meta[<span class="string">&#x27;item&#x27;</span>] = item  <span class="comment"># 将item暂存</span></span><br><span class="line">        <span class="keyword">yield</span> request</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_body</span>(<span class="params">self,response</span>):</span></span><br><span class="line">        item = response.meta[<span class="string">&#x27;item&#x27;</span>]</span><br><span class="line">        body = response.xpath(<span class="string">&quot;.//*[@class=&#x27;postBody&#x27;]&quot;</span>)</span><br><span class="line">        item[<span class="string">&#x27;cimage_urls&#x27;</span>] = body.xpath(<span class="string">&#x27;.//img//@src&#x27;</span>).extract()<span class="comment"># 提取图片链接</span></span><br><span class="line">        <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure>
<h6 id="XMLFeedSpider"><a href="#XMLFeedSpider" class="headerlink" title="XMLFeedSpider"></a>XMLFeedSpider</h6><p>XMLFeedSpider被设计用于通过迭代各个节点来分析XML源。迭代器可以从Iternodes,XML,HTML中选择。在XMLFeedSpider中，需要定义下列类属性来设置迭代器及标记名称。</p>
<ol>
<li>iterator</li>
</ol>
<p>用于确定使用哪个迭代器string,默认为iternodes，可选项有(1. iternodes, 2. html , 3. html)</p>
<ol>
<li><p>itertag</p>
<p>itertag为一个包含开始迭代的节点名string</p>
</li>
<li><p>namespaces</p>
<p> 称为命名空间，由(prefix,url),元组(tuple)所组成的list。这里定义了在文档中会被spider处理可用的namespace,prefix和url会被自动调用。由register_namespace()方法生成namespace。</p>
</li>
</ol>
<p>示例代码如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyXMLFeedSpider</span>(<span class="params">XMLFeedSpider</span>):</span></span><br><span class="line"></span><br><span class="line">    name = <span class="string">&quot;myxmlfeed&quot;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;cnblogs.com&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&quot;https://feed.cnblogs.com/blog/u/269038/rss&quot;</span>]</span><br><span class="line">    namespaces = [&#123;<span class="string">&#x27;n&#x27;</span>,<span class="string">&#x27;http://www.sitemaps.org/schemas/sitemap/0.9&#x27;</span>&#125;]</span><br><span class="line">    iterator = <span class="string">&#x27;html&#x27;</span> <span class="comment"># 用于定义解析方式</span></span><br><span class="line">    itertag = <span class="string">&#x27;entry&#x27;</span></span><br><span class="line">    <span class="comment">#XMLFeedSpider方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">adapt_response</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        这个方法在页面解析前和页面下载后之间被调用。可以用于修改Response内容，并再返回。</span></span><br><span class="line"><span class="string">        :param response:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span>  response</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_node</span>(<span class="params">self, response, selector</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">            当节点符合itertag时，该方法被调用。接收到的response以及相对应的Selector作为参数传递给该方法。</span></span><br><span class="line"><span class="string">            需要返回一个Item对象或Request对象，或包含二者的可迭代对象</span></span><br><span class="line"><span class="string">        :param response:</span></span><br><span class="line"><span class="string">        :param selector:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">print</span>(selector.xpath(<span class="string">&#x27;id/text()&#x27;</span>).extract()[<span class="number">0</span>])</span><br><span class="line">        <span class="built_in">print</span>(selector.xpath(<span class="string">&#x27;title/text()&#x27;</span>).extract()[<span class="number">0</span>])</span><br><span class="line">        <span class="built_in">print</span>(selector.xpath(<span class="string">&#x27;summary/text()&#x27;</span>).extract()[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_results</span>(<span class="params">self, response, results</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        在页面解析后，数据返回前进行处理。主要是对返回数据的最后处理。修改Item的内容</span></span><br><span class="line"><span class="string">        :param response:</span></span><br><span class="line"><span class="string">        :param results:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> [response,results]</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<blockquote>
<h4 id="2-Item-Loader模块"><a href="#2-Item-Loader模块" class="headerlink" title="2.Item Loader模块"></a><a id="two"></a>2.Item Loader模块</h4><h5 id="Item-Loader是什么？"><a href="#Item-Loader是什么？" class="headerlink" title="Item Loader是什么？"></a>Item Loader是什么？</h5></blockquote>
<p>Item Loader提供了一种边界的方式填充抓到的Items。Item Loader可以直接对Item分析，并提取出想要的数据保存到容器中，而Item则是机械的根据键值对对应，返回数据。所以Item Loader更加灵活，高效。</p>
<p>Item Loader负责数据的收集，处理和填充。Item Loader包含两个重要的组件：输入处理器(input processors)和输出处理器(output processors)。</p>
<ol>
<li>Item Loader的每个字段都包含了一个输入处理器和输出处理器。</li>
<li>输入处理器接收到response后，通过add_xpath,add_css,add_value等方法提取数据，并将数据保存到Item Loader中。</li>
<li>收集完成数据之后，通过ItemLoader.load_item()方法来填充并返回Item对象。load_item()方法内部先调用输出处理器来处理收集到的数据，结果保存到最终的Item中。</li>
</ol>
<blockquote>
<h5 id="Item-Loader使用方法"><a href="#Item-Loader使用方法" class="headerlink" title="Item Loader使用方法"></a>Item Loader使用方法</h5></blockquote>
<p>在Item中声明输入输出处理器<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在Item中声明输入和输出处理器</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">filter_price</span>(<span class="params">value</span>):</span></span><br><span class="line">    <span class="keyword">if</span> value.isdigit():</span><br><span class="line">        <span class="keyword">return</span> value</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Product</span>(<span class="params">scrapy.Item</span>):</span></span><br><span class="line"></span><br><span class="line">    name = scrapy.Field(</span><br><span class="line">        input_processor=MapCompose(remove_tags),</span><br><span class="line">        output_processor=Join(),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    price = scrapy.Field(</span><br><span class="line">        input_processor=MapCompose(remove_tags,filter_price),</span><br><span class="line">        output_processor=TakeFirst(),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    stock = scrapy.Field()</span><br><span class="line">    last_updated = scrapy.Field(serializer=<span class="built_in">str</span>)</span><br></pre></td></tr></table></figure></p>
<p>在Item Loader类中声明类似field_in和field_out的属性。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ItemLoader</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ProductLoadr</span>(<span class="params">ItemLoader</span>):</span></span><br><span class="line">    default_output_processor = TakeFirst()</span><br><span class="line">    <span class="comment"># 声明输入输出处理器</span></span><br><span class="line">    <span class="comment">#输入处理器</span></span><br><span class="line">    name_in = MapCompose(unicode.title)</span><br><span class="line">    <span class="comment">#输出处理器</span></span><br><span class="line">    name_out = Join()</span><br><span class="line">    price_in =  MapCompose(unicode.price)</span><br><span class="line">    price_out = Join()</span><br><span class="line">    stock_in = MapCompose(unicode.stock)</span><br><span class="line">    stock_out = Join()</span><br><span class="line">    last_updated_in = MapCompose(unicode.last_updated)</span><br><span class="line">    last_updated_out = Join()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<h5 id="Item-Loader-Context"><a href="#Item-Loader-Context" class="headerlink" title="Item Loader Context"></a>Item Loader Context</h5></blockquote>
<p>Item Loader Context是一个任意的键值对字典。能够被Item Loader中的输入输出处理器所共享。<br>可以用于调整输入输出处理器的行为。</p>

            </div>
        
        <footer class="article-footer">
        </footer>
    </div>
</article>


    
<nav id="article-nav">
    
        <a href="/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E7%88%AC%E8%99%AB/debug%E5%8F%8D%E7%88%AC/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">Newer</strong>
            <div class="article-nav-title">
                
                    debug反爬
                
            </div>
        </a>
    
    
        <a href="/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">Older</strong>
            <div class="article-nav-title">Python常见问题</div>
        </a>
    
</nav>





    
    




<!-- baidu url auto push script -->
<script type="text/javascript">
    !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=window.location.href,o=document.referrer;if(!e.test(r)){var n="//api.share.baidu.com/s.gif";o?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var t=new Image;t.src=n}}(window);
</script>     
</section>
        </div>
        <footer id="footer">
    
        <script src='https://unpkg.com/mermaid@7.1.2/dist/mermaid.min.js'></script>
        <script>
            if (window.mermaid) {
                mermaid.initialize({
                    theme: 'forest'
                });
            }
        </script>
        
            <div class="outer">
                <div id="footer-info" class="inner">
                    ZZC &copy;
                        2021
                            <a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/80x15.png" /></a>
                            <br> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme - <a target="_blank" rel="noopener" href="https://github.com/zthxxx/hexo-theme-Wikitten">wikitten</a>
                            
                                <br>
                                <span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i> <span id="busuanzi_value_site_pv"></span></span>
                                &nbsp;|&nbsp;
                                <span id="busuanzi_container_site_pv"><i class="fa fa-user"></i> <span id="busuanzi_value_site_uv"></span></span>
                                
                </div>
            </div>
</footer>
        

    
        
<script src="/libs/lightgallery/js/lightgallery.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-pager.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-zoom.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-hash.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-share.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-video.min.js"></script>

    
    
        
<script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>

    
    
        <script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: { inlineMath: [ ["$","$"], ["\\(","\\)"] ], skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'], processEscapes: true, TeX: { equationNumbers: { autoNumber: 'AMS' } } } }); MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(); for (var i = 0; i
    < all.length; ++i) all[i].SourceElement().parentNode.className +=' has-jax' ; }); </script>
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <!-- <script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
    



<!-- Custom Scripts -->

<script src="/js/main.js"></script>


    </div>
</body>
</html>