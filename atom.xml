<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>个人博客</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-12-13T07:35:09.963Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>ZZC</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>CV2的常用方法</title>
    <link href="http://example.com/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/CV2/"/>
    <id>http://example.com/wiki/程序技术/Python/图像处理/CV2/</id>
    <published>2021-12-13T07:33:05.449Z</published>
    <updated>2021-12-13T07:35:09.963Z</updated>
    
    <content type="html"><![CDATA[<h4 id="读取图片"><a href="#读取图片" class="headerlink" title="读取图片"></a>读取图片</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img1 = cv2.imread(<span class="string">&#x27;bg1.png&#x27;</span>)</span><br></pre></td></tr></table></figure><h4 id="修改图片比例"><a href="#修改图片比例" class="headerlink" title="修改图片比例"></a>修改图片比例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img1 = cv2.resize(img1,(y(图像高度),x(图像宽度)))</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;读取图片&quot;&gt;&lt;a href=&quot;#读取图片&quot; class=&quot;headerlink&quot; title=&quot;读取图片&quot;&gt;&lt;/a&gt;读取图片&lt;/h4&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;p
      
    
    </summary>
    
      <category term="Python" scheme="http://example.com/categories/Python/"/>
    
    
      <category term="Python" scheme="http://example.com/tags/Python/"/>
    
      <category term="图像处理" scheme="http://example.com/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>滑块验证码破解</title>
    <link href="http://example.com/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E7%88%AC%E8%99%AB/%E6%BB%91%E5%9D%97%E7%A0%B4%E8%A7%A3/"/>
    <id>http://example.com/wiki/程序技术/Python/爬虫/滑块破解/</id>
    <published>2021-12-13T07:01:04.559Z</published>
    <updated>2021-12-13T07:14:04.431Z</updated>
    
    <content type="html"><![CDATA[<h4 id="滑块验证码破解"><a href="#滑块验证码破解" class="headerlink" title="滑块验证码破解"></a>滑块验证码破解</h4><p>最近在爬虫开发的过程中，遇到了关于滑块验证码，需要进行滑块验证码破解。这里涉及到图像方面的技术，可以借助OpenCV进行解决。</p><h4 id="通过CV2解决滑块验证"><a href="#通过CV2解决滑块验证" class="headerlink" title="通过CV2解决滑块验证"></a>通过CV2解决滑块验证</h4><p>这里通过CV2库进行滑块验证的解决。简单介绍一下滑块验证的几个步骤。</p><h5 id="1-获取图片（不带缺口的图片，带缺口的图片）"><a href="#1-获取图片（不带缺口的图片，带缺口的图片）" class="headerlink" title="1. 获取图片（不带缺口的图片，带缺口的图片）"></a>1. 获取图片（不带缺口的图片，带缺口的图片）</h5><p>根据网页，获取到滑块图片，一般来说分为两个图片，一个是缺口图，也就是缺少缺口的图片。一个是滑块图，也就是缺口图缺少的图片。假设缺口图为img1,滑块图为img2。</p><h5 id="2-识别缺口位置（设置一个对比阈值，遍历两张图片，找出相同位置像素RGB差距，超过此阈值的像素点，此像素点的位置就是缺口的位置）"><a href="#2-识别缺口位置（设置一个对比阈值，遍历两张图片，找出相同位置像素RGB差距，超过此阈值的像素点，此像素点的位置就是缺口的位置）" class="headerlink" title="2. 识别缺口位置（设置一个对比阈值，遍历两张图片，找出相同位置像素RGB差距，超过此阈值的像素点，此像素点的位置就是缺口的位置）"></a>2. 识别缺口位置（设置一个对比阈值，遍历两张图片，找出相同位置像素RGB差距，超过此阈值的像素点，此像素点的位置就是缺口的位置）</h5><h5 id="3-计算滑动距离"><a href="#3-计算滑动距离" class="headerlink" title="3. 计算滑动距离"></a>3. 计算滑动距离</h5><h5 id="4-模拟运动"><a href="#4-模拟运动" class="headerlink" title="4. 模拟运动"></a>4. 模拟运动</h5>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;滑块验证码破解&quot;&gt;&lt;a href=&quot;#滑块验证码破解&quot; class=&quot;headerlink&quot; title=&quot;滑块验证码破解&quot;&gt;&lt;/a&gt;滑块验证码破解&lt;/h4&gt;&lt;p&gt;最近在爬虫开发的过程中，遇到了关于滑块验证码，需要进行滑块验证码破解。这里涉及到图像方面的技术，可以
      
    
    </summary>
    
      <category term="爬虫" scheme="http://example.com/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="Python" scheme="http://example.com/tags/Python/"/>
    
      <category term="爬虫" scheme="http://example.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>Web项目部署</title>
    <link href="http://example.com/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Java/JavaWeb/%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2/"/>
    <id>http://example.com/wiki/程序技术/Java/JavaWeb/项目部署/</id>
    <published>2021-12-10T09:31:23.397Z</published>
    <updated>2021-12-13T01:22:04.658Z</updated>
    
    <content type="html"><![CDATA[<ol><li>安装Tomcat</li></ol><blockquote><ol><li>通过 tar -zxvf 解压tomcat。</li><li>修改catalina.sh，在脚本开头增加export JAVA_HOME指定jdk路径。</li></ol></blockquote><p>修改Tomcat的端口：<br>将8080，8005，8009修改其它端口即可。<br> <Connector port="8080"               maxThreads="150" minSpareThreads="25" maxSpareThreads="75"               enableLookups="false" redirectPort="8443" acceptCount="100"               connectionTimeout="20000" disableUploadTimeout="true" /></p><Server port="8005" shutdown="SHUTDOWN"><Connector port="8009" protocol="AJP/1.3" redirectPort="8443"/><ol><li>下载jdk</li></ol><p>下载jdk，然后通过tar -zxvf 进行解压jdk</p><ol><li>打包项目</li></ol><p>将项目打包war包，然后放入到tomcat的webapp目录下即可。</p><blockquote><ol><li>访问路径</li></ol></blockquote><p>将War包包放到webapp下之后，访问路径的名称就是war包的名称，假设war包为AAA.war,部署端口为8080.<br>ip地址为xxx.xxx.xxx则访问路径为：<a href="https://xxx.xxx.xxx/AAA。">https://xxx.xxx.xxx/AAA。</a></p><blockquote><ol><li>报错解决</li></ol></blockquote><h3 id="Cannot-find-usr-tomcat-tomcat9-bin-setclasspath-sh"><a href="#Cannot-find-usr-tomcat-tomcat9-bin-setclasspath-sh" class="headerlink" title="Cannot find /usr/tomcat/tomcat9/bin/setclasspath.sh"></a>Cannot find /usr/tomcat/tomcat9/bin/setclasspath.sh</h3><p>执行：unset CATALINA_HOME</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;安装Tomcat&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;通过 tar -zxvf 解压tomcat。&lt;/li&gt;
&lt;li&gt;修改catalina.sh，在脚本开头增加export JAVA_HOME指定jdk路径。&lt;/li&gt;
&lt;/ol&gt;

      
    
    </summary>
    
      <category term="JavaWeb" scheme="http://example.com/categories/JavaWeb/"/>
    
    
      <category term="JavaWeb" scheme="http://example.com/tags/JavaWeb/"/>
    
  </entry>
  
  <entry>
    <title>反爬技巧</title>
    <link href="http://example.com/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E7%88%AC%E8%99%AB/%E5%8F%8D%E7%88%AC%E6%8A%80%E5%B7%A7/"/>
    <id>http://example.com/wiki/程序技术/Python/爬虫/反爬技巧/</id>
    <published>2021-12-10T08:19:06.344Z</published>
    <updated>2021-12-10T08:21:56.064Z</updated>
    
    <content type="html"><![CDATA[<h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>这里主要总结了一些爬虫开发过程中的反爬技巧。</p><blockquote><ol><li>正确设置headers</li></ol></blockquote><p>通常我们简单设置一下User-Agent就能够获取到网页内容。但是对于一些网站，通过request获取到的网页内容，通常又和正常访问网页获取到的内容不一致。这里就需要根据网页的Headers来设置request内的headers属性，用于避免被检测。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h4&gt;&lt;p&gt;这里主要总结了一些爬虫开发过程中的反爬技巧。&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;正确设置headers&lt;/li&gt;
&lt;/ol
      
    
    </summary>
    
      <category term="爬虫" scheme="http://example.com/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="Python" scheme="http://example.com/tags/Python/"/>
    
      <category term="爬虫" scheme="http://example.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>debug反爬</title>
    <link href="http://example.com/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E7%88%AC%E8%99%AB/debug%E5%8F%8D%E7%88%AC/"/>
    <id>http://example.com/wiki/程序技术/Python/爬虫/debug反爬/</id>
    <published>2021-12-10T07:01:24.965Z</published>
    <updated>2021-12-10T07:08:39.363Z</updated>
    
    <content type="html"><![CDATA[<h4 id="关于解决-function-anonymous-debugger-的问题"><a href="#关于解决-function-anonymous-debugger-的问题" class="headerlink" title="关于解决(function anonymous() {debugger})的问题"></a>关于解决(function anonymous() {debugger})的问题</h4><h5 id="1-实现原理"><a href="#1-实现原理" class="headerlink" title="1. 实现原理"></a>1. 实现原理</h5><p>如何实现无限debugger呢？实现无限debugger就是不断的打断你，页面跳转到source页面，阻止你看内容。<br>写一个不断调用debugger即可。<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">(<span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;<span class="keyword">var</span> a = <span class="keyword">new</span> <span class="built_in">Date</span>(); <span class="keyword">debugger</span>; <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">Date</span>() - a &gt; <span class="number">100</span>;&#125;())</span><br><span class="line"></span><br></pre></td></tr></table></figure></p><h5 id="2-问题解决"><a href="#2-问题解决" class="headerlink" title="2. 问题解决"></a>2. 问题解决</h5>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;关于解决-function-anonymous-debugger-的问题&quot;&gt;&lt;a href=&quot;#关于解决-function-anonymous-debugger-的问题&quot; class=&quot;headerlink&quot; title=&quot;关于解决(function anonym
      
    
    </summary>
    
      <category term="爬虫" scheme="http://example.com/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="Python" scheme="http://example.com/tags/Python/"/>
    
      <category term="爬虫" scheme="http://example.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>Python爬虫-Scrapy进阶</title>
    <link href="http://example.com/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E7%88%AC%E8%99%AB/Python%E7%88%AC%E8%99%AB-Scrapy%E8%BF%9B%E9%98%B6/"/>
    <id>http://example.com/wiki/程序技术/Python/爬虫/Python爬虫-Scrapy进阶/</id>
    <published>2021-12-09T09:00:55.657Z</published>
    <updated>2021-12-10T06:39:40.879Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-Spider模块"><a href="#1-Spider模块" class="headerlink" title="1.Spider模块"></a><a href="#one">1.Spider模块</a></h3><h3 id="2-Item-Loader"><a href="#2-Item-Loader" class="headerlink" title="2.Item Loader"></a><a href="#two">2.Item Loader</a></h3><h2 id="深入Scrapy爬虫框架"><a href="#深入Scrapy爬虫框架" class="headerlink" title="深入Scrapy爬虫框架"></a>深入Scrapy爬虫框架</h2><blockquote><h4 id="1-Spider模块-1"><a href="#1-Spider模块-1" class="headerlink" title="1.Spider模块"></a><a id="one"></a>1.Spider模块</h4></blockquote><p>Spider模块是定义爬虫的动作及分析网页结构的地方，我们容易看出，在这里给出了解析网页获取元素，并进行是否继续爬取下一个网页的操作(也就是爬虫的动作)。Spider的执行流程</p><blockquote><ol><li><p>从入口URL初始化Request并设置回调函数。这个Reuquest下载完毕返回Response，并作为参数传送给回调函数，Spider初始的Request是通过调用start_requests()方法获取。start_requests()读取start_urls中的URL，并以parse为回调函数生成Request。也就是说初始的URL，只需要在start_urls加入，系统会自动的获取response，并以parse()为解析函数。</p></li><li><p>在回调函数分析Response，返回Item对象，dict,ruquest或者一个包括三者的可迭代容器。其中返回的Request对象会经过Scrapy处理，下载相应内容，并调用设置相应的解析函数。例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">request = scrapy.Request(url=url,callback=self.parse_body) <span class="comment">#调用Request方法，并设置解析函数</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>在解析函数内，可以使用页面解析技术，对页面元素进行解析，可以用BeautifuleSoup等等技术。通过response可以获取到响应的内容。将分析的数据生成item</p></li><li><p>由spider返回item,可以经过Item Pipeline被存到数据库或使用Feed exports存入到文件中。</p></li></ol></blockquote><h5 id="Spider类的成员变量"><a href="#Spider类的成员变量" class="headerlink" title="Spider类的成员变量"></a>Spider类的成员变量</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"> @:param name 定义spider名字的字符串，名字必须唯一。可以生成多个相同的spider实例</span></span><br><span class="line"><span class="string"> 通常可以用网站域名命名spider</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> @:param allowed_domains: 包含了spder允许爬取的域名列表。</span></span><br><span class="line"><span class="string"> 当OffsiteMiddleware组件启用时，域名不在列表中的URL不会被跟进。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> @:param statr_urls:URL列表，当没有配置statr_requests9）f方法的时候，spider会从该列表开始进行爬取。也就是说爬虫开始爬取的</span></span><br><span class="line"><span class="string"> URL就是从start_urls中获取。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> @:param custom_setting：该设置是一个dict,当启动spider时，该设置将会覆盖项目级的设置。也就是</span></span><br><span class="line"><span class="string"> 说可以在这里对spider单独定义。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> @:param crawler 该属性在初始化class后，由类方法from_crawler()设置。并且链接了</span></span><br><span class="line"><span class="string"> 本spider实例羽Crawler对象。</span></span><br><span class="line"><span class="string"> &#x27;&#x27;&#x27;</span></span><br><span class="line"> name = <span class="string">&#x27;myspider&#x27;</span></span><br><span class="line"> allowed_domains = [<span class="string">&quot;www.baidu.com&quot;</span>]</span><br><span class="line"> start_urls = [</span><br><span class="line">     <span class="string">&quot;https://www.baidu.com&quot;</span></span><br><span class="line"> ]</span><br><span class="line"> custom_settings = &#123;&#125;</span><br><span class="line"> crawler = <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h5 id="Spider类的方法"><a href="#Spider类的方法" class="headerlink" title="Spider类的方法"></a>Spider类的方法</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 常用的Spider方法</span></span><br><span class="line"><span class="comment"># 该方法必须返回一个可迭代对象，对象包含spider用于爬虫的第一个request。</span></span><br><span class="line"><span class="comment"># 也就是说 start_requests是项目启动的开始，是根据start_url作为项目启动URL</span></span><br><span class="line"><span class="comment"># 如果没有设置start_requests方法，就会默认从start_urls的url生成Request。</span></span><br><span class="line"><span class="comment"># 如果需要定制最初爬取的Request对象，可以重写方法。</span></span><br><span class="line"><span class="comment"># 例如通过POST登录</span></span><br><span class="line"><span class="comment"># 总结来说：strt_request就是整个程序的入口，如果不指定就是直接从start_ruls中获取url，以parse()为回调函数进行解析。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">start_requests</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="keyword">return</span> [scrapy.FormRequest(<span class="string">&quot;http://www.example.com/login&quot;</span>,formdata=&#123;</span><br><span class="line">        <span class="string">&#x27;user&#x27;</span>:<span class="string">&#x27;john&#x27;</span>,<span class="string">&#x27;pass&#x27;</span>:<span class="string">&#x27;secret&#x27;</span></span><br><span class="line">    &#125;,callback=self.login)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># start_requests对url请求后的响应，会通过login进行处理</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">login</span>(<span class="params">self,response</span>):</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_requests_from_url</span>(<span class="params">self, url</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    接受一个URL并返回用于爬取的Request对象</span></span><br><span class="line"><span class="string">    :param url:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response, **kwargs</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    用于解析网页内容，一般作为初始URL解析的回调函数</span></span><br><span class="line"><span class="string">    :param response:</span></span><br><span class="line"><span class="string">    :param kwargs:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">close</span>(<span class="params">spider, reason</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    当Spider关闭时，该函数被调用。可以用来在spider关闭时，释放占用的资源。</span></span><br><span class="line"><span class="string">    :param reason:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>Scrapy除了Spider类作为基类进行扩展，还提供了CrawlSpider，XMLFeedSpider,CSVFeedSpider和SitemapSpider等类来实现不同的爬虫任务。</p><h6 id="CrawlSpider"><a href="#CrawlSpider" class="headerlink" title="CrawlSpider"></a>CrawlSpider</h6><p>CrawlSpider类常用于爬取一般的网站。其中定义了一些规则(rule)来提供跟进链接功能。<br>CrawlSpider提供了新的属性rules。rules包含一个或多个Rule对象的集合。每个Rule对爬取网站的动作定义了特定的规则。如果多个Rule匹配相同的链接，则先定义的被调用。<br>CrawlSpider提供的初始URL解析方法，parse_start_url(response)。该方法返回一个Item对象或者一个Request对象或者包含二者的对象。使用示例如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyCrawlSpider</span>(<span class="params">CrawlSpider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;crawlSpider&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&quot;cnblogs.com&quot;</span>]<span class="comment">#域名</span></span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">&quot;http://www.cnblogs.com/qiyeboy/default.html?page=1&quot;</span></span><br><span class="line">    ]</span><br><span class="line">    <span class="comment"># Rule原型</span></span><br><span class="line">    <span class="comment"># scrapy.contrib.spiders.Rule(link_exactor,callback=None,cb_kwargs=None,</span></span><br><span class="line">    <span class="comment"># follow=None,process_links=None,process_request=None)</span></span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(allow=(<span class="string">&quot;/qiyeboy/default.html\?page=\d&#123;1,&#125;&quot;</span>,)),</span><br><span class="line">                    follow=<span class="literal">True</span>,</span><br><span class="line">                    callback=<span class="string">&#x27;parse_item&#x27;</span></span><br><span class="line">                           ),</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># LinkExtractor对象的构造</span></span><br><span class="line">    <span class="comment"># allow: 用于匹配满足正则表达式的链接</span></span><br><span class="line">    <span class="comment"># deny: 排除正则表达式匹配的链接，优先级高于allow</span></span><br><span class="line">    <span class="comment"># allow_domains：允许的域名，可以是list或str</span></span><br><span class="line">    <span class="comment"># deny_domains:排除的域名</span></span><br><span class="line">    <span class="comment"># restrict_xpaths:提取满足Xpath选择条件的链接。</span></span><br><span class="line">    <span class="comment"># restrict_css:xxxCSSxxx的链接</span></span><br><span class="line">    <span class="comment"># tags: 提取指定标签下的链接。</span></span><br><span class="line">    <span class="comment"># unique:链接是否去重</span></span><br><span class="line">    <span class="comment"># process_value:值处理函数。</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response, **kwargs</span>):</span></span><br><span class="line">        papers = response.xpath(<span class="string">&quot;.//*[@class=&#x27;day&#x27;]&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> paper <span class="keyword">in</span> papers:</span><br><span class="line">            url = paper.xpath(<span class="string">&quot;.//*[@class=&#x27;postTitle&#x27;]/a/@href&quot;</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            title = paper.xpath(<span class="string">&quot;.//*[@class=&#x27;postTitle&#x27;]/a/text()&quot;</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            time = paper.xpath(<span class="string">&quot;.//*[@class=&#x27;dayTitle&#x27;]/a/text()&quot;</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            content = paper.xpath(<span class="string">&quot;.//*[@class=&#x27;postTitle&#x27;]/a/text()&quot;</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            item = MyCrawlSpider(url=url, title=title, time=time, content=content)</span><br><span class="line">            request = scrapy.Request(url=url, callback=self.parse_body)  <span class="comment"># 调用Request方法，并设置解析函数</span></span><br><span class="line">            request.meta[<span class="string">&#x27;item&#x27;</span>] = item  <span class="comment"># 将item暂存</span></span><br><span class="line">        <span class="keyword">yield</span> request</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_body</span>(<span class="params">self,response</span>):</span></span><br><span class="line">        item = response.meta[<span class="string">&#x27;item&#x27;</span>]</span><br><span class="line">        body = response.xpath(<span class="string">&quot;.//*[@class=&#x27;postBody&#x27;]&quot;</span>)</span><br><span class="line">        item[<span class="string">&#x27;cimage_urls&#x27;</span>] = body.xpath(<span class="string">&#x27;.//img//@src&#x27;</span>).extract()<span class="comment"># 提取图片链接</span></span><br><span class="line">        <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure><h6 id="XMLFeedSpider"><a href="#XMLFeedSpider" class="headerlink" title="XMLFeedSpider"></a>XMLFeedSpider</h6><p>XMLFeedSpider被设计用于通过迭代各个节点来分析XML源。迭代器可以从Iternodes,XML,HTML中选择。在XMLFeedSpider中，需要定义下列类属性来设置迭代器及标记名称。</p><ol><li>iterator</li></ol><p>用于确定使用哪个迭代器string,默认为iternodes，可选项有(1. iternodes, 2. html , 3. html)</p><ol><li><p>itertag</p><p>itertag为一个包含开始迭代的节点名string</p></li><li><p>namespaces</p><p> 称为命名空间，由(prefix,url),元组(tuple)所组成的list。这里定义了在文档中会被spider处理可用的namespace,prefix和url会被自动调用。由register_namespace()方法生成namespace。</p></li></ol><p>示例代码如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyXMLFeedSpider</span>(<span class="params">XMLFeedSpider</span>):</span></span><br><span class="line"></span><br><span class="line">    name = <span class="string">&quot;myxmlfeed&quot;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;cnblogs.com&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&quot;https://feed.cnblogs.com/blog/u/269038/rss&quot;</span>]</span><br><span class="line">    namespaces = [&#123;<span class="string">&#x27;n&#x27;</span>,<span class="string">&#x27;http://www.sitemaps.org/schemas/sitemap/0.9&#x27;</span>&#125;]</span><br><span class="line">    iterator = <span class="string">&#x27;html&#x27;</span> <span class="comment"># 用于定义解析方式</span></span><br><span class="line">    itertag = <span class="string">&#x27;entry&#x27;</span></span><br><span class="line">    <span class="comment">#XMLFeedSpider方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">adapt_response</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        这个方法在页面解析前和页面下载后之间被调用。可以用于修改Response内容，并再返回。</span></span><br><span class="line"><span class="string">        :param response:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span>  response</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_node</span>(<span class="params">self, response, selector</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">            当节点符合itertag时，该方法被调用。接收到的response以及相对应的Selector作为参数传递给该方法。</span></span><br><span class="line"><span class="string">            需要返回一个Item对象或Request对象，或包含二者的可迭代对象</span></span><br><span class="line"><span class="string">        :param response:</span></span><br><span class="line"><span class="string">        :param selector:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">print</span>(selector.xpath(<span class="string">&#x27;id/text()&#x27;</span>).extract()[<span class="number">0</span>])</span><br><span class="line">        <span class="built_in">print</span>(selector.xpath(<span class="string">&#x27;title/text()&#x27;</span>).extract()[<span class="number">0</span>])</span><br><span class="line">        <span class="built_in">print</span>(selector.xpath(<span class="string">&#x27;summary/text()&#x27;</span>).extract()[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_results</span>(<span class="params">self, response, results</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        在页面解析后，数据返回前进行处理。主要是对返回数据的最后处理。修改Item的内容</span></span><br><span class="line"><span class="string">        :param response:</span></span><br><span class="line"><span class="string">        :param results:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> [response,results]</span><br><span class="line"></span><br></pre></td></tr></table></figure></p><blockquote><h4 id="2-Item-Loader模块"><a href="#2-Item-Loader模块" class="headerlink" title="2.Item Loader模块"></a><a id="two"></a>2.Item Loader模块</h4><h5 id="Item-Loader是什么？"><a href="#Item-Loader是什么？" class="headerlink" title="Item Loader是什么？"></a>Item Loader是什么？</h5></blockquote><p>Item Loader提供了一种边界的方式填充抓到的Items。Item Loader可以直接对Item分析，并提取出想要的数据保存到容器中，而Item则是机械的根据键值对对应，返回数据。所以Item Loader更加灵活，高效。</p><p>Item Loader负责数据的收集，处理和填充。Item Loader包含两个重要的组件：输入处理器(input processors)和输出处理器(output processors)。</p><ol><li>Item Loader的每个字段都包含了一个输入处理器和输出处理器。</li><li>输入处理器接收到response后，通过add_xpath,add_css,add_value等方法提取数据，并将数据保存到Item Loader中。</li><li>收集完成数据之后，通过ItemLoader.load_item()方法来填充并返回Item对象。load_item()方法内部先调用输出处理器来处理收集到的数据，结果保存到最终的Item中。</li></ol><blockquote><h5 id="Item-Loader使用方法"><a href="#Item-Loader使用方法" class="headerlink" title="Item Loader使用方法"></a>Item Loader使用方法</h5></blockquote><p>在Item中声明输入输出处理器<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在Item中声明输入和输出处理器</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">filter_price</span>(<span class="params">value</span>):</span></span><br><span class="line">    <span class="keyword">if</span> value.isdigit():</span><br><span class="line">        <span class="keyword">return</span> value</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Product</span>(<span class="params">scrapy.Item</span>):</span></span><br><span class="line"></span><br><span class="line">    name = scrapy.Field(</span><br><span class="line">        input_processor=MapCompose(remove_tags),</span><br><span class="line">        output_processor=Join(),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    price = scrapy.Field(</span><br><span class="line">        input_processor=MapCompose(remove_tags,filter_price),</span><br><span class="line">        output_processor=TakeFirst(),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    stock = scrapy.Field()</span><br><span class="line">    last_updated = scrapy.Field(serializer=<span class="built_in">str</span>)</span><br></pre></td></tr></table></figure></p><p>在Item Loader类中声明类似field_in和field_out的属性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ItemLoader</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ProductLoadr</span>(<span class="params">ItemLoader</span>):</span></span><br><span class="line">    default_output_processor = TakeFirst()</span><br><span class="line">    <span class="comment"># 声明输入输出处理器</span></span><br><span class="line">    <span class="comment">#输入处理器</span></span><br><span class="line">    name_in = MapCompose(unicode.title)</span><br><span class="line">    <span class="comment">#输出处理器</span></span><br><span class="line">    name_out = Join()</span><br><span class="line">    price_in =  MapCompose(unicode.price)</span><br><span class="line">    price_out = Join()</span><br><span class="line">    stock_in = MapCompose(unicode.stock)</span><br><span class="line">    stock_out = Join()</span><br><span class="line">    last_updated_in = MapCompose(unicode.last_updated)</span><br><span class="line">    last_updated_out = Join()</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><h5 id="Item-Loader-Context"><a href="#Item-Loader-Context" class="headerlink" title="Item Loader Context"></a>Item Loader Context</h5></blockquote><p>Item Loader Context是一个任意的键值对字典。能够被Item Loader中的输入输出处理器所共享。<br>可以用于调整输入输出处理器的行为。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1-Spider模块&quot;&gt;&lt;a href=&quot;#1-Spider模块&quot; class=&quot;headerlink&quot; title=&quot;1.Spider模块&quot;&gt;&lt;/a&gt;&lt;a href=&quot;#one&quot;&gt;1.Spider模块&lt;/a&gt;&lt;/h3&gt;&lt;h3 id=&quot;2-Item-Loader&quot;
      
    
    </summary>
    
      <category term="爬虫" scheme="http://example.com/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="Python" scheme="http://example.com/tags/Python/"/>
    
      <category term="爬虫" scheme="http://example.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>Python常见问题</title>
    <link href="http://example.com/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"/>
    <id>http://example.com/wiki/程序技术/Python/常见问题/</id>
    <published>2021-12-08T06:36:41.000Z</published>
    <updated>2021-12-08T06:41:02.235Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Python：常遇见的字符编码问题-TypeError-a-bytes-like-object-is-required-not-‘str’"><a href="#Python：常遇见的字符编码问题-TypeError-a-bytes-like-object-is-required-not-‘str’" class="headerlink" title="Python：常遇见的字符编码问题 TypeError: a bytes-like object is required, not ‘str’"></a>Python：常遇见的字符编码问题 TypeError: a bytes-like object is required, not ‘str’</h3><p>需要将写入的数据进行编码转换(通过encode转化)。例如:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">file.write(line.encode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Python：常遇见的字符编码问题-TypeError-a-bytes-like-object-is-required-not-‘str’&quot;&gt;&lt;a href=&quot;#Python：常遇见的字符编码问题-TypeError-a-bytes-like-object-is-
      
    
    </summary>
    
      <category term="Python" scheme="http://example.com/categories/Python/"/>
    
    
      <category term="Python" scheme="http://example.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>JavaWeb后端数据导出</title>
    <link href="http://example.com/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Java/JavaWeb/%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA/"/>
    <id>http://example.com/wiki/程序技术/Java/JavaWeb/数据导出/</id>
    <published>2021-12-06T07:07:34.071Z</published>
    <updated>2021-12-06T09:11:19.936Z</updated>
    
    <content type="html"><![CDATA[<h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>我们在进行页面开发的过程中，经常需要获取数据，以及下载数据。通常从页面下载数据有多种方式，可以生成PDF下载，可以生成Excel表格下载。<br>这里介绍这几种数据下载方式。</p><h6 id="PDF下载"><a href="#PDF下载" class="headerlink" title="PDF下载"></a>PDF下载</h6><h6 id="Excel下载"><a href="#Excel下载" class="headerlink" title="Excel下载"></a>Excel下载</h6><p>Java比较常用的Excel导入和导出技术有两种，Jakarta POI和Java Excel。Jakarta POI 是一套用于访问微软格式文档的Java API。Jakarta POI有不少组件组成，其中有用于操做Excel格式文件的HSSF和用于操做Word的HWPF，在各类组件中目前只有用于操做Excel的HSSF相对成熟。官方主页<a href="http://poi.apache.org/index.html，API文档http://poi.apache.org/apidocs/index.htmlapi。这里主要介绍Jakarta">http://poi.apache.org/index.html，API文档http://poi.apache.org/apidocs/index.htmlapi。这里主要介绍Jakarta</a> POI的用法。</p><p>首先是maven依赖<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.poi&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;poi&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;<span class="number">3.17</span>&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.poi&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;poi-ooxml&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;<span class="number">3.17</span>&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h4&gt;&lt;p&gt;我们在进行页面开发的过程中，经常需要获取数据，以及下载数据。通常从页面下载数据有多种方式，可以生成PDF下载，可以生成Excel表格下载。&lt;
      
    
    </summary>
    
      <category term="JavaEE" scheme="http://example.com/categories/JavaEE/"/>
    
    
      <category term="Java" scheme="http://example.com/tags/Java/"/>
    
      <category term="JavaWeb" scheme="http://example.com/tags/JavaWeb/"/>
    
  </entry>
  
  <entry>
    <title>Java中对JSON的操作</title>
    <link href="http://example.com/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Java/JAVA-Json/"/>
    <id>http://example.com/wiki/程序技术/Java/JAVA-Json/</id>
    <published>2021-12-01T06:56:29.125Z</published>
    <updated>2021-12-01T07:00:13.269Z</updated>
    
    <content type="html"><![CDATA[<p>JSON格式的数据在Web开发中经常作为数据请求格式或数据响应格式，所以对JSON格式的数据的操作十分重要。</p><p>常见的JSON操作主要有以下几种方式，JSON对象转化JSON字符串，JSON字符串转化JSON对象，普通数据对象转换JSON字符串，普通数据对象转换JSON对象。</p><p>常见的JSON第三方库有fastjson,gson等。这里主要以fastjson作为介绍。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;JSON格式的数据在Web开发中经常作为数据请求格式或数据响应格式，所以对JSON格式的数据的操作十分重要。&lt;/p&gt;
&lt;p&gt;常见的JSON操作主要有以下几种方式，JSON对象转化JSON字符串，JSON字符串转化JSON对象，普通数据对象转换JSON字符串，普通数据对象转换
      
    
    </summary>
    
      <category term="程序技术" scheme="http://example.com/categories/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Java" scheme="http://example.com/categories/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Java/"/>
    
    
  </entry>
  
  <entry>
    <title>抖店开发--订单导出之信息获取</title>
    <link href="http://example.com/wiki/%E6%8A%96%E5%BA%97API%E5%BC%80%E5%8F%91/%E8%AE%A2%E5%8D%95%E5%AF%BC%E5%87%BA/"/>
    <id>http://example.com/wiki/抖店API开发/订单导出/</id>
    <published>2021-12-01T04:38:34.647Z</published>
    <updated>2021-12-01T05:05:30.709Z</updated>
    
    <content type="html"><![CDATA[<p>我们可以通过订单列表查询API获取到店铺的订单列表。根据需要获取的信息和抖店API查询到的结果，做如下表格，用于获取对应参数。响应格式如下所示：</p><p><img src="/images/响应.PNG" alt="a1"></p><div class="table-container"><table><thead><tr><th style="text-align:center">名称</th><th style="text-align:center">获取方式</th><th style="text-align:center">获取结果</th></tr></thead><tbody><tr><td style="text-align:center">主订单编号</td><td style="text-align:center">order_id</td><td style="text-align:center">可获取</td></tr><tr><td style="text-align:center">选购商品</td><td style="text-align:center">product_name</td><td style="text-align:center">可获取</td></tr><tr><td style="text-align:center">商品规格</td><td style="text-align:center">order_type_desc</td><td style="text-align:center">可获取</td></tr><tr><td style="text-align:center">订单应付金额</td><td style="text-align:center">order_amount</td><td style="text-align:center">可获取</td></tr><tr><td style="text-align:center">收件人</td><td style="text-align:center">encrypt_post_receiver</td><td style="text-align:center">加密</td></tr><tr><td style="text-align:center">收件人手机号</td><td style="text-align:center">encrypt_post_tel</td><td style="text-align:center">加密</td></tr><tr><td style="text-align:center">详细地址</td><td style="text-align:center">post_addr省，市，区县，街道可获取，详细地址（encrypt_detail）</td><td style="text-align:center">部分加密</td></tr><tr><td style="text-align:center">买家留言</td><td style="text-align:center">buyer_words</td><td style="text-align:center">可获取</td></tr><tr><td style="text-align:center">订单提交时间</td><td style="text-align:center">create_time</td><td style="text-align:center">可获取</td></tr><tr><td style="text-align:center">订单状态</td><td style="text-align:center">order_status</td><td style="text-align:center">可获取</td></tr><tr><td style="text-align:center">承若发货时间</td><td style="text-align:center">appointment_ship_time</td><td style="text-align:center">可获取</td></tr><tr><td style="text-align:center">商家备注</td><td style="text-align:center">seller_words</td><td style="text-align:center">可获取</td></tr><tr><td style="text-align:center">身份证姓名</td><td style="text-align:center">user_id_info.encrypt_id_card_name</td><td style="text-align:center">加密</td></tr><tr><td style="text-align:center">身份证号</td><td style="text-align:center">user_id_info.encrypt_id_card_no</td><td style="text-align:center">加密</td></tr></tbody></table></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;我们可以通过订单列表查询API获取到店铺的订单列表。根据需要获取的信息和抖店API查询到的结果，做如下表格，用于获取对应参数。响应格式如下所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/响应.PNG&quot; alt=&quot;a1&quot;&gt;&lt;/p&gt;
&lt;div class=&quot;table
      
    
    </summary>
    
      <category term="抖店" scheme="http://example.com/categories/%E6%8A%96%E5%BA%97/"/>
    
    
      <category term="JAVA" scheme="http://example.com/tags/JAVA/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E7%88%AC%E8%99%AB/Untitled-1/"/>
    <id>http://example.com/wiki/程序技术/Python/爬虫/Untitled-1/</id>
    <published>2021-11-26T01:21:47.277Z</published>
    <updated>2021-12-10T08:50:26.005Z</updated>
    
    <content type="html"><![CDATA[< div class = "v-image__image v-image__image--cover"style = "background-image: url(&quot;https://doge.zzzmh.cn/wallpaper/origin/a58cbbffd2aa49c1b1e99990be912f30.jpg/thumbs?auth_key=1642176000-d1e0a42b4ad44111e5c25911da43d23e-0-3cd3282f8ac059d4a3573b0104c631c3&quot;); background-position: center center;" > < /div><a href = "https://doge.zzzmh.cn/wallpaper/origin/a58cbbffd2aa49c1b1e99990be912f30.jpg?response-content-disposition=attachment&amp;auth_key=1642176000-d1e0a42b4ad44111e5c25911da43d23e-0-0c38988dbe7d8b1203a85814583d2315" > < div title = "下载"class = "tool" > < i aria - hidden = "true"class = "v-icon notranslate mdi mdi-download theme--light"style = "color: rgb(47, 146, 150); caret-color: rgb(47, 146, 150);" > < /i></div > < /a>]]></content>
    
    <summary type="html">
    
      
      
        &lt; div class = &quot;v-image__image v-image__image--cover&quot;
style = &quot;background-image: url(&amp;quot;https://doge.zzzmh.cn/wallpaper/origin/a58cbbffd2a
      
    
    </summary>
    
      <category term="程序技术" scheme="http://example.com/categories/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Python" scheme="http://example.com/categories/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/"/>
    
      <category term="爬虫" scheme="http://example.com/categories/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E7%88%AC%E8%99%AB/"/>
    
    
  </entry>
  
  <entry>
    <title>selenium+Chrome(79版本以上)反爬</title>
    <link href="http://example.com/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E7%88%AC%E8%99%AB/selenium%E5%8F%8D%E7%88%AC/"/>
    <id>http://example.com/wiki/程序技术/Python/爬虫/selenium反爬/</id>
    <published>2021-11-25T08:16:51.544Z</published>
    <updated>2021-11-25T09:06:37.133Z</updated>
    
    <content type="html"><![CDATA[<h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><font size=2>&nbsp;&nbsp;&nbsp;最近在学习爬虫的过程中碰到一个奇怪的现象，当我在正常的浏览器页面访问网站的时候，能够正常访问到网页的数据。然而，当我通过selenium进行爬取网页数据的时候，出现服务器异常的提醒。正常访问能够访问，而通过selenium访问的时候却报错，这是为什么呢？通过查阅相关资料，可以得出，碰上反爬虫了。</font><blockquote><p>分析</p></blockquote><font size=2>为什么可以得出碰上反爬虫了呢？通常我们通过selenium进行爬取网页的时候，可以通过 window.navigator.webdriver检测是否使用了webdriver。我们可以试一下。在正常访问的网页中输入 window.navigator.webdriver，通常返回的是false或undifine，而当我们通过selenium访问浏览器的时候，在网页控制台输入 window.navigator.webdriver，会返回true。假如我是网页的设计者，我就会先在网页加载的时候写下这么一行代码 :</font><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (<span class="built_in">window</span>.navigator.webdriver)&#123;</span><br><span class="line">    alert(<span class="string">&quot;爬虫爬的好，牢饭吃到饱&quot;</span>)</span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">    alert(<span class="string">&quot;正常页面&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><font size=2>所以，当我们爬取网页出现上述情况的时候，很大可能浏览器存在反selenium。下面介绍一下如何解决反爬，常见的反反爬方案包含：设置参数 excludeSwitches、mitmproxy 拦截过滤、cdp 命令。</font><h3 id="2-解决方案"><a href="#2-解决方案" class="headerlink" title="2. 解决方案"></a>2. 解决方案</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;要想解决上述的问题，我们可以让window.navigator.webdriver返回false即可。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">options = webdriver.ChromeOptions()</span><br><span class="line">options.add_experimental_option(<span class="string">&#x27;excludeSwitches&#x27;</span>, [<span class="string">&#x27;enable-automation&#x27;</span>])</span><br><span class="line">driver = webdriver.Chrome(executable_path=<span class="string">&#x27;E:\codeEverment\python\chromedriver.exe&#x27;</span>, options=options) <span class="comment"># chrome驱动 </span></span><br><span class="line">                                 </span><br><span class="line"></span><br><span class="line">script = <span class="string">&quot;Object.defineProperty(navigator, &#x27;webdriver&#x27;, &#123; get: () =&gt; undefined&#125;)&quot;</span></span><br><span class="line">    </span><br><span class="line">driver.execute_cdp_cmd(<span class="string">&quot;Page.addScriptToEvaluateOnNewDocument&quot;</span>, &#123;<span class="string">&quot;source&quot;</span>: script&#125;)</span><br></pre></td></tr></table></figure><br>要见检查是否避免浏览器对webdriver的检测，可以通过selenium访问<a href="https://intoli.com/blog/not-possible-to-block-chrome-headless/chrome-headless-test.html">https://intoli.com/blog/not-possible-to-block-chrome-headless/chrome-headless-test.html</a>,如果页面显示全绿，那么就表明避免成功，反之失败。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h4&gt;&lt;font size=2&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;最近在学习爬虫的过程中碰到一个奇怪的现象，当我在正常的浏览器页面访问网站的时候，能够
      
    
    </summary>
    
      <category term="爬虫" scheme="http://example.com/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="Python" scheme="http://example.com/tags/Python/"/>
    
      <category term="爬虫" scheme="http://example.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>Python爬虫-中级</title>
    <link href="http://example.com/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E7%88%AC%E8%99%AB/Python%E7%88%AC%E8%99%AB-%E4%B8%AD%E7%BA%A7/"/>
    <id>http://example.com/wiki/程序技术/Python/爬虫/Python爬虫-中级/</id>
    <published>2021-11-22T06:44:03.511Z</published>
    <updated>2021-12-09T09:02:28.525Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-数据存储"><a href="#1-数据存储" class="headerlink" title="1.数据存储"></a><a href="#one">1.数据存储</a></h3><h3 id="2-动态文件抓取"><a href="#2-动态文件抓取" class="headerlink" title="2.动态文件抓取"></a><a href="#two">2.动态文件抓取</a></h3><h3 id="3-Web端协议分析"><a href="#3-Web端协议分析" class="headerlink" title="3.Web端协议分析"></a><a href="#three">3.Web端协议分析</a></h3><h3 id="4-数据存储"><a href="#4-数据存储" class="headerlink" title="4.数据存储"></a><a href="#one">4.数据存储</a></h3><h3 id="1-数据存储-1"><a href="#1-数据存储-1" class="headerlink" title="1.数据存储"></a><a href="#one">1.数据存储</a></h3><h6 id="1-数据存储-2"><a href="#1-数据存储-2" class="headerlink" title="1. 数据存储"></a>1.<a id="one"/> 数据存储</h6><blockquote><p>前面介绍了关于数据存储的csv,txt,json方式，这里介绍如何采用数据库保存数据，主要是了解两个数据库，关系数据库和分布式数据库。<br>即MySQL和MongoDB。</p></blockquote><h6 id="1-1-MySQL"><a href="#1-1-MySQL" class="headerlink" title="1.1 MySQL"></a>1.1 MySQL</h6><blockquote><p>Python对MySQL的操作通过pymsql模块支持。<br>Python操作MySQL的代码如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Python对MySQL的操作主要是由pymysql模块进行支持。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 主机ip(host),用户名(user),密码(passwd),数据库名称(db),端口(port),编码(charset)</span></span><br><span class="line"><span class="comment"># 打开数据库， pymysql.connect(host=,user=,passwd=,db=,port=,charset=)</span></span><br><span class="line">db = pymysql.connect(</span><br><span class="line">    host=<span class="string">&#x27;localhost&#x27;</span>,</span><br><span class="line">    user=<span class="string">&#x27;test&#x27;</span>,</span><br><span class="line">    passwd=<span class="string">&#x27;123456&#x27;</span>,</span><br><span class="line">    db=<span class="string">&#x27;votemsy&#x27;</span>,</span><br><span class="line">    charset=<span class="string">&#x27;utf-8&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 连接数据库成功后就可以操作数据库</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个游标对象</span></span><br><span class="line"><span class="comment"># 游标是系统为用户开设的一个数据缓冲区，存放SQL语句的执行结果</span></span><br><span class="line"><span class="comment"># 游标对象支持的数据库的操作</span></span><br><span class="line">cursor = db.cursor()</span><br><span class="line"></span><br><span class="line"><span class="comment">#需要执行的sql语句</span></span><br><span class="line">sql = <span class="string">&quot;&quot;</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="comment">#执行一条SQL语句</span></span><br><span class="line">    cursor.execute(sql)</span><br><span class="line">    <span class="comment">#执行多条SQL语句</span></span><br><span class="line">    cursor.executemany(sql)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#用来从结果中取一条记录，并将游标指向下一条记录</span></span><br><span class="line">    result = cursor.fetchone()</span><br><span class="line">    <span class="comment">#用来从结果中取多条记录</span></span><br><span class="line">    result = cursor.fetchmany(<span class="number">5</span>)</span><br><span class="line">    <span class="comment">#获取所有记录列表</span></span><br><span class="line">    results = cursor.fetchall()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 插入数据</span></span><br><span class="line">    data = <span class="string">&quot;&#x27;qiye&#x27;,20&quot;</span></span><br><span class="line">    cursor.execute(<span class="string">&#x27;INSERT INTO person (name,age) VALUES (%s)&#x27;</span>%data)</span><br><span class="line">    <span class="comment"># 插入数据，占位符法</span></span><br><span class="line">    cursor.execute(<span class="string">&#x27;INSERT INTO person(name,age) VALUES (%s,%s)&#x27;</span>,(<span class="string">&#x27;qiye&#x27;</span>,<span class="number">20</span>))</span><br><span class="line">    <span class="comment">#执行多条插入语句</span></span><br><span class="line">    cursor.executemany(<span class="string">&#x27;INSERT INTO person(name,age) values &#x27;</span>,[(<span class="string">&#x27;qiye&#x27;</span>,<span class="number">20</span>),(<span class="string">&#x27;jack&#x27;</span>,<span class="number">20</span>)])</span><br><span class="line"></span><br><span class="line">    <span class="comment">#查询数据</span></span><br><span class="line">    cursor.execute(<span class="string">&#x27;SELECT * FROM person&#x27;</span>)</span><br><span class="line">    res = cursor.fetchall() <span class="comment">#获取所有结果</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> res:</span><br><span class="line">        <span class="built_in">print</span>(line)</span><br><span class="line">    cursor.execute(<span class="string">&#x27;SELECT * FROM person&#x27;</span>)</span><br><span class="line">    res = cursor.fetchone() <span class="comment">#只获取一个结果</span></span><br><span class="line">    <span class="built_in">print</span>(res)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#修改和删除数据</span></span><br><span class="line">    cursor.execute(<span class="string">&#x27;UPDATE person SET name=%s WHERE id=%s&#x27;</span>,(<span class="string">&#x27;rose&#x27;</span>,<span class="number">1</span>))</span><br><span class="line">    cursor.execute(<span class="string">&#x27;DELETE FROM person where id=%s&#x27;</span>,(<span class="number">0</span>,))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 用来事务提交，只有commit之后，才会提交到数据库进行一系列的操作</span></span><br><span class="line">    db.commit()</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e :</span><br><span class="line">    <span class="comment"># 由于在执行事务的过程中，出现错误，所以回滚，恢复原来的状态，不执行操作</span></span><br><span class="line">    db.rollback()</span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    cursor.close() <span class="comment">#关闭游标</span></span><br><span class="line">    db.close() <span class="comment">#关闭一个数据库连接</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></p></blockquote><h6 id="1-2-MongoDB"><a href="#1-2-MongoDB" class="headerlink" title="1.2 MongoDB"></a>1.2 MongoDB</h6><p>MongoDB是基于分布式文件存储的数据库，用于为Web应用提供可扩展的高性能数据存储解决方案。MongoDB属于非关系数据库。</p><p>MongoDB的基本概念是文档，集合，数据库。</p><p>MongoDB中的表通过collection替代，MongoDB中的行通过document替换。MongoDB中的列通过field替换。<br>MongoDB自动将_id字段设置为主键。</p><blockquote><p>文档：文档是MongoDB中数据的基本单元（即BSON）,类似于关系数据库中的行。文档具有唯一标识_id.数据库可以自动生成。文档以key/value形式。例如: {“name”:”qiye”,”age”:24}</p></blockquote><p>文档具有如下三个特性：</p><ol><li>文档的键值对是有序的，顺序不同文档亦不同。</li><li>文档的值可以是字符串，整数，数组以及文档等类型。</li><li>文档的键是用双引号标识的字符串。以——开头的键是保留的，建议不要使用。</li><li>文档区分大小写以及值类型</li></ol><blockquote><p>集合：集合也就是一组文档，类似于数据表。集合没有固定的结构，可以在集合中插入不同格式和类型的数据（和关系表的差异）。</p></blockquote><p>集合命名不能是空字符串，不能有’\0’字符，不能以system.开头，不要包含$。</p><blockquote><p>数据库：一个MongoDB可以创建多个数据库，默认数据库是db，数据库存储在data目录。MongoDB的单个实例可以容纳多个独立的数据库。</p></blockquote><p>MongoDB的数据类型如下所示：<br><img src="/images/数据类型.PNG" alt="a11"></p><blockquote><p>插入语法：db.集合.insert(JSON格式数据)</p><p>查询语法：db.集合.find()<br><img src="/images/条件查询.PNG" alt="a12"></p></blockquote><p>对于多条件查询(and和or).<br>and通过逗号隔开。例如：db.集合.find({“key1”:{条件1},”key2”:{条件2}})</p><p>or通$or来实现。例如：db.集合.find({<br>    $or:[<br>        {key1:value1},{key2:value2}<br>    ]<br>})</p><blockquote><p>更新文档：MongoDB通过update(),save()方法来更新集合中的文档。update: db.集合.update(<br>    query,<br>    update，{<br>        upsert:boolean,<br>        multi: boolean,<br>        writeConcern:document<br>    }<br>)<br>其中：query为update的查询条件，update:update的对象和一些更新的操作符等（类似于set后面的内容），upsert（可选，如果不存在update记录，是否插入新文档）, multi（可选，是否更新全部查找出来的记录），writeConcern(可选，异常抛出级别)。<br>eg:<br>db.python.update(<br>    {‘title’,’python’},{$set:{‘title’,’python爬’}}<br>)<br>db.python.update(<br>    {‘title’,’python’},{$set:{‘title’:’python爬’}},{multi:true}<br>)</p></blockquote><p>对于save()方法，通过传入的文档替换已有的文档。db.集合.save({<br>    document{<br>        writeConcern:document<br>    }<br>})</p><blockquote><p>删除文档：MongoDB提供了remove()方法来删除文档。</p></blockquote><p>db.集合.remove(<br>    query, #删除的文档的条件<br>    {<br>        justOne:boolean, # 如果设置为true，则只删除一个文档。<br>        writeConcern:document<br>    }<br>)</p><p>删除所有title等于mongodb的文档<br>db.python.remove({‘title’:’Mongodb’})<br>如果没有查询条件，就相当于删除所有的文档。<br>python操作mongodb代码如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1. 建立连接</span></span><br><span class="line"><span class="comment">#pymogo模块使用MongoClient对象描述一个数据库客户端，创建对象的主要参数是host和port</span></span><br><span class="line"><span class="comment">#如下三种方式创建</span></span><br><span class="line">client = pymongo.MongoClient() <span class="comment"># 连接默认的主机IP和端口</span></span><br><span class="line"><span class="comment"># client = pymongo.MongoClient(&#x27;localhost&#x27;,27017) #显示指定IP和端口</span></span><br><span class="line"><span class="comment"># client = pymongo.MongoClient(&#x27;mongodb://localhost:27017/&#x27;) #采用URL格式进行连接</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#2. 获取数据库,通过MongoClient的属性方式来访问数据库</span></span><br><span class="line">db = client.test <span class="comment">#方式一</span></span><br><span class="line"><span class="comment"># db = client[&#x27;pa-pers&#x27;] #方式二</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#3. 获取一个集合</span></span><br><span class="line"><span class="comment"># collection = db.books #方式一</span></span><br><span class="line">collection = db[<span class="string">&#x27;test_one&#x27;</span>] <span class="comment">#方式二</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#插入文档操作</span></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&#x27;author&#x27;</span>:<span class="string">&#x27;mike&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;text&#x27;</span>:<span class="string">&#x27;My first book&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;tags&#x27;</span>:[<span class="string">&quot;爬虫&quot;</span>,<span class="string">&quot;python&quot;</span>,<span class="string">&quot;网络&quot;</span>],</span><br><span class="line">    <span class="string">&#x27;date&#x27;</span>: datetime.datetime.utcnow()</span><br><span class="line">&#125;</span><br><span class="line">data_id = collection.insert_one(data) <span class="comment"># 插入一条语句,返回数据的_id值,如果文件内没有_id值，则会自动添加到一文件里</span></span><br><span class="line"><span class="comment"># data_id = collection.insert_many(data) # 插入多条,数据以列表形式[&#123;&#125;,&#123;&#125;]</span></span><br><span class="line"><span class="built_in">print</span>(data_id)</span><br><span class="line"><span class="comment"># 查询语句，find_one</span></span><br><span class="line"><span class="built_in">print</span>(collection.find_one(&#123;<span class="string">&#x27;author&#x27;</span>:<span class="string">&#x27;mike&#x27;</span>&#125;))</span><br><span class="line"><span class="comment"># 通过_id查询</span></span><br><span class="line"><span class="built_in">print</span>(collection.find_one(&#123;<span class="string">&#x27;_id&#x27;</span>: ObjectId(<span class="string">&#x27;619c4dc19c281df292e7e0dd&#x27;</span>)&#125;))</span><br><span class="line"><span class="comment"># 通过find可以查询多个符合条件的文档,并且可以在括号中加入限制条件，查询多个符合条件的文档</span></span><br><span class="line"><span class="keyword">for</span> book <span class="keyword">in</span> collection.find():</span><br><span class="line">    <span class="built_in">print</span>(book)</span><br><span class="line"><span class="comment"># 统计符合条件的数目</span></span><br><span class="line"><span class="built_in">print</span>(collection.count_documents(&#123;<span class="string">&#x27;author&#x27;</span>:<span class="string">&#x27;mike&#x27;</span>&#125;))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改文档</span></span><br><span class="line">collection.update_one(&#123;<span class="string">&#x27;author&#x27;</span>:<span class="string">&#x27;mike&#x27;</span>&#125;,&#123;<span class="string">&quot;$set&quot;</span>:&#123;<span class="string">&quot;text&quot;</span>:<span class="string">&quot;python book&quot;</span>&#125;&#125;)</span><br><span class="line"><span class="comment">#删除文档</span></span><br><span class="line">collection.delete_one(&#123;<span class="string">&#x27;author&#x27;</span>:<span class="string">&#x27;mike&#x27;</span>&#125;) <span class="comment"># 如果要删除多个，delete_many</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></p><h6 id="2-动态网站抓取"><a href="#2-动态网站抓取" class="headerlink" title="2. 动态网站抓取"></a>2. <a id="two"/>动态网站抓取</h6><p>动态网页主要涉及到的技术是Ajax（Asynchoronous JavaScript and XML）和动态Html。</p><blockquote><p>Ajax技术用于网页的局部刷新，不必刷新整个页面，只需要调整局部内容，达到想要的效果，用户体验得到提升。<br>AJAX使用SOAP,XML或者支持JSON的WebService接口，在客户端利用JavaScript处理来自服务器的响应。</p></blockquote><p>SOAP:简单对象访问协议是交换数据的一种协议规范，是一种轻量的、简单的、基于XML（标准通用标记语言下的一个子集）的协议，它被设计成在WEB上交换结构化的和固化的信息。</p><blockquote><p>动态html（DHTML，Dynamic Html）,由HTML+CSS+JavaScript。</p></blockquote><p>如何从动态html页面爬取数据？有如下两种方法：</p><blockquote><ol><li>直接从JavaScript中采集加载的数据</li></ol></blockquote><h6 id="爬取影评信息"><a href="#爬取影评信息" class="headerlink" title="爬取影评信息"></a>爬取影评信息</h6><p>网页地址(www.mitime.com)</p><blockquote><ol><li>直接采集浏览器中已经加载的数据</li></ol></blockquote><p>对于直接加载渲染后的页面，可以通过PhantomJS,Selenium进行爬取。PhantomJS是基于WebKit的服务端JavaScript API，全面支持Web而无需浏览器支持，运行快，支持各种Web标准，DOM处理，CSS选择器，JSON，Cancas和SVG。PhantomJS可以用于网页自动化，网络检测，网页截屏，无界面测试等。可以把PhantomJS看成一个无界面的浏览器。</p><p>Selenium: Selenium是一个自动化测试工具，支持各种浏览器，Selenium支持浏览器驱动，可以对浏览器进行控制。</p><p>Selenium可以说是网页爬取的大杀器，可以直接模拟操作浏览器页面。下面介绍关于Selenium的使用方法。</p><blockquote><ol><li>安装配置</li></ol></blockquote><p>对于Selenium的安装配置教程可以自行百度。这里我采用的是Firefox,所以只需要两步，1. 下载selenium,通过pip指令就行。2. 下载驱动器geckodriver。通过如下代码即可使用：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.keys <span class="keyword">import</span> Keys</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="comment"># executable_path就是下载的geckodriver所在的文件路径</span></span><br><span class="line">driver  = webdriver.Firefox(executable_path=<span class="string">&#x27;E:\codeEverment\python\geckodriver\geckodriver-v0.14.0-win64\geckodriver.exe&#x27;</span>)</span><br><span class="line">driver.get(<span class="string">&#x27;http://www.baidu.com&#x27;</span>)</span><br></pre></td></tr></table></figure></p><blockquote><ol><li>元素查找</li></ol></blockquote><p>selenium的元素定位方法如下图所示：<br><img src="/images/定位方法.PNG" alt="a22"></p><blockquote><ol><li>页面操作</li></ol></blockquote><p>如何给表单填写内容？我们可以定位到表单元素，然后通过元素.send_keys填入内容。找到按钮或链接通过元素.click()模拟点击事件。如果要清除填入的内容，通过元素.clear()可以清除内容。</p><p>对于下拉选项，可以通过WebDriver提供的一个叫Select方法进行选择。</p><p>对于元素拖拽，首先要找到源元素和目的元素，然后用ActionChains类可以实现。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.keys <span class="keyword">import</span> Keys</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">driver  = webdriver.Firefox(executable_path=<span class="string">&#x27;E:\codeEverment\python\geckodriver\geckodriver-v0.14.0-win64\geckodriver.exe&#x27;</span>)</span><br><span class="line">driver.get(<span class="string">&#x27;http://www.baidu.com&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(driver.title)</span><br><span class="line"><span class="keyword">assert</span> <span class="string">u&#x27;百度&#x27;</span> <span class="keyword">in</span> driver.title</span><br><span class="line">elem = driver.find_element_by_name(<span class="string">&#x27;wd&#x27;</span>)</span><br><span class="line">elem.clear()</span><br><span class="line">elem.send_keys(<span class="string">u&#x27;网络爬虫&#x27;</span>) <span class="comment"># 给控件填写内容</span></span><br><span class="line">elem.send_keys(Keys.RETURN) <span class="comment">#这里是回车按钮</span></span><br><span class="line">time.sleep(<span class="number">3</span>)</span><br><span class="line">driver.close()</span><br><span class="line"><span class="comment"># 执行js代码</span></span><br><span class="line"><span class="comment"># 将页面拉到最低端</span></span><br><span class="line">driver.execute_script(<span class="string">&quot;window.scrollTo(0,document.body.scrollHeight);&quot;</span>)</span><br></pre></td></tr></table></figure><p>显示等待的API：<br><img src="/images/显示等待.PNG" alt="a24"></p><h6 id="3-Web端协议分析-1"><a href="#3-Web端协议分析-1" class="headerlink" title="3. Web端协议分析"></a>3.<a id="three"></a> Web端协议分析</h6><p>这里主要是关于网页登录POST分析，和验证码的解决方法。一般通过form表单填写账号密码，然后进行获取更多有效数据。</p><blockquote><p>通过POST请求登录</p></blockquote><p>一般我们都会通过构造表单数据，进行post请求。但是通常我们不仅仅提交的是账号，密码，还需要分析页面的具体提交数据，’<br>然后分析对应的数据，进行构建</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">这里主要演示了，如何通过session构建表单，然后进行表单提交。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_xsrf</span>(<span class="params">session</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    _xsrf是一个动态参数从网页中获取</span></span><br><span class="line"><span class="string">    :param Session:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    index_url = <span class="string">&#x27;http://www.baidu.com&#x27;</span></span><br><span class="line">    index_page = session.get(index_url)</span><br><span class="line">    html = index_page.text</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">session = requests.session()</span><br><span class="line">_xsrf = get_xsrf(session)</span><br><span class="line">post_url = <span class="string">&#x27;htttp://www.zhihu.com/login/phone_num&#x27;</span></span><br><span class="line">postdata = &#123; <span class="comment"># 构造post参数，这需要分析登录过程传递的参数，然后进行构建，通常不仅仅包含</span></span><br><span class="line">    <span class="comment">#账号密码选项，还有许多附加项</span></span><br><span class="line">    <span class="string">&#x27;_xsrf&#x27;</span>:_xsrf,</span><br><span class="line">    <span class="string">&#x27;password&#x27;</span>:<span class="string">&#x27;xxxxxxx&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;phone_no&#x27;</span>:<span class="string">&#x27;xxxxxxx&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;remember_me&#x27;</span>:<span class="string">&#x27;true&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">login_page = session.post(post_url,data=postdata)</span><br><span class="line">login_code = login_page.text</span><br><span class="line"><span class="built_in">print</span>(login_page.status_code)</span><br><span class="line"><span class="built_in">print</span>(login_code)</span><br></pre></td></tr></table></figure><blockquote><p>加密数据分析</p></blockquote><p>通常在网页传输的数据都会进行数据加密，然后添加一系列附加的参数到POST请求中，而且还有验证码。<br>所以这时候需要对网页进行分析。</p><blockquote><ol><li>监听网络数据，分析传送参数</li></ol></blockquote><p>通常这一过程，我们会反复登录，然后记录传送的参数以及cookie中值的变化。</p><blockquote><ol><li>分析参数的获取方式</li></ol></blockquote><p>当我们完成传送参数的分析过程的时候，就需要进一步解析参数的生成方法，然后在程序中进行生成参数，然后构建data,进行post请求。通过我们获取参数的方法有两种。一是根据网络请求分析，查看是否有参数通过API进行获取，例如有的网页的Token，Public_key等是通过API进行获取，通常我们可以在网络请求中查看。二是根据JS文件获取生成方式，通常通过API获取参数还是需要通过JS获取API需要传递的参数，通常我们从JS中获取参数是通过网页文件中搜索参数名，然后从众多包含参数名的JS文件中，分析出参数在哪个JS文件中生成，并提取出相应的生成方法。</p><p>实例代码如下(以百度网盘为例)：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">分析百度网盘的登录：</span></span><br><span class="line"><span class="string">https://passport.baidu.com/v2/api/?login  #账号验证链接</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">staticpage: https://pan.baidu.com/res/static/thirdparty/pass_v3_jump.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">charset: UTF-8</span></span><br><span class="line"><span class="string">tpl: netdisk</span></span><br><span class="line"><span class="string">subpro: netdisk_web</span></span><br><span class="line"><span class="string">apiver: v3</span></span><br><span class="line"><span class="string">codestring:</span></span><br><span class="line"><span class="string">safeflg: 0</span></span><br><span class="line"><span class="string">u: https://pan.baidu.com/disk/home</span></span><br><span class="line"><span class="string">isPhone:</span></span><br><span class="line"><span class="string">quick_user: 0</span></span><br><span class="line"><span class="string">logintype: basicLogin</span></span><br><span class="line"><span class="string">logLoginType: pc_loginBasic</span></span><br><span class="line"><span class="string">idc:</span></span><br><span class="line"><span class="string">loginmerge: true</span></span><br><span class="line"><span class="string">crypttype: 12</span></span><br><span class="line"><span class="string">mkey:</span></span><br><span class="line"><span class="string">countrycode:</span></span><br><span class="line"><span class="string">fp_uid:</span></span><br><span class="line"><span class="string">fp_info:</span></span><br><span class="line"><span class="string">loginversion: v4</span></span><br><span class="line"><span class="string">supportdv: 1</span></span><br><span class="line"><span class="string">mem_pass: on</span></span><br><span class="line"><span class="string">detect: 1</span></span><br><span class="line"><span class="string">alg: v3</span></span><br><span class="line"><span class="string">tt: 时间戳</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">POST1：</span></span><br><span class="line"><span class="string">gid: A7A60F7-2233-48D5-9CD2-B51EB721ADDF</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">username: 2891112980@qq.com</span></span><br><span class="line"><span class="string">password: OcYb7XL/QONk5nADRh+a8cPYNbCvxlMxmncxXomf94YxHenzYWxVJUnM60bNhLt6mYmL+oXC4QvAVw9ujoREPP/YrFDvJNI87jgBwE6doPvn8/9+H8gATohKY68SaIoF+G9tMh/9VIOk5OuwrmpwzvZNQAY/V7gPAjCGmTKWPu4=</span></span><br><span class="line"><span class="string">rsakey: F6qaltAhSGSTrr3LYZoF0fDJkX11XTI6</span></span><br><span class="line"><span class="string">ppui_logintime: 33785</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># ds通过viewlog可以获取</span></span><br><span class="line"><span class="string">#https://passport.baidu.com/viewlog?callback=jQuery11020116633250707733_1637907449065&amp;ak=1e3f2dd1c81f2075171a547893391274&amp;as=b052f9ad&amp;fs=aJ2zH%2BxmPIQryyPrpIPqtXmH72tk2XARV%2F09o05kx%2FNTGdkoP%2Bzms8NSTm0jdEzP%2BhyPK1KdjXobjyUVxQ9OAuiZZmmEtQpubsfgTL8NYZWy5Sj0%2Bp5a20bTVZFZ70YbQcqZadFjrJ3ompkIg8E%2BYKbzQiEl0HRdRM6o429%2BhEeW3SwAMvEl04XHGbic4703ZlUREQzEeQ5v4b840qnfHziBVVGS9jihhHliV1iPFo6%2Brdl0G1YGREEm%2FvCvr3H15pDBP346ucrwUvqF23DN2WxkjdG68I%2FlW8rMEoTmx2sRpgiVDW4FwR7GYgOinomA7XKjKIV44rACzwS5Cd53wrP%2FCxFhAH91X%2BlFr%2F5Nye6OxX7u7B5FeVe4OnMt%2BrE0cYUqWLzqAls1loOLNoKaGNKpxIjOup%2BA%2B4sulrz1K89itYMKw7MQeNERfCI32hPmJ%2FSAJz36rVBtWO1aMUq66Vu7D8QrNIQ6Ko2L1vq3UQGqO0PRKSObWKZ4leHIf7wzJAMMD2K5cIVq1iLD2k7u5RmP8TI8EYsbxA0V4X8rwdAjAnFOgE4ch%2ByNyJfCeB0FPWs6VPPb9Opd37f6ofMcxWxkjdG68I%2FlW8rMEoTmx2smMDXKV2I%2F%2FSoxAYPYNoZT7XKjKIV44rACzwS5Cd53wuq17oB3hRDHI%2F5FD8ApIUyOxX7u7B5FeVe4OnMt%2BrE0pO2CUHf3wzY2O1nRsJt429KpxIjOup%2BA%2B4sulrz1K8%2Fgsgko9%2FybfRXZevgkJ2FTJ%2FSAJz36rVBtWO1aMUq66TWu3mrKMIRru7O6yI6%2B2TDqQXhdGcWeeWbzEILv75p3aopf9L%2Fmg3TG32fE46ACdLe9EtBCfLdqwpsieMHokZYjAnFOgE4ch%2ByNyJfCeB0FTmTqlzbiE0dSKyXoaNVBrXPmvUO8LF0TrlU912rIKlNqHIWEzcVbD5iGbnqKODdJh2NjhpbaJhRLDM6hXKbFY1SOq8SbKq03JqsbsJTIds6txmXY3cvIjmhaLph06iufE2oUGZsm4FwM9L7uTYsCXEhwGeYx1aILjYgChhgGUkTgVEgyn9h0l5p8hDZ7MKqOqYtXA1fmKQ0NEKMmzZd8eYFcgQPNQxncOm63JKnGItlgXNqFT31JBhv5lC7ybrYm5BE4sZtiEjgFwbXnaseNyqG1B2V5SJLYgUj69M46RJ09vxsCO54v7u3N3p1RjZlHwgU0OC16voeLsV3dm54Q2686dcWl%2BMBcvN6nLD3oN4wZ0sE582gll4wCKKEU3HrI&amp;tk=4006KvNubQMyUKPA8V02ndLZ4ZdO%2BQjmAT7GxVnjL4Rwk6ewi356PNOQKePl0ypYx1c7Dpi5RQawPXeIhjtrwJmhbK%2B7%2FP98piTEVpjpMwlZ0Es%3D&amp;_=1637907449068</span></span><br><span class="line"><span class="string">ds: II4Fg+RtgS2K3+RJnfEduZufjjdwD4QhYQhW04uf/VRDc+fFv1h7ViPEKzfVS15/YEt/aPddzytkFKhGf1Uo/XJm6pthogRlVaD8YeC68vvNq44fKPFACQkFXnHXZ8IGNQ8yrxON2Up0DT3jOOlmAxcKlI5PS3IaOp/jshcyHK+rJaRTTxZ4IXSCKZA+yQAEcAjLtuNMmB1RjOGr5SoG6fPAF+/5zUe4JogUCHg4IFDAaLsFP9Nev6IkG0mnTXJlwdIJSe6ZaTCOplnmGC0mouUychSC9/KIyV2TJiN7kJCUQKyqbp3VAbpz+e9xfaFeqtyPv+wOE1buN6QpyyJ8NvJ4edqWVwch1ebshP8gVPM5tNlcd/YWPT2n6VFtxn5ejme5wI1wDnpCBtbXY3C0+hIJaqJ9M94QNQvK4Swn6kGkrLKCgBbkaOfOdnfdMXmUrIOkIn8vCcbx8htOM9d5kNn8DmHNt4rtCcXphfQSNvf4didhsiAzwUU0ZQ1G53CTs7xMe9NqmzIRYgs/OVr4WIqK7r5cRjuBtcWtZAGKqrOWEO9QokQM225kP47RB25Vap6P4obUOTl88p4eNEGefEhqfDr7ZBqZ8p65Ht76ndP1+q8N6dpCh7CR5hv96mkIw1jfYWlQaZvgjNF/3uxqDRSnLLf9LGJ6O2qdR6IdN3XHB5DGmpdnOiu9PWA6J1qSAfeZOiPBXIsoDM+5yTqMwthRIWZK7zJ4B2vfQrqcqYgW3C9w6KglvuIEaNBZBnjrA/QuA1PU8ZMCijyrRN+3jnS1VX6lBoxVFG9oQnRLdyTaNFQbcq1o6zdcRh/zCQMcBSvZK8tKboXFXDK6oN0zYaSBdx3rJVzzEdkAL1gA8t0nqYsFbdQIQjeFi5RjIrjvDknLZ82xw0zoid7DyZ7qYTbIGxjdYK0QdKXH/u6GM446LCkG2wnSgTEHtBWSJIacz3haMH0277hPZeyGtjstPhqrm3v6wFYqSqa0feecGEGXUlFkq1vfEb/q6CQUEoRzZREiW6pEVnFUIzNG/8mqfISDRwYFqTOjNn5HAEho8qf0G9G3zi6FZgGQ8Jq4HJ9F6I4QEagJYde/A5KmPqZNgSxJc/j/vXzQ7I565b/1F6A=</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># tk 通过viewlog可以获取</span></span><br><span class="line"><span class="string">tk: 3806qsn4na7kF+g6FX58o+wfHp0rkicKoGxH7zGNq7/Nc12RpVbL51wDca2EsymyAXLwDS2oDrrP90vY/QvHD4ykyS18NmHsVx9q95E2iL5h0T4=</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">dv: tk0.53300068179592071637896306454@ssr0MBvDUOnmgCECw2C3ptJldEClhFtpdFQJtVI3wWM6COtyEyvJzgnkEOnmgCECw2C3ptJldEClhFtpdFQJtVI3wWM6COtyUitizgnkCOnmgCECw2C3ptJldEClhFtpdFQJtVI3wWM6COvkrgn2zwtHzzupohD3Q9EClFJlhDCpX~JldlI-AHDRpKG9zjny7gFk3iukqOArpvol8hDAdFCptEJyoFJiAyGJ8vB6lVukU-nSAXtr0DBvD7gukn~t9zyvkrlupohD3Q9EClFJlhDCpX~JldyQ68KLJoXvDUzukn-vmz~tkIlupohD3Q9EClFJlhDCpX~JldyQ68KLJoXnDq-nHzytDIOtDrgnmgCECw2C3ptJldEClhFtpdFIiA1M6V~FkrznkrOnyB~ukC~nSrOArpvol8hDAdFCptEJyoFJitlBRleQ2zwtSIOny7yukClvDUOArpvol8hDAdFCptEJyoFJitlBRleQpQHBJhzGJ8XBggLzgFHhpZWhFrhn9zHuk3-CrYQ5OzuSCynyqznkBjnDIwtD3HnkIgtSnivk3-nyq-tkC~hrYL2o~I2nbuHdzB6jNBRpeG2CNB-dKuHglMRoVGRVNG6E_ArnnmzzukrHvkqOtyr-ukrlnyBOvkB~ukrlnyBOnDCyt1zjnSE_</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">fuid: FOCoIC3q5fKa8fgJnwzbE67EJ49BGJeplOzf+4l4EOvDuu2RXBRv6R3A1AZMa49I27C0gDDLrJyxcIIeAeEhD8JYsoLTpBiaCXhLqvzbzmvy3SeAW17tKgNq/Xx+RgOdb8TWCFe62MVrDTY6lMf2GrfqL8c87KLF2qFER3obJGn1imUD9LtLDAxtUQVt00ywrFuY99+6ElzcETNlw/C1xZYD5SLH8W4d36DzPMGV4JvslIL5jj8EphieYalb6sMBbKVYW5I2LDDIlDR71IUk1mpk3Y5oUBZH/dZ3rKHJ0IrTnF2Wvu65NpvARErKLH28zZNnk8BWIbmbBo8AkexVQD4TDTFi/kJX2nM5fjwUAQ7erld8wjGrZonj8gE2rhKeVRKCfkBUbih20ajKSj+uMVvFor2HqteRD2yQbHfKX9I9NLYjYxH1YiKtJ/LZAt+jDVAzZK7r2I/XoTgOvpK/GRXi7OMMoCL+ptOvZYbHZs2EmNX6yJZWrVbkhpE/nUJFiBoWKq2H4RxmaiTcdrlpoJQCEBGWNtTsmA4KXyjd88UZ+jjahyvNzJARDVgTFkgMHmv/tVUjVExnyBvjSrtrPoNvLDs45y1J1BPSrpDADEz2WH0+/bGxWLp7WNEcuhl9zrEQCVXVz1ypT0UIooITdod7rWTX1LABi9llmt7bm09SsvyWN9Io4FIQt/daeMGulvDHd3RTujFKqjbyri7OLazNV00oTLvGOs+5nIyBMdEkYaTFoTKPDDVtdCO/a2IhGao+HBbcA3Sf1GWmuogDLSCOxH8nX4hJuc0/kKmVlWYouh6qHeKBM7Z7nT+yF0MXReV/blmoigtQ9A6GiwCQZffiSKUOp1VsS+Ly9+Iupn8y+IS13BgMJv25Rgmo9qqpVhLAbfjO5WTzIDI7m0pWOYtgRQxRCPxURvzJkLg7aW9Jm4l4Bb/STxNSv23Ru6jHCU7CX0YAw0dSweJL1vvynMwJmCcF9FlItQPQ5C9mG3VH8xRyN02ywrifxP8IF10Hg3b+Vi67h2TKPZAaOJzerzLANGXGTGd0Djy9B9kQWIoYRDDc4ujl2xJR5AN3q8OeLV68X8zvK+Yv4VQDA+ZZkVu82rr07bPfAFb6iDElQPL0gOE5uGejgPswFkbgH6k2WEZafSOKRDnPOYABKWeLHdXZe2bA0DO+1FlR8qb+PmiFcZVouo5DCvlQhjRhvpItjUh2/yNfyHjnbZ1A/hRRI7BFVDtu1KaJzjx51nTN1+yRNkC71fasq+HI3zFAuiUsfI5v5JSd2kRNZE7s6bQrA5yMI31SfUDgxDrsd6lPtUU=</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">traceid: F3DFF901</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">callback: parent.bd__pcbs__7pdpae</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">time: 1637896340</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">sig: NHhDWmhlSkpXWlpoVlpTb1hZajZwaXhyYlRtSmVUM1lCRzBXa1dhOFRPWmtMZnRHd2Vmd29rdTZlUzhHKzl6eA==</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">elapsed: 2</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">shaOne: 00b653720afbeae6ff66615907b0e59e85a35757</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">rinfo: &#123;&quot;fuid&quot;:&quot;1d5264f920930df8d682b5cbac99c9e5&quot;&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">POST2：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#通过gid获取token</span></span><br><span class="line"><span class="string">#https://passport.baidu.com/v2/api/?getapi&amp;token=&amp;tpl=netdisk&amp;subpro=netdisk_web&amp;apiver=v3&amp;tt=1637908334880&amp;class=login&amp;gid=4D970C9-672F-4002-BCD8-D71F629D9C8A&amp;loginversion=v4&amp;logintype=basicLogin&amp;traceid=&amp;time=1637908335&amp;alg=v3&amp;sig=ZHpJazJocTlTeHNMNG5LUlZjdE8yTXNLMUNjMGk3QmVTUzdDajF2Y2Q0M3pjSDBNL1k4ZHN1VHJzY0g0QWdrbw%3D%3D&amp;elapsed=10&amp;shaOne=00c2bc34cb293b92b355a01af5b33dcb0c7c0e19&amp;callback=bd__cbs__elghk8</span></span><br><span class="line"><span class="string">token: 134400c212148a1ed97cd3e14a64dec4</span></span><br><span class="line"><span class="string">#</span></span><br><span class="line"><span class="string">#通过loginv4_tangram_c32acce.js可以 看到gid的生成方法</span></span><br><span class="line"><span class="string"># 通过F12查找可以得到gid的生成方法，如下所示</span></span><br><span class="line"><span class="string"># &quot;xxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx&quot;.replace(/[xy]/g, function(e) &#123;</span></span><br><span class="line"><span class="string">#                     var t = 16 * Math.random() | 0,</span></span><br><span class="line"><span class="string">#                         n = &quot;x&quot; === e ? t : 3 &amp; t | 8;</span></span><br><span class="line"><span class="string">#                     return n.toString(16)</span></span><br><span class="line"><span class="string">#                 &#125;).toUpperCase()</span></span><br><span class="line"><span class="string">gid: 14893FE-D2FB-4BBC-9D6F-353A905BD43D</span></span><br><span class="line"><span class="string">username: 18370446979</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#可以通过rsa加密</span></span><br><span class="line"><span class="string">#通过F12找到password的生成方法</span></span><br><span class="line"><span class="string"># password: function() &#123; e._getRSA(function(t) &#123; e.RSA = t.RSA, e.rsakey = t.rsakey &#125;) &#125;</span></span><br><span class="line"><span class="string">password: qnmL7K9NK7pvaHhlmV/FVFjJEJsUUCmPs+aRr0jWLPSe9y033E9268hTdWCZoGGSz3fV2Q5BN7szAXd8vpH/I4BzNI0Jd72MXb1pkNEXeUnuxEy7xDPGshCWThTIID2PcCydW0dWrs/GrVjTsiwKFrOuig8uWSeJ5F5RVS2ioMc=</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">rsakey: kC02XvnT7I6uMux9cYbgVbsVqcat7gCK</span></span><br><span class="line"><span class="string">#在loginv4_tangram_c32acce.js文件可以找到ppui的生成方法，没啥影响，可以用相同的ppui</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ppui_logintime: 59338</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ds: DJv1I2ZMYFt4VNJGrEieRzX+fTxEGqp5KEKwP82Eqs0OwC/0nDO0AaGbSnOx4gLBgEwFUlmknWtM8w70bR6651jBTWR3RrN6M8athvLv0qjIh/uqJXSiudqxzvNbI8JrbRQi/L6z0yapH8OzFzgtjkCbQnKIIseJ5YN7pXQNzzfsLmwRSboSxSIMh7H+mNWlm7Jv6bipWb2Ef+mULPz+HJcsYAuYX7ZSRej5qKjg4LilTqk77vHywOzTdYX43QwjBa95tTsSQl3UdoyTyTSoP3+MI39NMnpfvc31ubL1aYBzIwtGTKBGQ6r9IMPO1/apOChCY8Ukvh5YsbuEPVZhHNrWGbwQxmPZGfwnHLxk+a4fe8Swz2GQYZhJWXhGX1zomphghvSfI0Xr0C3ofNTFL5YQ71CiRAzbbmQ/jtEHblVptfsMcO06PhUuRCioIIrvPK3f5pSnKweaOreL/stiDNRDmTc/TFc/zLbPufGyD5xEZm3ptEBPg9JO1kZVGX9hEjqGlJPTvnmgyiTZbqqYMGuU+teFEfSezySS7QbzHrNdJWklVjPbX4MaXF0vQwV3QvJ2BYaIJXbUbmi2N+MCb6uuhcCUzRXcvQcCFN+nCi8JV0rZbi8qRA6qogqITSmcoX+C2ebWRCqd1Bta5oZQDFnlNY8P1//P9TI67UuT8f3rpPwKHtCV94QXnYOPyXhxoFShURm0wEXyWfe6k74eCKJzF9WHKgqjvWNBU4oxh51ptfsMcO06PhUuRCioIIrvRnbBncAl/l2oYpW1Tl+s9vX6rw3p2kKHsJHmG/3qaQjDWN9haVBpm+CM0X/e7GoNFKcst/0sYno7ap1Hoh03dccHkMaal2c6K709YDonWpJOuWUh5Btk18pp2ofQaQue++3sNK8B3l22xvtu69xAcBbcL3DoqCW+4gRo0FkGeOsD9C4DU9TxkwKKPKtE37eOdLVVfqUGjFUUb2hCdEt3JNo0VBtyrWjrN1xGH/MJAxwFK9kry0puhcVcMrqg3TNhpIF3HeslXPMR2QAvWADy3SepiwVt1AhCN4WLlGMiuO/EHjpcfKHlM/uGqUpTxlzFg6wRAvrcujI33KeY139x4zosKQbbCdKBMQe0FZIkhpybzWnTPAJbZ2HlksG4LzZfZZxOv3Rz8OzebBbGZY2cKHzOIWo49PxA+Q/fgOWSMCg+0HmDAKY5njRPYRTBGiWmrU3+ErtPH77j3x0d0oaItNhgp6PrWJ92dgGBZTxabg4LrS+iGvesD1QIbG1EpOUu6EGco5bp1s9+m48R0KveFA==</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">tk: 5886+r0RsngU7eH85qinjvKq/Ov8cTqi3758E9sFclzWzRrsTzYvBtjqRuohenHcu9EkNtVwd1ZSl1bUdta7LJyUF+N0t3lElPs4Qk2Y4E3v6mM=</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">dv: tk0.076573147928699071637897079952@ssm0MCo4JL8mcC6CyrCStv9Xw6CXhUvtwUR9v3JSyEOGCLvj6ZvT-c8k6L8mcC6CyrCStv9Xw6CXhUvtwUR9v3JSyEOGCLvjKeo9-yoH--0tDh4SRH6CXU9Xh4CtlZ9XwXJiAe4atYFH-~ok6cUk2-8e--0tDh4SRH6CXU9Xh4CtlZ9XwXJiAe4atYFH-x8k6yUkSi0kqLA2toDXph4AwUCtv69jDU9~AjF9poKGX30k7eo4hltm0otok7-0k8~ve-Xv12e0tDh4SRH6CXU9Xh4CtlZ9XwjRGpYI9Dlo46e0k8Xve-Xvj8Z0tDh4SRH6CXU9Xh4CtlZ9XwjRGpYI9Dlo4KX0k5x8e-Xok6y0tDh4SRH6CXU9Xh4CtlZ9XwaO~pYUkSi8e-e8j8Lv16e8mcC6CyrCStv9Xw6CXhUvtwUR9v3JSyEOGAlokKe0kSX0k2e812e0r-_CllI~lI~vtMEhImi8H-e0kSiBmpRsL-01q~v1C~8j2ZvjSeokKyo4q~84Kjvj7yvjq~o4SX87__imVIrDZJr8P0ew-KGxgKatWFrCgKiwY0ecXOaD3Fa3gFG6_zmp8m--0k2ev18Lvj2i0k2X8jKLokKZ0k2X8jKL84CjvB-x816_</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">fuid: FOCoIC3q5fKa8fgJnwzbE67EJ49BGJeplOzf+4l4EOvDuu2RXBRv6R3A1AZMa49I27C0gDDLrJyxcIIeAeEhD8JYsoLTpBiaCXhLqvzbzmvy3SeAW17tKgNq/Xx+RgOdb8TWCFe62MVrDTY6lMf2GrfqL8c87KLF2qFER3obJGn1imUD9LtLDAxtUQVt00ywrFuY99+6ElzcETNlw/C1xZYD5SLH8W4d36DzPMGV4JvslIL5jj8EphieYalb6sMBbKVYW5I2LDDIlDR71IUk1mpk3Y5oUBZH/dZ3rKHJ0IrTnF2Wvu65NpvARErKLH28zZNnk8BWIbmbBo8AkexVQD4TDTFi/kJX2nM5fjwUAQ7erld8wjGrZonj8gE2rhKeVRKCfkBUbih20ajKSj+uMVvFor2HqteRD2yQbHfKX9I9NLYjYxH1YiKtJ/LZAt+jDVAzZK7r2I/XoTgOvpK/GRXi7OMMoCL+ptOvZYbHZs2EmNX6yJZWrVbkhpE/nUJFiBoWKq2H4RxmaiTcdrlpoJQCEBGWNtTsmA4KXyjd88UZ+jjahyvNzJARDVgTFkgMHmv/tVUjVExnyBvjSrtrPoNvLDs45y1J1BPSrpDADEz2WH0+/bGxWLp7WNEcuhl9zrEQCVXVz1ypT0UIooITdod7rWTX1LABi9llmt7bm09SsvyWN9Io4FIQt/daeMGulvDHd3RTujFKqjbyri7OLazNV00oTLvGOs+5nIyBMdEkYaTFoTKPDDVtdCO/a2IhGao+HBbcA3Sf1GWmuogDLSCOxH8nX4hJuc0/kKmVlWYouh6qHeKBM7Z7nT+yF0MXReV/blmoigtQ9A6GiwCQZffiSKUOp1VsS+Ly9+Iupn8y+IS13BgMJv25Rgmo9qqpVhLAbfjO5WTzIDI7m0pWOYtgRQxRCPxURvzJkLg7aW9Jm4l4Bb/STxNSv23Ru6jHCU7CX0YAw0dSweJL1vvynMwJmCcF9FlItQPQ5C9mG3VH8xRyN02ywrifxP8IF10Hg3b+Vi67h2TKPZAaOJzerzLANGXGTGd0Djy9B9kQWIoYRDDc4ujl2xJR5AN3q8OeLV68X8zvK+Yv4VQDA+ZZkVu82rr07bPfAFb6iDElQPL0gOE5uGejgPswFkbgH6k2WEZafSOKRDnPOYABKWeLHdXZe2bA0DO+1FlR8qb+PmiFcZVouo5DCvlQhjRhvpItjUh2/yNfyHjnbZ1A/hRRI7BFVDtu1KaJzjx51nTN1+yRNkC71fasq+HI3zFAuiUsfI5v5JSd2kRNZE7s6bQrA5yMI31SfUDgxDrsd6lPtUU=</span></span><br><span class="line"><span class="string">traceid: B67AC501</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#baidu.phoenix._setIconsStatus</span></span><br><span class="line"><span class="string">#只是标识，不参与校验</span></span><br><span class="line"><span class="string">&quot;bd__cbs__&quot; + Math.floor(Math.random() * 2147483648).toString(36)</span></span><br><span class="line"><span class="string">callback: parent.bd__pcbs__kk48fu</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">time: 1637897139</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">alg: v3</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">sig: cFJLQ0ZzMWo2VmFaaUVXMFJQbk94QUhuUWFLeEVkNFllM2tjOVhFQ1hOcEg2UC9PUUltR2l2SnZOcFpQNi9FTw==</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">elapsed: 5</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">shaOne: 00a72749f19999931e2653a554991baf3f874f7b</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">rinfo: &#123;&quot;fuid&quot;:&quot;1d5264f920930df8d682b5cbac99c9e5&quot;&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    一般我们对登录附加信息的获取，都会通过多个POST请求进行比较，得出不变的数据和变动的数据，</span></span><br><span class="line"><span class="string">    然后进行分析处理。</span></span><br><span class="line"><span class="string">    1. 获取表单提交参数</span></span><br><span class="line"><span class="string">    2. 确定参数获取方式-&gt;可以通过F12的内容查找，然后搜索指定参数名，找到对应的代码，分析数据如何生成的</span></span><br><span class="line"><span class="string">    3. 构建post请求，进行登录</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> base64</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> Crypto.PublicKey <span class="keyword">import</span> RSA</span><br><span class="line"><span class="keyword">from</span> Crypto.Cipher <span class="keyword">import</span> PKCS1_v1_5</span><br><span class="line"><span class="keyword">import</span> PyV8 <span class="comment">#pyv8引擎，可以直接执行js代码，不用转换为python语言</span></span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> quote</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    s = requests.Session()</span><br><span class="line">    s.get(<span class="string">&#x27;http://yun.baidu.com&#x27;</span>)</span><br><span class="line">    js = <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    function callback()&#123;</span></span><br><span class="line"><span class="string">        return &quot;bd__cbs__&quot; + Math.floor(Math.random() * 2147483648).toString(36) ; </span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    function gid()&#123;</span></span><br><span class="line"><span class="string">    return &quot;xxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx&quot;.replace(/[xy]/g, function(e) &#123;</span></span><br><span class="line"><span class="string">                    var t = 16 * Math.random() | 0,</span></span><br><span class="line"><span class="string">                        n = &quot;x&quot; === e ? t : 3 &amp; t | 8;</span></span><br><span class="line"><span class="string">                    return n.toString(16)</span></span><br><span class="line"><span class="string">                &#125;).toUpperCase()</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    ctxt = PyV8.JsContext()</span><br><span class="line">    ctxt.enter()</span><br><span class="line">    ctxt.<span class="built_in">eval</span>(js)</span><br><span class="line">    <span class="comment">### 获取gid</span></span><br><span class="line">    gid = ctxt.<span class="built_in">locals</span>.gid()</span><br><span class="line">    <span class="comment">### 获取callback</span></span><br><span class="line">    callback = ctxt.<span class="built_in">locals</span>.callback()</span><br><span class="line">    <span class="comment">### 获取token,根据需要的参数，传入相应参数，返回对应的token</span></span><br><span class="line">    tokenUrl = <span class="string">&quot;#https://passport.baidu.com/v2/api/?getapi&amp;token=&amp;tpl=netdisk&amp;subpro=netdisk_web&amp;apiver=v3&amp;tt=1637908334880&amp;class=login&amp;gid=4D970C9-672F-4002-BCD8-D71F629D9C8A&amp;loginversion=v4&amp;logintype=basicLogin&amp;traceid=&amp;time=1637908335&amp;alg=v3&amp;sig=ZHpJazJocTlTeHNMNG5LUlZjdE8yTXNLMUNjMGk3QmVTUzdDajF2Y2Q0M3pjSDBNL1k4ZHN1VHJzY0g0QWdrbw%3D%3D&amp;elapsed=10&amp;shaOne=00c2bc34cb293b92b355a01af5b33dcb0c7c0e19&amp;callback=bd__cbs__elghk8&quot;</span></span><br><span class="line">    token_response = s.get(tokenUrl)</span><br><span class="line">    pattern = re.<span class="built_in">compile</span>(<span class="string">r&#x27;&quot;token&quot;\s*:\s*&quot;(\w+)&quot;&#x27;</span>)</span><br><span class="line">    match = pattern.search(token_response.text)</span><br><span class="line">    <span class="keyword">if</span> match:</span><br><span class="line">        token = match.group(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> Exception</span><br><span class="line">    <span class="comment">#### 获取callback</span></span><br><span class="line">    callback2 = ctxt.<span class="built_in">locals</span>.callback()</span><br><span class="line">    <span class="comment">#### 获取rsakey和pubkey</span></span><br><span class="line">    rsaUrl = <span class="string">&quot;&quot;</span></span><br><span class="line">    response = s.get(rsaUrl)</span><br><span class="line">    key = response.text <span class="comment">#匹配搜索key</span></span><br><span class="line">    pubkey = response.text</span><br><span class="line">    <span class="comment">####加密password</span></span><br><span class="line">    password = <span class="string">&#x27;&#x27;</span> <span class="comment">#自己的密码</span></span><br><span class="line">    pubkey = pubkey.replace(<span class="string">&#x27;\\n&#x27;</span>,<span class="string">&#x27;\n&#x27;</span>).replace(<span class="string">&#x27;\\&#x27;</span>,<span class="string">&#x27;&#x27;</span>)<span class="comment">#处理pubkey</span></span><br><span class="line">    rsakey = RSA.importKey(pubkey) <span class="comment">#百度网盘通过的是RSA加密</span></span><br><span class="line">    cipher = PKCS1_v1_5.new(rsakey)</span><br><span class="line">    password = base64.b64decode(cipher.encrypt(password)) <span class="comment">#加密</span></span><br><span class="line">    <span class="comment">###获取callback</span></span><br><span class="line">    callback3 = ctxt.<span class="built_in">locals</span>.callback()</span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">&quot;charset&quot;</span>: <span class="string">&#x27;UTF - 8&#x27;</span>,</span><br><span class="line">        <span class="string">&quot;tpl&quot;</span>: <span class="string">&quot;netdisk&quot;</span>,</span><br><span class="line">        <span class="string">&quot;subpro&quot;</span>: <span class="string">&quot;netdisk_web&quot;</span>,</span><br><span class="line">        <span class="string">&quot;apiver&quot;</span>: <span class="string">&quot;v3&quot;</span>,</span><br><span class="line">        <span class="string">&quot;codestring&quot;</span>:<span class="string">&quot;&quot;</span>,</span><br><span class="line">            <span class="string">&quot;safeflg&quot;</span>: <span class="number">0</span>,</span><br><span class="line">        <span class="string">&quot;u&quot;</span>: <span class="string">&#x27;https: // pan.baidu.com / disk / home&#x27;</span>,</span><br><span class="line">        <span class="string">&quot;isPhone&quot;</span>:<span class="string">&quot;&quot;</span>,</span><br><span class="line">        <span class="string">&quot;quick_user&quot;</span>: <span class="number">0</span>,</span><br><span class="line">        <span class="string">&quot;logintype&quot;</span>: <span class="string">&quot;basicLogin&quot;</span>,</span><br><span class="line">        <span class="string">&quot;logLoginType&quot;</span>: <span class="string">&quot;pc_loginBasic&quot;</span>,</span><br><span class="line">        <span class="string">&quot;idc&quot;</span>:<span class="string">&quot;&quot;</span>,</span><br><span class="line">        <span class="string">&quot;loginmerge&quot;</span>: <span class="literal">True</span>,</span><br><span class="line">        <span class="string">&quot;crypttype&quot;</span>: <span class="number">12</span>,</span><br><span class="line">        <span class="string">&quot;mkey&quot;</span>:<span class="string">&quot;&quot;</span>,</span><br><span class="line">        <span class="string">&quot;countrycode&quot;</span>:<span class="string">&quot;&quot;</span>,</span><br><span class="line">        <span class="string">&quot;fp_uid&quot;</span>:<span class="string">&quot;&quot;</span>,</span><br><span class="line">        <span class="string">&quot;fp_info&quot;</span>:<span class="string">&quot;&quot;</span>,</span><br><span class="line">        <span class="string">&quot;loginversion&quot;</span>: <span class="string">&quot;v4&quot;</span>,</span><br><span class="line">        <span class="string">&quot;supportdv&quot;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="string">&quot;mem_pass&quot;</span>: <span class="string">&quot;on&quot;</span>,</span><br><span class="line">        <span class="string">&quot;detect&quot;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="string">&quot;alg&quot;</span>: <span class="string">&quot;v3&quot;</span>,</span><br><span class="line">        <span class="string">&quot;gid&quot;</span>:gid,</span><br><span class="line">        <span class="string">&#x27;callback&#x27;</span>:callback3,</span><br><span class="line">        <span class="string">&#x27;token&#x27;</span>:token,</span><br><span class="line">        <span class="string">&#x27;password&#x27;</span>:password</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">#构建好了表单数据，然后就可以进行页面登录了</span></span><br><span class="line">    post1_response = s.post(<span class="string">&#x27;https://passport.baidu.com/v2/api/?login&#x27;</span>,data=data)</span><br><span class="line">    <span class="comment">#如果页面还有其它信息需要验证，在后面进行处理即可</span></span><br><span class="line">    <span class="comment">#比如需要滑块验证等</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></p><blockquote><p>验证码问题</p></blockquote><p>从上面的POST表单构建引出的一个新的问题，就是关于验证码的问题，通常验证码有三种形式，一种是在post表单中的图片的验证码，一种是根据图片点击相应的区域，一种是滑块验证。</p><blockquote><blockquote><p>IP代理</p></blockquote></blockquote><p>同一个IP频繁访问网页，可能会导致IP被封禁或者需要输入验证码验证是否是真人。解决的方法可以通过加大爬虫的延时，让网页觉得你就是真人在浏览网页，毕竟通过爬虫访问网页的频率过快，容易被识别，然而通过减慢爬虫时延带来的另一个问题就是效率的降低。更好的一种做法的更换IP进行访问。</p><p>IP代理的方式可以通过设置request的proxies参数进行设置。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 代理设置，使用代理Proxy,可以为任意请求方法通过设置proxies参数来配置单个请求</span></span><br><span class="line">   proxies = &#123;</span><br><span class="line">       <span class="string">&quot;http&quot;</span>: <span class="string">&quot;http://0.10.1.10:3128&quot;</span>,</span><br><span class="line">       <span class="string">&quot;https&quot;</span>: <span class="string">&quot;http://10.10.1.10:1080&quot;</span>,</span><br><span class="line">       <span class="comment"># &quot;http&quot;:&quot;http://user:pass@10.10.1.10:3128&quot; #这是代理中身份认证的用户名和密码，来设置代理</span></span><br><span class="line">   &#125;</span><br><span class="line">   requests.get(<span class="string">&quot;www.baidu.com&quot;</span>, proxies=proxies)  <span class="comment"># 设置代理ip</span></span><br></pre></td></tr></table></figure><br>我们已经知道通过request可以设置代理IP，那么如何获取代理IP？有如下几种方式：</p><blockquote><ol><li><p>VPN<br>国内和国外很多厂商提供VPN服务，可以分配不同的网络线路，并可以自动更换IP，实时性很高，速度很快。但是价格一般较高，适合商用。</p></li><li><p>IP代理池<br>一些厂商将很多IP做成代理池，提供API接口，允许用户使用程序调用。稳定的IP代理池费用也是较高的，所以不适合个人学习使用。</p></li><li><p>ADSL宽带拨号<br>也就是拨号上网。ADSL每次断开重新连接时会分配新的IP地址，爬虫可以利用这个原理更换IP。但是更换IP需要断开重连，所以效率并不高，适用于实时性不高的场景。<br>Windows下通过rasdial操作可以进行拨号，Python通过os.system来执行命令行语句，进行拨号操作。代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">作为示例进行演示，如何通过ADSL进行拨号和断开</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">g_adsl_account = &#123;</span><br><span class="line">    <span class="string">&quot;name&quot;</span>:<span class="string">&quot;adsl&quot;</span>,</span><br><span class="line">    <span class="string">&quot;username&quot;</span>:<span class="string">&quot;xxxxxxxx&quot;</span>,</span><br><span class="line">    <span class="string">&quot;password&quot;</span>:<span class="string">&quot;xxxxxxxx&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Adsl</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.name = g_adsl_account[<span class="string">&#x27;name&#x27;</span>]</span><br><span class="line">        self.username = g_adsl_account[<span class="string">&#x27;username&#x27;</span>]</span><br><span class="line">        self.password = g_adsl_account[<span class="string">&#x27;password&#x27;</span>]</span><br><span class="line">    <span class="comment">#修改asdl</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_adsl</span>(<span class="params">self,account</span>):</span></span><br><span class="line">        self.name = account[<span class="string">&#x27;name&#x27;</span>]</span><br><span class="line">        self.username = account[<span class="string">&#x27;username&#x27;</span>]</span><br><span class="line">        self.password = account[<span class="string">&#x27;password&#x27;</span>]</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        拨号连接</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">connect</span>(<span class="params">self</span>):</span></span><br><span class="line">        cmd_str = <span class="string">&quot;rasdlal %s %s %s&quot;</span>%(self.name,self.username,self.password)</span><br><span class="line">        os.system(cmd_str)<span class="comment">#调用windows的控制台，通过rasdlal进行拨号</span></span><br><span class="line">        time.sleep(<span class="number">5</span>)</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        断开连接</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">disconnect</span>(<span class="params">self</span>):</span></span><br><span class="line">        cmd_str = <span class="string">&quot;rasdial %s / disconnect&quot;</span>%self.name</span><br><span class="line">        os.system(cmd_str)</span><br><span class="line">        time.sleep(<span class="number">5</span>)</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        重新拨号</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reconnect</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.disconnect()</span><br><span class="line">        self.connect()</span><br></pre></td></tr></table></figure></li></ol></blockquote><p>如果我们想要找到一些免费的IP代理，可以在各个网站寻找免费的IP，然后对IP去重，检测代理有效性等操作，存放到数据库中，通过接口获取免费的IP，构建自己的IP池。</p><blockquote><blockquote><p>图片验证码识别</p></blockquote></blockquote><p>我们在浏览器登录的时候，常常需要输入图片验证码，这里给出几种方法解决图片验证码的问题。</p><blockquote><ol><li>Cookie绕过登录，我们在浏览网站的时候，常常会保留登录信息，下次登录就不要进行登录，通过Cookie即可登录。所以我们可以获取登录后的Cookie，然后设置Cookie，绕过登录。可以获取多个Cookie，构建Cookie池，绕过登录验证。示例代码如下。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    通过已经登陆过的Cookie进行通过Cookie进行登录。</span></span><br><span class="line"><span class="string">    我们可以在模拟登录成功后，将session的值保存到本地，后续可以通过cookie进行登录。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> requests.cookies <span class="keyword">import</span> cookiejar_from_dict</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_session</span>(<span class="params">session</span>):</span></span><br><span class="line">    <span class="comment">#将session写入文件,session.txt</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;session.txt&#x27;</span>,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        pickle.dump(session.headers,f) <span class="comment">#写入头</span></span><br><span class="line">        pickle.dump(session.cookes.get_dict(),f)<span class="comment">#写入Cookie值</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;将sesssion写入文件:session.txt&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_session</span>():</span></span><br><span class="line">    <span class="comment">#加载session</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;session.txt&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        headers = pickle.load(f)</span><br><span class="line">        cookies = pickle.load(f)</span><br><span class="line">        <span class="keyword">return</span> headers,cookies</span><br><span class="line">session  = requests.Session()</span><br><span class="line">session.headers = <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36&#x27;</span></span><br><span class="line">dicts = <span class="built_in">dict</span>()</span><br><span class="line">dicts[<span class="string">&#x27;BDORZ&#x27;</span>] = <span class="string">&#x27;FFFB88E999055A3F8A630C64834BD6D0&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;PSINO&#x27;</span>] = <span class="string">&#x27;7&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;BDRCVFR[hpwYTbhBfiY]&#x27;</span>] = <span class="string">&#x27;9xWipS8B-FspA7EnHc1QhPEUf&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;BDUSS_BFESS&#x27;</span>] = <span class="string">&#x27;XFOcmlGQVhEdUZjSnJiWmJmbVgza35YV0RvZktEUEdkUXgyYkJ4S01uOER0OHRoSVFBQUFBJCQAAAAAAAAAAAEAAADprZrnsrvLxrnp1MYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMqpGEDKqRhW&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;BDUSS&#x27;</span>] = <span class="string">&#x27;XFOcmlGQVhEdUZjSnJiWmJmbVgza35YV0RvZktEUEdkUXgyYkJ4S01uOER0OHRoSVFBQUFBJCQAAAAAAAAAAAEAAADprZrnsrvLxrnp1MYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMqpGEDKqRhW&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;BAIDUID_BFESS&#x27;</span>] = <span class="string">&#x27;E8BBAF114F9097C4849493D68A677EC2:FG=1&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;HMACCOUNT_BFESS&#x27;</span>] = <span class="string">&#x27;13391551711E4651&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;MCITY&#x27;</span>] = <span class="string">&#x27;-%3A&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;BAIDUID&#x27;</span>] = <span class="string">&#x27;A02BD18D5032DA5E3DA0339468C7AE42:FG=1&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;__yjs_duid&#x27;</span>] = <span class="string">&#x27;1_2b5acc51d9eef8efeada14364c2710b71633588836061&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;c_dl_fref&#x27;</span>] = <span class="string">&#x27;https://blog.csdn.net/kaida1234/article/details/89553115&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;Hm_lpvt_6bcd52f51e9b3dce32bec4a3997715ac&#x27;</span>] = <span class="string">&#x27;1638500494&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;c_page_id&#x27;</span>] = <span class="string">&#x27;default&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;c_first_page&#x27;</span>] = <span class="string">&#x27;https%3A//i.csdn.net/&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;log_Id_pv&#x27;</span>] = <span class="string">&#x27;1556&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;delPer&#x27;</span>] = <span class="string">&#x27;0&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;TY_SESSION_ID&#x27;</span>] = <span class="string">&#x27;1e66f339-636d-4633-845e-6afde0a1d0f8&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;PSTM&#x27;</span>] = <span class="string">&#x27;1633401440&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;dc_sid&#x27;</span>] = <span class="string">&#x27;2cee0d889d6dbf50e0ba642d35372f04&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;dc_session_id&#x27;</span>] = <span class="string">&#x27;10_1638499930521.206489&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;log_Id_click&#x27;</span>] = <span class="string">&#x27;664&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;c_segment&#x27;</span>] = <span class="string">&#x27;12&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;c_first_ref&#x27;</span>] = <span class="string">&#x27;cn.bing.com&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;ab_sr&#x27;</span>] = <span class="string">&#x27;1.0.1_MzcxMWQ4NzQzNGYyZWRmZmJhNTA2NTdiNDY5Yjc2M2I3NTg2MThlZjg4OGRhZWVjNGExYmEwYzljODc5ZmExNmJhM2RkYWQxOTI5NzcyZjhiZWM5MDExNmU3ODZjNTcxMGY1MDg0ZTA1MmE3MTc4MWZjYTcxYjQ0ODg5OGVjY2JiZDgyZjlkYjk5Nzg4M2Q4OTVkYzRiMDIwZWJkM2FmOQ==&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;firstDie&#x27;</span>] = <span class="string">&#x27;1&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;log_Id_view&#x27;</span>] = <span class="string">&#x27;4444&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;c_dl_um&#x27;</span>] = <span class="string">&#x27;-&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;AU&#x27;</span>] = <span class="string">&#x27;5E7&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;c_dl_rid&#x27;</span>] = <span class="string">&#x27;1638195457309_383576&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;H_PS_PSSID&#x27;</span>] = <span class="string">&#x27;&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;uuid_tt_dd&#x27;</span>] = <span class="string">&#x27;10_37481785600-1633532465546-630652&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;Hm_up_6bcd52f51e9b3dce32bec4a3997715ac&#x27;</span>] = <span class="string">&#x27;%7B%22islogin%22%3A%7B%22value%22%3A%221%22%2C%22scope%22%3A1%7D%2C%22isonline%22%3A%7B%22value%22%3A%221%22%2C%22scope%22%3A1%7D%2C%22isvip%22%3A%7B%22value%22%3A%220%22%2C%22scope%22%3A1%7D%2C%22uid_%22%3A%7B%22value%22%3A%22weixin_43387852%22%2C%22scope%22%3A1%7D%7D&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;c_dl_prid&#x27;</span>] = <span class="string">&#x27;1638100826971_946707&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;Hm_lvt_e5ef47b9f471504959267fd614d579cd&#x27;</span>] = <span class="string">&#x27;1637833430&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;Hm_ct_6bcd52f51e9b3dce32bec4a3997715ac&#x27;</span>] = <span class="string">&#x27;6525*1*10_37481785600-1633532465546-630652!5744*1*weixin_43387852&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;BT&#x27;</span>] = <span class="string">&#x27;1633859763611&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;HMACCOUNT&#x27;</span>] = <span class="string">&#x27;13391551711E4651&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;Hm_lvt_6bcd52f51e9b3dce32bec4a3997715ac&#x27;</span>] = <span class="string">&#x27;1638500140,1638500349,1638500394,1638500403&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;p_uid&#x27;</span>] = <span class="string">&#x27;U010000&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;UN&#x27;</span>] = <span class="string">&#x27;weixin_43387852&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;__gads&#x27;</span>] = <span class="string">&#x27;ID=20d2edb2ecff0dd8-2294b66f51cc00dd:T=1633682976:RT=1633682976:S=ALNI_MZ4Wd5yAdGLxFPr5rHe4LQE0aLwJw&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;BIDUPSID&#x27;</span>] = <span class="string">&#x27;FBAA203ACF6D45F80BC31F3396736AD0&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;dc_tos&#x27;</span>] = <span class="string">&#x27;r3ir2m&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;c_ref&#x27;</span>] = <span class="string">&#x27;https%3A//i.csdn.net/&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;ssxmod_itna&#x27;</span>] = <span class="string">&#x27;Yq+xBDuQG=YUGkDzxAhYo=mxWqY5Y3K3qoiQD/YBmDnqD=GFDK40oE7bD7mKn5BAuDeWxrGhuqWKFixPmaAiDOh31A+=0iEdDU4i8DCTrPoD4fKGwD0eG+DD4DWDmW7DnxAQDjxGpycuTXBDi3Dbg=Di4D+zd=DmqG0DDUH/4G2D7Uy8ivyWld52ubMiir4YB=DjqTD/+qFMWRFsa5VWjnTu44DC2v1oi519poqYAiWbqGybKGunqXV4uR1pq0Z3j5vKG4oBrdoBiPet0q3ngxU6GDPARCztP4KD++P7g+dBr5DGRwx3wDxD&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;UserToken&#x27;</span>] = <span class="string">&#x27;885ba7040ab64148b8d10b4450fcc279&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;UserNick&#x27;</span>] = <span class="string">&#x27;%E5%BD%92%E6%9D%A5%E7%A9%BA%E7%A9%BA&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;BDRCVFR[C0p6oIjvx-c]&#x27;</span>] = <span class="string">&#x27;Ble67U-OKLffjRLnjc3nW6kg1IxpA7E&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;ssxmod_itna2&#x27;</span>] = <span class="string">&#x27;Yq+xBDuQG=YUGkDzxAhYo=mxWqY5Y3K3qoiG9toFxBwm47pxUxBa4Hq7GFGfoiDhPizeG7q5h7Mt7khdzCG2O7=IYjr6oTN9ebmgXvejbDDQt5Uljyh7yEuBiEMSIhcGRVeRAB+Er04T2YpCHxTHtYBrV15C0eviq+WkT8vmqGKrtFG=Mo7sk/ntYiGQI87s1SYx1=TpeYcD5OALP3OQgpKTRGpC8bLiPSMTSCodV1ddSeu1P99Niqq8dQDd8+mcI+I5FHuv=yFBy=Ui7ZguyP6CkyK9C79iTqo4RqQd7EgTbEExB=XSjr88yXeYel5TGD1iDPnnD87ZjDQAGXQH+juTKGtnYnRahRAEKiPL+T8qkYT8m+Rfrue493By+ydLytmbuKaH8EG7wRfwD1eVGar8usImSzTL8TEB2qTwYBx4U5lGftyDTa9bB0sRWl748nyt6uW0xEDBAYAm8Hxm5fDx//oaf2ZYB4txDKdNdYzlm+0Ghg+xMcWCAXV138h8iDaP8DzG482Wr72i44D7=DYIOeD=&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;c_pref&#x27;</span>] = <span class="string">&#x27;https%3A//cn.bing.com/&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;c_utm_medium&#x27;</span>] = <span class="string">&#x27;distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;UserName&#x27;</span>] = <span class="string">&#x27;weixin_43387852&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;c_dl_fpage&#x27;</span>] = <span class="string">&#x27;/download/weixin_38695452/12856957&#x27;</span></span><br><span class="line">dicts[<span class="string">&#x27;UserInfo&#x27;</span>] = <span class="string">&#x27;885ba7040ab64148b8d10b4450fcc279&#x27;</span></span><br><span class="line"><span class="comment">#不能直接将字典对象设置为cookies ，需要通过requests库的cookiejar_from_dict()方法</span></span><br><span class="line"><span class="comment">#把字段对象转换为cookiejar对象</span></span><br><span class="line">session.cookies = cookiejar_from_dict(dicts)</span><br><span class="line">r = session.post(<span class="string">&#x27;https://blog.csdn.net/&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(r.status_code)</span><br><span class="line"><span class="built_in">print</span>(r.text)</span><br><span class="line">save_session(session)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(session.headers)</span></span><br><span class="line"><span class="comment"># print(session.cookies.get_dict())</span></span><br><span class="line"><span class="comment"># session.headers,session.cookies = load_session() #将cookie设置为保存的cookie</span></span><br></pre></td></tr></table></figure></li><li>借助图片识别技术识别图片文字。一种常用的是通过tesseract-ocr进行识别，一种借助百度提供的文字识别技术进行识别处理。</li></ol></blockquote><p>通过图像识别技术来获取文字信息，通常需要对图像进行预处理来提高识别准确率。这里给出一些处理流程。</p><p><pre class="mermaid">    graph LR        原始图片 --> 图片放大        图片放大 --> 灰度化        灰度化 --> 二值化        二值化 --> 去除边框        去除边框 --> 降噪        降噪 --> 结束</pre><br>示例代码如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#图像处理方法</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment">#1.放大图片</span></span><br><span class="line"><span class="comment">#DPI≥ 300的图片有更好的识别效果</span></span><br><span class="line">img_org = cv2.imread(<span class="string">&#x27;R-C.png&#x27;</span>)</span><br><span class="line">h,w = img_org.shape[:<span class="number">2</span>]</span><br><span class="line">h,w = h*<span class="number">2</span>,w*<span class="number">2</span> <span class="comment">#按比例放大两倍</span></span><br><span class="line">img_l = cv2.resize(img_org,(w,h))</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(cv2.cvtColor(img_org,cv2.COLOR_BGR2RGB))</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(cv2.cvtColor(img_l,cv2.COLOR_BGR2RGB))</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment">#2. 图像灰度化，通过cvtColor灰度化图像</span></span><br><span class="line">img_org = cv2.imread(<span class="string">&#x27;R-C.png&#x27;</span>)</span><br><span class="line">img_gray = cv2.cvtColor(img_org,cv2.COLOR_BGR2GRAY) <span class="comment"># 灰度化</span></span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(cv2.cvtColor(img_org,cv2.COLOR_BGR2RGB))</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(cv2.cvtColor(img_org,cv2.COLOR_BGR2RGB))</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment">#3.图像二值化</span></span><br><span class="line"><span class="comment">#二值化将图片转换为黑白图像，二值化可以通过cv2.threshold()方法，该方法会返回两个参数，第一个为阈值，第二个为转化后的图像</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">cv2.threshold(src,thresh,maxval,type,dst=None)</span></span><br><span class="line"><span class="string">其中thresh为阈值，maxval为高于阈值的处理，dst为二值化处理方法选择的参数。</span></span><br><span class="line"><span class="string">dst指定的不同在于处理逻辑的不同。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">img_org = cv2.imread(<span class="string">&#x27;R-C.png&#x27;</span>)</span><br><span class="line">img_gray = cv2.cvtColor(img_org,cv2.COLOR_BGR2GRAY) <span class="comment"># 灰度化</span></span><br><span class="line"><span class="comment"># 像素点高于127的设置为255，不高于127的设置为0</span></span><br><span class="line">_,img_bin = cv2.threshold(img_gray,<span class="number">127</span>,<span class="number">255</span>,cv2.THRESH_BINARY)<span class="comment">#二值化</span></span><br><span class="line">plt.subplot(<span class="number">131</span>),plt.imshow(cv2.cvtColor(img_org,cv2.COLOR_BGR2RGB))</span><br><span class="line">plt.subplot(<span class="number">132</span>),plt.imshow(cv2.cvtColor(img_gray,cv2.COLOR_BGR2RGB))</span><br><span class="line">plt.subplot(<span class="number">133</span>),plt.imshow(cv2.cvtColor(img_bin,cv2.COLOR_BGR2RGB))</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment">#4.去除边框,当存在边框的时候去除,</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clearBorder</span>(<span class="params">img</span>):</span></span><br><span class="line">    h,w = img.shape[:<span class="number">2</span>]</span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,w):</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,h):</span><br><span class="line">            <span class="keyword">if</span>(y&lt;<span class="number">2</span> <span class="keyword">or</span> y&gt;w-<span class="number">2</span>):</span><br><span class="line">                img[x,y] = <span class="number">255</span></span><br><span class="line">            <span class="keyword">if</span> x &lt; <span class="number">2</span> <span class="keyword">or</span> x &gt;h-<span class="number">2</span>:</span><br><span class="line">                img[x,y] = <span class="number">255</span></span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="comment">#5. 降噪</span></span><br><span class="line"><span class="comment"># 噪声是图像中亮度或颜色的随机变化，降低噪声有利于准确率的提升，噪声去除的方法有很多</span></span><br><span class="line"><span class="comment"># 这里以线降噪为例</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">interfaceLine</span>(<span class="params">img</span>):</span></span><br><span class="line">    h,w = img.shape[:<span class="number">2</span>]</span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,w-<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,h-<span class="number">1</span>):</span><br><span class="line">            count = <span class="number">0</span></span><br><span class="line">            <span class="keyword">if</span> np.<span class="built_in">all</span>(img[x,y-<span class="number">1</span>])&gt;<span class="number">245</span>:</span><br><span class="line">                count = count+<span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> np.<span class="built_in">all</span>(img[x,y+<span class="number">1</span>])&gt;<span class="number">245</span>:</span><br><span class="line">                count = count+<span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> np.<span class="built_in">all</span>(img[x-<span class="number">1</span>],y)&gt;<span class="number">245</span>:</span><br><span class="line">                count = count+<span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> np.<span class="built_in">all</span>(img[x+<span class="number">1</span>],y)&gt;<span class="number">245</span>:</span><br><span class="line">                count = count+<span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> count &gt; <span class="number">2</span> :</span><br><span class="line">                img[x,y] = <span class="number">255</span></span><br><span class="line">    <span class="keyword">return</span> img</span><br></pre></td></tr></table></figure></p><p>通过tesseract-ocr进行识别，需要下载tesseract-oct,并且下载两个包。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install pytesseract</span><br><span class="line">pip install pillow</span><br></pre></td></tr></table></figure><br>示例代码如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pyteFunction</span>():</span></span><br><span class="line">    image = Image.<span class="built_in">open</span>(<span class="string">&#x27;test.PNG&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置tesseract的安装路径,这里设置你下载的tesseract-ocr的安装路径</span></span><br><span class="line">    pytesseract.pytesseract.tesseract_cmd = <span class="string">r&#x27;C:\Program Files (x86)\Tesseract-OCR\tesseract.exe&#x27;</span></span><br><span class="line"></span><br><span class="line">    code = pytesseract.pytesseract.image_to_string(image)</span><br><span class="line">    <span class="built_in">print</span>(code)</span><br></pre></td></tr></table></figure></p><p>通过百度API调用文字识别服务。可以访问<a href="https://ai.baidu.com/">https://ai.baidu.com/</a>，然后搜索文字识别，创建一个文字识别应用，创建成功后，根据提供的APP_KEY和Secret_Key即可调用API，获取到服务。示例代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#通过调用百度API进行验证码的识别</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">identify_Verification_code</span>(<span class="params">API_Key, Secret_Key, Verification_code</span>):</span></span><br><span class="line"></span><br><span class="line">    host = <span class="string">&#x27;https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&amp;client_id=&#x27;</span> + API_Key + <span class="string">&#x27;&amp;client_secret=&#x27;</span> + Secret_Key</span><br><span class="line">    response = requests.get(host)</span><br><span class="line">    access_token = response.json()[<span class="string">&#x27;access_token&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    request_url = <span class="string">&quot;https://aip.baidubce.com/rest/2.0/ocr/v1/general_basic&quot;</span></span><br><span class="line">    <span class="comment"># 二进制方式打开图片文件,Verification_code是要识别的验证码的名字</span></span><br><span class="line">    f = <span class="built_in">open</span>(Verification_code, <span class="string">&#x27;rb&#x27;</span>)</span><br><span class="line">    img = base64.b64encode(f.read())</span><br><span class="line"></span><br><span class="line">    params = &#123;<span class="string">&quot;image&quot;</span>: img&#125;</span><br><span class="line">    access_token = access_token</span><br><span class="line">    request_url = request_url + <span class="string">&quot;?access_token=&quot;</span> + access_token</span><br><span class="line">    headers = &#123;<span class="string">&#x27;content-type&#x27;</span>: <span class="string">&#x27;application/x-www-form-urlencoded&#x27;</span>&#125;</span><br><span class="line">    response = requests.post(request_url, data=params, headers=headers)</span><br><span class="line">    shibie_result = response.json()[<span class="string">&#x27;words_result&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;words&#x27;</span>]</span><br><span class="line">    <span class="built_in">print</span>(shibie_result)</span><br><span class="line"></span><br><span class="line"><span class="comment">#通过调用百度提供的接口来进行识别验证码</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">baiduAPI</span>():</span></span><br><span class="line">    API_Key = <span class="string">&#x27;#&#x27;</span> <span class="comment">#应用的key</span></span><br><span class="line">    Secret_Key = <span class="string">&#x27;#&#x27;</span> <span class="comment">#应用的Secret_Key</span></span><br><span class="line">    Verification_code = <span class="string">&#x27;R-C.PNG&#x27;</span> <span class="comment">#图片地址</span></span><br><span class="line">    identify_Verification_code(API_Key, Secret_Key, Verification_code)</span><br></pre></td></tr></table></figure><blockquote><blockquote><p>滑动验证码</p></blockquote></blockquote><p>滑动验证码涉及到图片拼接方面的知识。要想解决可以有以下思路，一是通过selenium模拟行为，解决滑动验证码，二是组建Cookie池绕过验证码。</p><p>通过selenium解决滑动验证码的流程：</p><blockquote><ol><li>获取图片（不带缺口的图片，带缺口的图片）</li><li>识别缺口位置（设置一个对比阈值，遍历两张图片，找出相同位置像素RGB差距，超过此阈值的像素点，此像素点的位置就是缺口的位置）</li><li>计算滑动距离</li><li>模拟运动</li></ol><blockquote><blockquote><p>www&gt;m&gt;wap</p></blockquote></blockquote></blockquote><p>www是PC浏览器看到的网站，m和wap是移动端，大部分智能手机用的是m站，少部分旧手机用的还是wap。一般wap爬取较为简单，我们可以通过修改User-Agent模拟不同终端发送出请求，请求不同的页面。<br>如何设置不同的User-Agent,我们可以在浏览器扩展选项中下载相关的User-Agent的应用。以Edge为例：<br>下载图中的扩展应用。<br><img src="/images/user-agent.PNG" alt="A33"><br>按照如下操作，选择需要模拟的浏览器，然后通过Verify User-Agent Setting可以查看User-Agent，以Iphone为例.<br><img src="/images/step.PNG" alt="A34"><br>获取到的请求头：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Mozilla/<span class="number">5.0</span> (iPhone; CPU iPhone OS <span class="number">13_2_3</span> like Mac OS X) AppleWebKit/<span class="number">605.1</span><span class="number">.15</span> (KHTML, like Gecko) Version/<span class="number">13.0</span><span class="number">.3</span> Mobile/<span class="number">15E148</span> Safari/<span class="number">604.1</span></span><br></pre></td></tr></table></figure></p><blockquote><blockquote><p>小结</p></blockquote></blockquote><p>对于网页爬取登录问题和验证码问题，需要对具体的网页进行分析，是通过API解析还是通过Cookie池登录，以及登录过程中的验证码破解问题。</p><h4 id="4-终端协议分析"><a href="#4-终端协议分析" class="headerlink" title="4.  终端协议分析"></a>4. <a id="four"></a> 终端协议分析</h4><p>一个应用不仅仅具有PC端而且还具有移动客户端。所以我们在进行爬虫开发的时候，不仅仅可以从PC端进行爬取，而且还可以从移动客户端进行爬取。我们可以借助User-Agent来伪装自己，进行数据的爬取。</p><blockquote><h3 id="1-PC端数据抓包分析"><a href="#1-PC端数据抓包分析" class="headerlink" title="1. PC端数据抓包分析"></a>1. PC端数据抓包分析</h3></blockquote><p>将爬虫伪装成PC客户端，可以对PC客户端进行抓包分析。PC抓包软件有Wireshark,Http Analyzer等。Wireshark擅长各类网络协议分析，比较重型。而Http Analizer更注重于对Http/Https协议的分析。Http Analizer可以针对某个进程进行抓包。</p><blockquote><blockquote><h4 id="Wireshark"><a href="#Wireshark" class="headerlink" title="Wireshark"></a>Wireshark</h4></blockquote></blockquote><p>Wireshark的使用方法很简单，只需要设置过滤规则进行监听即可。<br>简单的过滤规则，如指定监听的网址ip.addr == 121.40.103.238(这个地址是虾米音乐网地址，<a href="https://www.xiami.com/">https://www.xiami.com/</a>)。然后点击开始监听。<br>则Wireshark就会监听和121.40.103.238的数据。通过cmd，ping这个地址即可。</p><p><img src="/images/wireshark.PNG" alt="a41"></p><blockquote><blockquote><h4 id="http-Analyzer"><a href="#http-Analyzer" class="headerlink" title="http Analyzer"></a>http Analyzer</h4></blockquote></blockquote><p>http Analyzer的使用方法也很简单，点击开始监听即可。可以通过选择需要监听的进程进行监听。通过type可以选择需要过滤的数据类型。</p><p>通过抓包进行分析请求，进行数据爬取一般都是挺复杂的，涉及到逆向PC客户端软件和分析算法的能力。所以如果想要通过抓包进行爬取，需要了解相关技术进行爬取。</p><blockquote><h3 id="2-App抓包分析"><a href="#2-App抓包分析" class="headerlink" title="2. App抓包分析"></a>2. App抓包分析</h3></blockquote><p>移动端的抓包分析，以Android App为例。对Android应用抓包，通过下载安卓模拟器，将应用安装到模拟器中，然后进行抓包分析。</p><p>这里采用wireshake进行抓包分析，wireshake的过滤示例如下：</p><blockquote><p>过滤域名包含baidu.com的数据<br>http.host contains “baidu.com”<br>过滤指定ip地址<br>ip.addr == xxx.xxx.xxx.xxx</p></blockquote><p><img src="/images/wiresharke-1.PNG" alt="a44"><br><img src="/images/wiresharke-2.PNG" alt="a45"></p><h6 id="5-初窥Scrapy爬虫框架"><a href="#5-初窥Scrapy爬虫框架" class="headerlink" title="5. 初窥Scrapy爬虫框架"></a>5.<a id="five"></a> 初窥Scrapy爬虫框架</h6><p>Scrapy爬虫框架操作简单，是比较流行的爬虫解决方案，所以在这里对Scrapy进行学习。<br>Scraoy使用Twisted这个异步网络来处理网络通信，并且包含了各种中间件接口，可以灵活的完成各种需求。</p><blockquote><h4 id="1-Scrapy各大组件"><a href="#1-Scrapy各大组件" class="headerlink" title="1. Scrapy各大组件"></a>1. Scrapy各大组件</h4></blockquote><p>Scrapy的各个组件其实和之前学过的简单爬虫的各个模块相类似。</p><blockquote><blockquote><ol><li>Scrapy 引擎(Engine)</li></ol></blockquote></blockquote><p>Scrapy引擎负责控制数据流在系统的所有组件中流动，并在相应动作发生时触发事件。<br>这类似于爬虫调度器的作用。</p><blockquote><blockquote><ol><li>Scrapy 调度器(Scheduler)</li></ol></blockquote></blockquote><p>Scrapy调度器从引擎接收Request并将它们入队，以便之后引擎请求request时提供给引擎。这类似于URL管理器的作用。</p><blockquote><blockquote><ol><li>Scrapy 下载器(Downloader)</li></ol></blockquote></blockquote><p>Scrapy下载器负责获取页面数据并提供给引擎，而后提供给Spider。这类似于html下载器作用。</p><blockquote><blockquote><ol><li>Spider</li></ol></blockquote></blockquote><p>Spider是Scrapy用户编写用于分析Response并提取Item(即获取到的Item)或额外跟进的URL的类。每个Spider负责处理一个特定(或一些)网站。类似于html解析器作用。</p><blockquote><blockquote><ol><li>Item Pipeline</li></ol></blockquote></blockquote><p>Item Pipeline负责处理被Spider提取出来的Item。典型的处理有清理验证及持久化(例如存储到数据库中)。类似于数据存储器的作用。</p><blockquote><blockquote><ol><li>Downloader middlewares（下载器中间件）</li></ol></blockquote></blockquote><p>下载器中间件是在引擎及下载器之间的特定钩子(specific hook),处理Downloader传递给引擎的Response.<br>其提供了一个简便的机制，通过插入自定义代码来扩展Scrapy功能。</p><blockquote><blockquote><ol><li>Scrapy中间件(Spider middlewares)</li></ol></blockquote></blockquote><p>Scrapy中间件是在引擎及Spider之间的特定钩子(specific hook),处理Spider的输入(response)和<br>输出(Items及requests)。其提供了一个渐变的机制，通过插入自定义代码来扩展Scrapy功能。</p><p><img src="/images/Scrapy.PNG" alt="a58"></p><p><img src="/public/images/Spyder流程.PNG" alt="a59"></p><blockquote><h4 id="2-Scrapy的安装"><a href="#2-Scrapy的安装" class="headerlink" title="2. Scrapy的安装"></a>2. Scrapy的安装</h4></blockquote><p>这里介绍一下Windows下如何安装Scrapy(Python 3.7版本)。<br>如果不是Python3.7版本的，需要下载对应的Pywin32。</p><blockquote><h4 id="1-Pywin32下载"><a href="#1-Pywin32下载" class="headerlink" title="1. Pywin32下载"></a>1. Pywin32下载</h4></blockquote><p><a href="https://github.com/mhammond/pywin32/">下载地址</a></p><p>各个Pywin32的版本如图所示：<br><img src="/images/pywin32.PNG" alt="a58"></p><p>找到3.7版本，64位的安装包。<br><img src="/images/pywin32-1.PNG" alt="a59"></p><p>运行安装包后，通过命令行测试，如果没报错，则安装成功。<br><img src="/images/pywin32-2.PNG" alt="a590"></p><p>安装成功后，需要通过pip下载pywin32，或者直接通过pycharm安装pywin32<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pywin32</span><br></pre></td></tr></table></figure></p><blockquote><h4 id="2-pyOpenSSL下载"><a href="#2-pyOpenSSL下载" class="headerlink" title="2. pyOpenSSL下载"></a>2. pyOpenSSL下载</h4></blockquote><p><a href="https://github.com/pyca/pyopenssl">下载地址</a> , 或者通过pycharm下载 pyOpenSSL,或者通过 pip install pyOpenSSL</p><blockquote><h4 id="3-lxml下载"><a href="#3-lxml下载" class="headerlink" title="3. lxml下载"></a>3. lxml下载</h4></blockquote><p>通过pycharm下载，或者pip install lxml</p><blockquote><h4 id="4-Scrapy下载"><a href="#4-Scrapy下载" class="headerlink" title="4. Scrapy下载"></a>4. Scrapy下载</h4></blockquote><p>通过pycahrm下载，或者通过pip install Scrapy</p><p>如果要查看是否安装成功，通过pip list命令可以查看已经安装的库。</p><blockquote><h4 id="3-Scrapy应用"><a href="#3-Scrapy应用" class="headerlink" title="3. Scrapy应用"></a>3. Scrapy应用</h4><blockquote><ol><li>创建一个新的Scrapy项目</li></ol></blockquote></blockquote><p>命令行切换到指定文件夹，运行命令 scrapy startproject xxxx ,即可创建名为xxxx的项目。</p><p><img src="/images/scrapy-4.PNG" alt="a533"></p><p>如果出现”ImportError: DLL load failed: 找不到指定的程序”错误提示，或者出现python.exe无法找到入口….pythoncom37.dll。</p><p>首先下载：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ImportError: DLL load failed: 找不到指定的程序</span><br></pre></td></tr></table></figure></p><p>然后在电脑搜索pythoncom37.dll。观察无法找到入口的路径，一般都是在C盘的System32下，然后将搜索到的pythoncom37.dll所在的文件夹的内容(选择lib目录下的pywin32下的pythoncom37.dll文件夹里面的两个dll文件放到system32下)，复制到System32下，覆盖即可。</p><p><img src="/images/scrapy-7.PNG" alt="a554"></p><p>创建成功后的目录结构如图所示：</p><p><img src="/images/scrapy目录结构.PNG" alt="a556"></p><blockquote><blockquote><blockquote><h4 id="1-创建爬虫模块"><a href="#1-创建爬虫模块" class="headerlink" title="1. 创建爬虫模块"></a>1. 创建爬虫模块</h4></blockquote></blockquote></blockquote><p>爬虫模块都放置于spiders文件夹中。爬虫模块用于从单个网站或多个网站爬取数据的类。包含初始页面的URL，网页链接，分析网页内容，提取数据。<br>需要创建一个Spider类，继承scrapy.Spider类。<br>需要定义下面三个属性：<br>name:区别Spider，名字必须唯一。<br>start_urls:Spider启动时进行爬取的入口URL列表。<br>parse():Spider的一个方法，被调用时，负责解析返回数据，提取数据。</p><p>启动爬虫模块：通过命令行，切换到项目根目录下，运行<br>scrapy crawl xxxx , 其中xxxx为Spider类的name属性。</p><blockquote><blockquote><blockquote><h4 id="2-选择器"><a href="#2-选择器" class="headerlink" title="2. 选择器"></a>2. 选择器</h4></blockquote></blockquote></blockquote><p>Scrapy选择器构建于lxml库之上。也可也通过Beautifulsoup库解析。</p><p>Selector的用法：Selector对象有四个基本方法</p><blockquote><ol><li><p>xpath(query):传入XPath表达式query，返回该表达式所有节点的selector list列表</p></li><li><p>css(query):传入CSS表达式query，返回该表达式所对应的所有节点的selector list列表</p></li><li><p>extract():序列化该节点为Unicode字符串并返回list列表</p></li><li><p>re(regex):根据传入的正则表达式对数据进行提取，返回Unicode字符串列表。</p></li></ol></blockquote><p>在spider类中的parse方法中，传入的一个参数为response,通过Selector(response)<br>即可创建一个Selector对象。<br>示例代码如下所示<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CnblogsSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&quot;cnblogs&quot;</span> <span class="comment">#爬虫名称</span></span><br><span class="line">    allowed_domains = [<span class="string">&quot;cnblogs.com&quot;</span>] <span class="comment">#允许的域名</span></span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">&quot;http://www.cnblogs.com/qiyeboy/default.html?page=1&quot;</span></span><br><span class="line">    ] <span class="comment"># Spider启动时进行爬取的入口URL列表。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">#解析函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="comment"># #Selector使用</span></span><br><span class="line">        <span class="comment"># selector = Selector(response)</span></span><br><span class="line">        <span class="comment"># #调用xpath</span></span><br><span class="line">        <span class="comment"># selector.xpath()</span></span><br><span class="line">        <span class="comment"># #调用css</span></span><br><span class="line">        <span class="comment"># selector.css()</span></span><br><span class="line">        <span class="comment"># #调用re</span></span><br><span class="line">        <span class="comment"># selector.re()</span></span><br><span class="line">        <span class="comment"># #调用extract</span></span><br><span class="line">        <span class="comment"># selector.extract()</span></span><br><span class="line"></span><br><span class="line">        papers = response.xpath(<span class="string">&quot;.//*[@class=&#x27;day&#x27;]&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> paper <span class="keyword">in</span> papers:</span><br><span class="line">            url = paper.xpath(<span class="string">&quot;.//*[@class=&#x27;postTitle&#x27;]/a/@href&quot;</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            title = paper.xpath(<span class="string">&quot;.//*[@class=&#x27;postTitle&#x27;]/a/text()&quot;</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            time = paper.xpath(<span class="string">&quot;.//*[@class=&#x27;dayTitle&#x27;]/a/text()&quot;</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            content = paper.xpath(<span class="string">&quot;.//*[@class=&#x27;postTitle&#x27;]/a/text()&quot;</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            <span class="built_in">print</span>(url,title,time,content)</span><br></pre></td></tr></table></figure></p><blockquote><blockquote><blockquote><h4 id="3-命令行工具"><a href="#3-命令行工具" class="headerlink" title="3. 命令行工具"></a>3. 命令行工具</h4></blockquote></blockquote></blockquote><p>这里介绍一下Scrapy命令行功能。</p><p>创建一个项目</p><blockquote><p>scrapy createproject xxxx<br>运行一个项目<br>scrapy crawl name（spider的name属性）<br>运行单个spider模块<br>scrapy runspider xxxx.py<br>列出当前项目所有Spider<br>scrapy list<br>快速创建spider模板<br>scrapy genspider -l<br>scrapy genspider -d basic<br>scrapy genspider -t basic example example.com<br>将项目部署到Scrapy服务<br>scrapy deploy</p><blockquote><blockquote><h4 id="4-定义Item"><a href="#4-定义Item" class="headerlink" title="4. 定义Item"></a>4. 定义Item</h4></blockquote></blockquote></blockquote><p>Item用于保存爬取到的数据，类似于字典类型，在之前的目录结构中，有个items.py文件用来定义存储数据的Item类。这个类需要继承scrapy.Item。示例代码如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SpiderItem</span>(<span class="params">scrapy.Item</span>):</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    <span class="comment"># name = scrapy.Field()</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CnblogspiderItem</span>(<span class="params">scrapy.Item</span>):</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like</span></span><br><span class="line">    <span class="comment"># 类似于字典类型，可以直接通过[]和get方法获取</span></span><br><span class="line">    url = scrapy.Field()</span><br><span class="line">    time = scrapy.Field()</span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    content = scrapy.Field()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    item = CnblogspiderItem(title=<span class="string">&#x27;爬虫&#x27;</span>,content=<span class="string">&#x27;爬虫开发&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(item[<span class="string">&#x27;title&#x27;</span>])</span><br><span class="line">    <span class="built_in">print</span>(item.get(<span class="string">&#x27;title&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(item.keys())</span><br><span class="line">    <span class="built_in">print</span>(item.items())</span><br><span class="line">    item2 = CnblogspiderItem(item) <span class="comment">#Item复制</span></span><br><span class="line">    <span class="comment">#dict和item转化</span></span><br><span class="line">    dict_item = <span class="built_in">dict</span>(item)</span><br><span class="line">    <span class="built_in">print</span>(dict_item)</span><br><span class="line">    item = CnblogspiderItem(&#123;<span class="string">&#x27;title&#x27;</span>:<span class="string">&#x27;爬虫&#x27;</span>,<span class="string">&#x27;content&#x27;</span>:<span class="string">&#x27;开发&#x27;</span>&#125;)</span><br><span class="line">    <span class="built_in">print</span>(item)</span><br></pre></td></tr></table></figure></p><p>我们可以在原有的Item基础之上，添加更过的字段用于扩展Item。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CnblogspiderItem</span>(<span class="params">scrapy.Item</span>):</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like</span></span><br><span class="line">    <span class="comment"># 类似于字典类型，可以直接通过[]和get方法获取</span></span><br><span class="line">    url = scrapy.Field()</span><br><span class="line">    time = scrapy.Field()</span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    content = scrapy.Field()</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">newCnblogspiderItem</span>(<span class="params">CnblogspiderItem</span>):</span></span><br><span class="line">    body = scrapy.Field()</span><br><span class="line">    title = scrapy.Field(CnblogspiderItem.fields[<span class="string">&#x27;title&#x27;</span>],body=body)</span><br></pre></td></tr></table></figure><p>如果要实现翻页功能,将提取出来的URL，构建新的Request对象，并指定解析方法。：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#解析函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">    <span class="comment"># #Selector使用</span></span><br><span class="line">    <span class="comment"># selector = Selector(response)</span></span><br><span class="line">    <span class="comment"># #调用xpath</span></span><br><span class="line">    <span class="comment"># selector.xpath()</span></span><br><span class="line">    <span class="comment"># #调用css</span></span><br><span class="line">    <span class="comment"># selector.css()</span></span><br><span class="line">    <span class="comment"># #调用re</span></span><br><span class="line">    <span class="comment"># selector.re()</span></span><br><span class="line">    <span class="comment"># #调用extract</span></span><br><span class="line">    <span class="comment"># selector.extract()</span></span><br><span class="line"></span><br><span class="line">    papers = response.xpath(<span class="string">&quot;.//*[@class=&#x27;day&#x27;]&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> paper <span class="keyword">in</span> papers:</span><br><span class="line">        url = paper.xpath(<span class="string">&quot;.//*[@class=&#x27;postTitle&#x27;]/a/@href&quot;</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        title = paper.xpath(<span class="string">&quot;.//*[@class=&#x27;postTitle&#x27;]/a/text()&quot;</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        time = paper.xpath(<span class="string">&quot;.//*[@class=&#x27;dayTitle&#x27;]/a/text()&quot;</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        content = paper.xpath(<span class="string">&quot;.//*[@class=&#x27;postTitle&#x27;]/a/text()&quot;</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        item = CnblogspiderItem(url=url,title=title,time=time,content=content)</span><br><span class="line">        <span class="keyword">yield</span> item <span class="comment">#将数据返回</span></span><br><span class="line">    next_page = Selector(response).re(<span class="string">u&#x27;&lt;a href=&quot;(\S*)&quot;&gt;下一页&lt;/a&gt;&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> next_page:</span><br><span class="line">        <span class="comment">#Request对象中的URL为请求链接，callback为回调方法，回调方法用于指定由</span></span><br><span class="line">        <span class="comment">#谁来解析此项Request请求的响应</span></span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(url=next_page[<span class="number">0</span>],callback=self.parse)</span><br></pre></td></tr></table></figure></p><blockquote><blockquote><blockquote><h4 id="5-定义Item-Pipeline"><a href="#5-定义Item-Pipeline" class="headerlink" title="5. 定义Item Pipeline"></a>5. 定义Item Pipeline</h4></blockquote></blockquote></blockquote><p>通过Item Pipeline可以对数据进行持久化存储，通过Item Pipeline可以对Item进行处理。<br>Item Pipeline主要有如下几个作用：</p><ol><li>清理HTML数据</li><li>验证爬取数据的合法性，检查Item是否包含某些字段</li><li>查重并丢弃</li><li>将数据结果保存到文件或数据库中</li></ol><p>Item Pipeline组件是一个独立的Python类，必须实现proocess_item方法</p><blockquote><p>process_item(self,item,spider)<br>其中itme是被爬取的item，Spider对象代表着爬取该Item的Spider</p></blockquote><p>示例代码如下所示:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CnblogspiderPipeline</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.file = <span class="built_in">open</span>(<span class="string">&#x27;parpers.json&#x27;</span>,<span class="string">&#x27;wb&#x27;</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self,item,spider</span>):</span></span><br><span class="line">        <span class="keyword">if</span> item[<span class="string">&#x27;title&#x27;</span>]:</span><br><span class="line">            <span class="comment">#将数据保存到文件中</span></span><br><span class="line">            line = json.dumps(<span class="built_in">dict</span>(item))+<span class="string">&quot;\n&quot;</span></span><br><span class="line">            self.file.write(line)</span><br><span class="line">            <span class="keyword">return</span> item </span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment">#DropItem是异常类型，如果不存在就爆出异常，进行丢弃</span></span><br><span class="line">            <span class="keyword">raise</span> DropItem(<span class="string">&quot;Missing title in %s&quot;</span>%item)</span><br><span class="line"></span><br></pre></td></tr></table></figure></p><p>编写好的Item Pipeline需要在settings.py(在目录结构中可以找到)中，将类添加到ITEM_PIPELINES变量中。<br>示例代码如下所示：其中的key就是Item Pipeline的类路径，value是自定义数字，当执行Item Pipeline时，按数字大小从低到高依次执行Item Pipeline。通常定义在0-1000范围内。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">&#x27;spider.pipelines.SpiderPipeline&#x27;</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><blockquote><blockquote><blockquote><h4 id="6-定义Item-Pipeline内置数据存储"><a href="#6-定义Item-Pipeline内置数据存储" class="headerlink" title="6. 定义Item Pipeline内置数据存储"></a>6. 定义Item Pipeline内置数据存储</h4></blockquote></blockquote></blockquote><h4 id="内置文本格式下载方式"><a href="#内置文本格式下载方式" class="headerlink" title="内置文本格式下载方式"></a>内置文本格式下载方式</h4><p>Scrapy提供了一些简单的存储方式。生成一个带有爬取数据的输出文件(feed)。Scrapy的输出自带各种序列化格式。</p><blockquote><p>json<br>JsonItemExporter<br>JSON lines<br>JsonLinesItemExporter<br>CSV<br>CsvItemExporter<br>XML<br>XmlItemExporter<br>Pickle<br>PickleItemExporter<br>Marshal<br>MarshalItemExporter</p></blockquote><p>使用方法：通过命令行使用，例如scrapy crawl xxx -o xxx.csv</p><h4 id="内置图片和文件下载方式"><a href="#内置图片和文件下载方式" class="headerlink" title="内置图片和文件下载方式"></a>内置图片和文件下载方式</h4><p>Scrapy提供了可重用的Item Pipeline(MediaPipeline分为FilesPipeline和ImagesPipeline)，如果要使用ImagesPipeline需要下载pillow模块(pip install pillow)。这类Pipeline具有如下特性。</p><ol><li>避免重新下载最近下载过的数据</li><li>指定存储的位置和方式<br>对于ImagesPipeline还具有额外的特性：</li><li>将所有下载的图片转换为通用的格式(JPG)和模型(RGB)</li><li>缩略图生成</li><li>检测图像的宽/高，确保它们满足最小限制<br>对于要下载的Item会在内部保存一个内部对了，避免多次下载几个Item共享的同一个图片。</li></ol><p>对于FilesPipeline的工作流程：</p><ol><li>在一个爬虫里，抓取一个Item，将文件URL，放入file_urls组内。</li><li>Item从爬虫内返回，进入Item Pipeline</li><li>当Item进入FilesPipeline,file_urls组内的URL将被Scrapy的调度器和下载器安排下载。</li><li>当文件下载完后，另一个字段files将被更新到结构中。这个组将包含一个字典列表，其中包括下载文件的信息。信息包括：下载文件的信息比如下载路径，源抓取地址，图片校验码。如果下载失败，会记录下载错误信息。</li></ol><p>对于ImagesPipeline的工作流程：</p><ol><li>从一个爬虫中，抓取一个Item，把图片的URL放图images_url组内。</li><li>项目从爬虫内返回，进入Item Pieline</li><li>当Item进入ImagesPipelin,images_urls组内的URL将被Scrapy的调度器和下载器安排下载。</li><li>当文件下载完成之后，另一个字段(images)将别更新到结构中。信息包括：下载图片的信息比如下载路径，源抓取地址，图片校验码。如果下载失败，会记录下载错误信息。</li></ol><h4 id="使用FilesPipeline"><a href="#使用FilesPipeline" class="headerlink" title="使用FilesPipeline:"></a>使用FilesPipeline:</h4><blockquote><ol><li>在settings.py文件的ITEM_PIPELINES添加一条’scrapy.pipelines.files.FilesPipeline’:1</li><li>在item添加两个字段，比如</li></ol></blockquote><p>file_urls = scrapy.Filed()<br>files = scrapy.Filed()</p><blockquote><ol><li>在settings.py中添加下载路径FILES_STORE，文件url所在的itme字段FILE_URLS_FILED，和文件信息所在item字段FILES_RESULT_FIELD。例如：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">FILES_STORE = <span class="string">&#x27;G:\\python&#x27;</span></span><br><span class="line">FILES_URLS_FIELD = <span class="string">&#x27;file_urls&#x27;</span></span><br><span class="line">FILES_RESULT_FIELD = <span class="string">&#x27;files&#x27;</span></span><br><span class="line">FILES_EXPIRES = <span class="number">30</span> <span class="comment"># 设置文件过期时间(天)</span></span><br></pre></td></tr></table></figure></li></ol></blockquote><h4 id="使用ImagesPipeline"><a href="#使用ImagesPipeline" class="headerlink" title="使用ImagesPipeline:"></a>使用ImagesPipeline:</h4><blockquote><ol><li>在settings.py文件的ITEM_PIPELINES添加一条’scrapy.pipelines.files.ImagesPipeline’:1</li><li>在item添加两个字段，比如<br>image_urls = scrapy.Filed()<br>images = scrapy.Filed()</li><li>在settings.py中添加下载路径IMAGES_STORE，文件url所在的itme字段IMAGES_URLS_FILED，和文件信息所在item字段IMAGES_RESULT_FIELD。IMAGES_THUMBS制作缩略图，并设置图片大小和尺寸。如果需要过滤特别小的图片可以使用IMAGES_MIN_HEIGHT和IMAGES_MIN_WIDTH来设置图片的最小高和宽。例如：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">IMAGES_STORE = <span class="string">&#x27;G:\\python&#x27;</span></span><br><span class="line">IMAGES_URLS_FIELD = <span class="string">&#x27;file_urls&#x27;</span></span><br><span class="line">IMAGES_RESULT_FIELD = <span class="string">&#x27;files&#x27;</span></span><br><span class="line">IMAGES_THUMBS = &#123;</span><br><span class="line">    <span class="string">&#x27;small&#x27;</span>:(<span class="number">50</span>,<span class="number">50</span>),</span><br><span class="line">    <span class="string">&#x27;big&#x27;</span>:(<span class="number">270</span>,<span class="number">270</span>)</span><br><span class="line">&#125;</span><br><span class="line">IMAGES_EXPIRES = <span class="number">30</span> <span class="comment"># 设置文件过期时间(天)</span></span><br></pre></td></tr></table></figure></li></ol></blockquote><p>在之前的示例基础上，在setting.py设置如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">&#x27;spider.pipelines.CnblogspiderPipeline&#x27;</span>: <span class="number">300</span>,</span><br><span class="line">   <span class="string">&#x27;scrapy.pipelines.images.ImagesPipeline&#x27;</span>:<span class="number">1</span></span><br><span class="line">&#125;</span><br><span class="line">IMAGES_STORE = <span class="string">&#x27;G:\\python\spider\spider&#x27;</span></span><br><span class="line">IMAGES_URLS_FIELD = <span class="string">&#x27;cimage_urls&#x27;</span></span><br><span class="line">IMAGES_RESULT_FIELE = <span class="string">&#x27;cimages&#x27;</span></span><br><span class="line">IMAGES_EXPIRES = <span class="number">30</span></span><br><span class="line">IMAGES_THUMBS = &#123;</span><br><span class="line">   <span class="string">&#x27;small&#x27;</span>:(<span class="number">50</span>,<span class="number">50</span>),</span><br><span class="line">   <span class="string">&#x27;big&#x27;</span>:(<span class="number">270</span>,<span class="number">270</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>然后在CnblogspiderItem添加两个字段cimage_urls和cimages。<br>修改spider代码，用于下载图片<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def parse(self,response):</span><br><span class="line">       papers = response.xpath(&quot;.//*[@class=&#x27;day&#x27;]&quot;)</span><br><span class="line">       for paper in papers:</span><br><span class="line">           url = paper.xpath(&quot;.//*[@class=&#x27;postTitle&#x27;]/a/@href&quot;).extract()[0]</span><br><span class="line">           title = paper.xpath(&quot;.//*[@class=&#x27;postTitle&#x27;]/a/text()&quot;).extract()[0]</span><br><span class="line">           time = paper.xpath(&quot;.//*[@class=&#x27;dayTitle&#x27;]/a/text()&quot;).extract()[0]</span><br><span class="line">           content = paper.xpath(&quot;.//*[@class=&#x27;postTitle&#x27;]/a/text()&quot;).extract()[0]</span><br><span class="line">           item = CnblogspiderItem(url=url,title=title,time=time,content=content)</span><br><span class="line">           request = scrapy.Request(url=url,callback=self.parse_body) #调用Request方法，并设置解析函数</span><br><span class="line">           request.meta[&#x27;item&#x27;] = item #将item暂存</span><br><span class="line">           yield request</span><br><span class="line">       next_page = Selector(response).re(u&#x27;&lt;a href=&quot;(\S*)&quot;&gt;下一页&lt;/a&gt;&#x27;)</span><br><span class="line">       if next_page:</span><br><span class="line">           #Request对象中的URL为请求链接，callback为回调方法，回调方法用于指定由</span><br><span class="line">           #谁来解析此项Request请求的响应</span><br><span class="line">           yield scrapy.Request(url=next_page[0],callback=self.parse)</span><br><span class="line"></span><br><span class="line">   def parse_body(self,response):</span><br><span class="line">       item = response.meta[&#x27;item&#x27;]</span><br><span class="line">       body = response.xpath(&quot;.//*[@class=&#x27;postBody&#x27;]&quot;)</span><br><span class="line">       item[&#x27;cimage_urls&#x27;] = body.xpath(&#x27;.//img//@src&#x27;).extract()# 提取图片链接</span><br><span class="line">       yield item</span><br></pre></td></tr></table></figure></p><p>这里容易看出ImagePipeline的执行流程，首先是将图片url放入到image_urls中，然后由Scrapy下载，最后保存到指定的路径。</p><h4 id="自定义FilesPipline和ImagesPipeline"><a href="#自定义FilesPipline和ImagesPipeline" class="headerlink" title="自定义FilesPipline和ImagesPipeline"></a>自定义FilesPipline和ImagesPipeline</h4><p>如果要自定义FilesPipline和ImagesPipeline则需要继承FilesPipeline或者ImagesPipeline，重写<br>get_media_requests和item_completed()方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">在工作流程中，管道会得到图片的URL并从项目中下载。需要重写get_media_requests方法.并对各个图片URL返回一个Request。</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_meida_requests</span>(<span class="params">self,item,info</span>):</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span>  <span class="title">MyImagesPipeline</span>(<span class="params">ImagesPipeline</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 管道通过get_media_requests接收到图片的URL并从项目中进行下载</span></span><br><span class="line">    <span class="comment"># get_media_request会返回图片URL对应的Request</span></span><br><span class="line">    <span class="comment"># 对于返回的结果results会以二元素的元组列表形式传送到item_completed方法</span></span><br><span class="line">    <span class="comment"># 返回格式</span></span><br><span class="line">    <span class="comment"># success: 布尔值，成功返回True，是啊比返回False</span></span><br><span class="line">    <span class="comment"># url:图片下载的url</span></span><br><span class="line">    <span class="comment"># path:图片存储路径</span></span><br><span class="line">    <span class="comment"># checksum:图片内容的MD5 hash</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_media_requests</span>(<span class="params">self, item, info</span>):</span></span><br><span class="line">        <span class="keyword">for</span> image_url <span class="keyword">in</span> item[<span class="string">&#x27;image_urls&#x27;</span>]:</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(image_url)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 当所有图片请求完成时，item_completed方法将被调用</span></span><br><span class="line">    <span class="comment"># results是get_media_requests下载完成之后的结果。</span></span><br><span class="line">    <span class="comment"># item_completed需要返回一个输出。这个输出会被送到随后的ItemPipelines(在Scrapy中，item的执行顺序会根据id大小依次调用)</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">item_completed</span>(<span class="params">self, results, item, info</span>):</span></span><br><span class="line">        image_paths = [x[<span class="string">&#x27;path&#x27;</span>] <span class="keyword">for</span> ok,x <span class="keyword">in</span> results <span class="keyword">if</span> ok]</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> image_paths:</span><br><span class="line">            <span class="keyword">raise</span> DropItem(<span class="string">&quot;Item contains no images&quot;</span>) <span class="comment">#丢弃项目DropItem</span></span><br><span class="line">        item[<span class="string">&#x27;image_paths&#x27;</span>] = image_paths </span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure><blockquote><blockquote><blockquote><h4 id="7-启动爬虫"><a href="#7-启动爬虫" class="headerlink" title="7. 启动爬虫"></a>7. 启动爬虫</h4></blockquote></blockquote><ol><li>命令行方式<br>scrapy crawl spider_name </li><li>使用CrawlProcess类<br>CrawlProcess类内部会开启Twisted reactor，配置log,设置Twisted reactor自动关闭。</li></ol></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment">#初始化CrawlerProcess参数</span></span><br><span class="line">    procerss = CrawlerProcess(&#123;</span><br><span class="line">        <span class="string">&#x27;USER-AGENT&#x27;</span>:<span class="string">&#x27;Mozilla/4.0 (compatible; MSIE 7.0 ; Windows NT 5.1)&#x27;</span></span><br><span class="line">    &#125;)</span><br><span class="line">    procerss.crawl(CnblogsSpider) <span class="comment">#运行爬虫</span></span><br><span class="line">    procerss.start()</span><br></pre></td></tr></table></figure><p>带启动参数的CrawlProcess类。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">procerss = CrawlerProcess(get_project_settings())</span><br><span class="line">procerss.crawl(CnblogsSpider)  <span class="comment"># 运行爬虫</span></span><br><span class="line">procerss.start()</span><br><span class="line"></span><br></pre></td></tr></table></figure></p><blockquote><ol><li>使用CrawlerRunner</li></ol></blockquote><p>CrawlerRunner：在spider结束后，必须自行关闭Twisted reactor 需要在CrawlerRunner.crawl所返回的对象中添加回调函数。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">configure_logging(&#123;<span class="string">&#x27;LOG_FORMAT&#x27;</span>:<span class="string">&#x27;%(levelname)s：%(message)s&#x27;</span>&#125;)</span><br><span class="line">  runner = CrawlerRunner()</span><br><span class="line">  d = runner.crawl(CnblogsSpider)</span><br><span class="line">  d.addBoth(<span class="keyword">lambda</span> _:reactor.stop())</span><br><span class="line">  reactor.run()</span><br></pre></td></tr></table></figure></p><blockquote><blockquote><blockquote><h4 id="8-强化爬虫"><a href="#8-强化爬虫" class="headerlink" title="8. 强化爬虫"></a>8. 强化爬虫</h4></blockquote></blockquote></blockquote><p>这里主要是介绍关于Scrapy的调试方法和异常，控制运行状态等内容。</p><blockquote><h5 id="1-调试方法"><a href="#1-调试方法" class="headerlink" title="1. 调试方法"></a>1. 调试方法</h5></blockquote><h4 id="Parse命令"><a href="#Parse命令" class="headerlink" title="Parse命令"></a>Parse命令</h4><p>检查Spider输出的最基本方法(Parse命令)，可以在函数层上检查spider各个部分的效果。<br>使用方法为scrapy parse —spider==spider_name -c parse -d 2<item_url><br>例如 scrapy parse —spider==cblogs -c parse -d”<a href="https://www.baidu.com">https://www.baidu.com</a>“</p><h4 id="Scrapy-shell"><a href="#Scrapy-shell" class="headerlink" title="Scrapy shell"></a>Scrapy shell</h4><p>通过Scrapy shell 可以查看spider某个位置中被处理的response，以确定期望的response是否到达特定位置。<br>在spider类中，添加scrapy.shell.inspect_response方法。当程序运行到inspect_response方法时，会暂停，并切换进shell中，方便进行调试。如果要退出终端可以ctrl+d进行退出。代码如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self,response</span>):</span></span><br><span class="line">       papers = response.xpath(<span class="string">&quot;.//*[@class=&#x27;day&#x27;]&quot;</span>)</span><br><span class="line">       <span class="comment">#添加scrapy shell</span></span><br><span class="line"></span><br><span class="line">       <span class="keyword">from</span> scrapy.shell <span class="keyword">import</span> inspect_response</span><br><span class="line">       inspect_response(response,self)</span><br><span class="line"></span><br><span class="line">       <span class="keyword">for</span> paper <span class="keyword">in</span> papers:</span><br><span class="line">           url = paper.xpath(<span class="string">&quot;.//*[@class=&#x27;postTitle&#x27;]/a/@href&quot;</span>).extract()[<span class="number">0</span>]</span><br><span class="line">           title = paper.xpath(<span class="string">&quot;.//*[@class=&#x27;postTitle&#x27;]/a/text()&quot;</span>).extract()[<span class="number">0</span>]</span><br><span class="line">           time = paper.xpath(<span class="string">&quot;.//*[@class=&#x27;dayTitle&#x27;]/a/text()&quot;</span>).extract()[<span class="number">0</span>]</span><br><span class="line">           content = paper.xpath(<span class="string">&quot;.//*[@class=&#x27;postTitle&#x27;]/a/text()&quot;</span>).extract()[<span class="number">0</span>]</span><br><span class="line">           item = CnblogspiderItem(url=url,title=title,time=time,content=content)</span><br><span class="line">           request = scrapy.Request(url=url,callback=self.parse_body) <span class="comment">#调用Request方法，并设置解析函数</span></span><br><span class="line">           request.meta[<span class="string">&#x27;item&#x27;</span>] = item <span class="comment">#将item暂存</span></span><br><span class="line">           <span class="keyword">yield</span> request</span><br><span class="line">       next_page = Selector(response).re(<span class="string">u&#x27;&lt;a href=&quot;(\S*)&quot;&gt;下一页&lt;/a&gt;&#x27;</span>)</span><br><span class="line">       <span class="keyword">if</span> next_page:</span><br><span class="line">           <span class="comment">#Request对象中的URL为请求链接，callback为回调方法，回调方法用于指定由</span></span><br><span class="line">           <span class="comment">#谁来解析此项Request请求的响应</span></span><br><span class="line">           <span class="keyword">yield</span> scrapy.Request(url=next_page[<span class="number">0</span>],callback=self.parse)</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">parse_body</span>(<span class="params">self,response</span>):</span></span><br><span class="line">       item = response.meta[<span class="string">&#x27;item&#x27;</span>]</span><br><span class="line">       body = response.xpath(<span class="string">&quot;.//*[@class=&#x27;postBody&#x27;]&quot;</span>)</span><br><span class="line">       item[<span class="string">&#x27;cimage_urls&#x27;</span>] = body.xpath(<span class="string">&#x27;.//img//@src&#x27;</span>).extract()<span class="comment"># 提取图片链接</span></span><br><span class="line">       <span class="keyword">yield</span> item</span><br><span class="line"></span><br></pre></td></tr></table></figure></p><h4 id="loggin"><a href="#loggin" class="headerlink" title="loggin"></a>loggin</h4><p>通过运行后的记录查看爬虫的运行状态</p><h4 id="编译器"><a href="#编译器" class="headerlink" title="编译器"></a>编译器</h4><p>借助编译器提供的Debug进行断点调试，查看程序运行情况。</p><blockquote><h5 id="2-异常"><a href="#2-异常" class="headerlink" title="2. 异常"></a>2. 异常</h5></blockquote><p>之前已经使用过以恶异常也就是抛弃Item,DropItem。下图是关于Scrapy异常的介绍。<br><img src="/images/scrapy-e1.PNG" alt="566"></p><p><img src="/images/scrapy-e2.PNG" alt="567"></p><blockquote><h5 id="3-控制运行状态"><a href="#3-控制运行状态" class="headerlink" title="3. 控制运行状态"></a>3. 控制运行状态</h5></blockquote><p>通过telnet访问Scrapy终端。<br>talnet localhost 6023<br>进入终端后，通过est()可以查看scrapy运行情况。<br>通过engine/pause()暂停运行，通过engine.unpause()继续运行。<br>通过engine.stop()停止运行。<br>配置telnet，在setting.py中配置IP和端口。<br>TELNETCONSOLE_PORT:6023 #设置为0或者None动态分配端口。<br>TELNETCONSOLE_HOST:’127.0.0.1’ #y也就是本地地址ip</p><h6 id="7-实战项目：Scrapy爬虫"><a href="#7-实战项目：Scrapy爬虫" class="headerlink" title="7. 实战项目：Scrapy爬虫"></a>7.<a id="seven"></a> 实战项目：Scrapy爬虫</h6>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1-数据存储&quot;&gt;&lt;a href=&quot;#1-数据存储&quot; class=&quot;headerlink&quot; title=&quot;1.数据存储&quot;&gt;&lt;/a&gt;&lt;a href=&quot;#one&quot;&gt;1.数据存储&lt;/a&gt;&lt;/h3&gt;&lt;h3 id=&quot;2-动态文件抓取&quot;&gt;&lt;a href=&quot;#2-动态文件抓取&quot; 
      
    
    </summary>
    
      <category term="爬虫" scheme="http://example.com/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="Python" scheme="http://example.com/tags/Python/"/>
    
      <category term="爬虫" scheme="http://example.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>Python爬虫开发与项目实战-第二回合（实战）</title>
    <link href="http://example.com/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E7%88%AC%E8%99%AB/Python%E7%88%AC%E8%99%AB2.1/"/>
    <id>http://example.com/wiki/程序技术/Python/爬虫/Python爬虫2.1/</id>
    <published>2021-11-18T08:35:25.519Z</published>
    <updated>2021-11-22T02:19:31.513Z</updated>
    
    <content type="html"><![CDATA[<p>爬虫的原理十分简单，通过URL，获取网页资源，再根据网页资源进一步获取需要的信息数据。</p><p>我们很容易借助requests,beautifulSoup库等实现一个简答的爬虫。实际上，到了这基本上爬虫的大概就已经学习完毕了。对于我们现在编写的爬虫与大型爬虫的差距在于以下几点：</p><blockquote><ol><li>实现方式</li><li>优化方式</li><li>稳健性<br>我们现在仅仅只考虑功能的实现，所以还只是基础爬虫，要实现一个大型的爬虫还因该从效率，稳健性，结构化，维护等方面综合考虑。</li></ol></blockquote><p><img src="/images/基础爬虫.PNG" alt="a1"></p><p>一个爬虫的基础框架可以分为：爬虫调度器，URL管理器，HTML下载器，HTML解析器，数据存储器</p><ol><li><p>爬虫调度器  负责其他四个模块的协调工作</p></li><li><p>URL管理器主要负责URL链接，维护已经爬取的URL集合和未爬取的URL集合，提供互殴去新的URL链接的接口</p></li><li><p>HTML下载器用于从URL管理器中获取未爬取的URL链接并下载HTML页面</p></li><li><p>HTML解析器用于从HTML下载器中获取已经下载的HTML页面，并从中解析出新的URL链接交给URL管理器<br>解析出有效数据交给数据存储器。</p></li><li><p>数据存储器用于将HTML解析器解析出来的数据通过文件或数据库的形式存储起来。</p></li></ol><p>爬虫的动态流程如下所示：<br><img src="/images/爬虫时序图.PNG" alt="a2"></p><h6 id="百度百科词条爬取项目"><a href="#百度百科词条爬取项目" class="headerlink" title="百度百科词条爬取项目"></a>百度百科词条爬取项目</h6><blockquote><h3 id="URL管理器"><a href="#URL管理器" class="headerlink" title="URL管理器"></a>URL管理器</h3></blockquote><h6 id="简单分布式爬虫"><a href="#简单分布式爬虫" class="headerlink" title="简单分布式爬虫"></a>简单分布式爬虫</h6><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>这里实现简单的分布式爬虫，采用主从模式。目前大型的爬虫都采用分布式爬取，所以通过此次实践加深对分布式爬虫的理解。分布式需要考虑如何设计结构，保证各个节点稳定高效地运作。</p><h4 id="主从模式"><a href="#主从模式" class="headerlink" title="主从模式"></a>主从模式</h4><p>主从模式是指由一台主机作为控制节点，负责管理所有运行网络爬虫的主机，爬虫只需要从控制节点那里接收任务，并把新<br>生成任务提交给控制节点就可以了，在这个过程中不必与其它爬虫通信。</p><blockquote><ol><li>采用主从模式，实现简单，利于管理。而控制节点则需要与所有爬虫进行通信。</li><li>主从模式的缺陷在于，控制节点会成为整个系统的瓶颈，容易导致整个分布式网络爬虫系统性能下降。</li></ol></blockquote><p>主从模式的结构如下所示(以一台主机和两台从机为例)：控制节点（ControlNode）主要分为URL管理器，数据存储器和控制调度器。(1)控制调度器通过三个进程来协调URL管理器和数据存储器的工作：(2)一个是URL管理进程，负责URL的管理和将URL传递给爬虫节点；(3)一个是数据提取进程，负责读取爬虫节点返回的数据，将返回数据中的URL交给URL管理进程，将标题和摘要等数据交给数据存储进程；最后一个是数据存储进程，负责将数据提取进程中提交的数据进行本地存储。</p><p>对于爬虫节点(SpdierNode):包含爬虫调度器，HTML下载器，HTML解析器，主要负责对URL进行爬取，下载，然后将新的URL,data返回给控制节点(ControlNode)。<br>爬虫调度器的执行流程：</p><ol><li>爬虫调度器从控制节点中的url_q队列读取URL</li><li>爬虫调度器调用HTML下载器，HTML解析器获取网页中新的URL和标题摘要</li><li>爬虫调度器将新的URL和标题摘要传入result_q队列交给控制节点</li></ol><p><img src="/images/主从.PNG" alt="a21"><br><img src="/images/控制节点.PNG" alt="a22"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;爬虫的原理十分简单，通过URL，获取网页资源，再根据网页资源进一步获取需要的信息数据。&lt;/p&gt;
&lt;p&gt;我们很容易借助requests,beautifulSoup库等实现一个简答的爬虫。实际上，到了这基本上爬虫的大概就已经学习完毕了。对于我们现在编写的爬虫与大型爬虫的差距在于
      
    
    </summary>
    
      <category term="爬虫" scheme="http://example.com/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="Python" scheme="http://example.com/tags/Python/"/>
    
      <category term="爬虫" scheme="http://example.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>Python爬虫开发与项目实战-第二回合</title>
    <link href="http://example.com/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E7%88%AC%E8%99%AB/Python%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E4%B8%8E%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98-%E7%AC%AC%E4%BA%8C%E5%9B%9E%E5%90%88/"/>
    <id>http://example.com/wiki/程序技术/Python/爬虫/Python爬虫开发与项目实战-第二回合/</id>
    <published>2021-11-17T02:40:35.328Z</published>
    <updated>2021-11-17T08:30:36.279Z</updated>
    
    <content type="html"><![CDATA[<p>网络爬虫：是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本。</p><p>网络爬虫可以分为：</p><blockquote><ol><li>通用网络爬虫</li></ol></blockquote><p>通过搜索引擎搜索关键词，然后从搜索引擎返回的数据中，爬取想要的数据。</p><blockquote><ol><li>聚焦网络爬虫</li></ol></blockquote><p>有针对性的爬取指定的网页链接。定向爬取相关页面。</p><blockquote><ol><li>增量式网络爬虫</li></ol></blockquote><p>也就是爬取新的数据，而对于之前爬取过的数据，不会再进行爬取。</p><blockquote><ol><li>深层网络爬虫</li></ol></blockquote><p>也就是爬取一些不能通过静态链接获取的，需要用户操作后才能访问获取的Web页面。</p><h6 id="网络爬虫结构"><a href="#网络爬虫结构" class="headerlink" title="网络爬虫结构"></a>网络爬虫结构</h6><p>爬虫的一般流程：</p><ol><li>需要爬取页面的URL</li><li>读取URL，获取到网页数据</li><li>从网页数据提取有用数据</li><li>抽取网页需要进一步爬取URL，进行再次爬取</li></ol><p><img src="/images/爬虫流程.PNG" alt="1.1"></p><h6 id="Request库"><a href="#Request库" class="headerlink" title="Request库"></a>Request库</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Python对HTTP请求的支持：通过urllib2和urllib或者通过request模块。</span></span><br><span class="line"><span class="string">一般通过request实现http请求。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    #发送get请求</span></span><br><span class="line"><span class="string">    r = requests.get(&#x27;&#x27;)</span></span><br><span class="line"><span class="string">    # 对于带有参数的url，可以通过建立一个map作为参数进行请求</span></span><br><span class="line"><span class="string">    payload = &#123;&#x27;keywords&#x27;:&#x27;blog:qiyeboy&#x27;,&#x27;pageindex&#x27;:1&#125;</span></span><br><span class="line"><span class="string">    r = requests.get(&#x27;&#x27;,params=payload) #通过map提供参数</span></span><br><span class="line"><span class="string">    #发送post请求</span></span><br><span class="line"><span class="string">    r = requests.post(&#x27;&#x27;)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="comment">#chardet是用于检测文本编码</span></span><br><span class="line"><span class="keyword">import</span> chardet</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">requestTemp</span>():</span></span><br><span class="line">    r = requests.get(<span class="string">&#x27;www.baidu.com&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(r.content) <span class="comment"># 返回字节类型的数据</span></span><br><span class="line">    <span class="built_in">print</span>(r.text) <span class="comment"># 返回文本形式的html</span></span><br><span class="line">    <span class="built_in">print</span>(r.encoding) <span class="comment"># 返回网页编码格式</span></span><br><span class="line">    r.encoding = <span class="string">&#x27;utf-8&#x27;</span> <span class="comment"># 可以自定义编码格式。然后再读取网页文本数据，这样就不会乱码</span></span><br><span class="line">    <span class="built_in">print</span>(r.text) <span class="comment"># 这是在utf-8编码下的文本数据</span></span><br><span class="line">    <span class="comment">#通过chardet进行解码</span></span><br><span class="line">    r.encoding = chardet.detect(r.content)[<span class="string">&#x27;encoding&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">### 我们可以对请求头headers进行处理,即对请求设置请求头,设置Cookie</span></span><br><span class="line">    <span class="comment">### 对于请求头，我们可以通过f12查看请求头格式</span></span><br><span class="line">    user_agent = <span class="string">&#x27;Mozilla/4.0&#x27;</span></span><br><span class="line">    headers = &#123;<span class="string">&#x27;User-Agent&#x27;</span>:user_agent&#125; <span class="comment">#设置请求头</span></span><br><span class="line">    <span class="comment">#自定义Cookie</span></span><br><span class="line">    cookies = <span class="built_in">dict</span>(name=<span class="string">&#x27;qiye&#x27;</span>,age=<span class="string">&#x27;10&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    r = requests.get(<span class="string">&#x27;www.baidu.com&#x27;</span>,headers=headers,cookies=cookies)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取响应的Cookie值</span></span><br><span class="line">    <span class="keyword">for</span> cookie <span class="keyword">in</span> r.cookies.keys():</span><br><span class="line">        <span class="built_in">print</span>(r.cookies.get(cookie))</span><br><span class="line"></span><br><span class="line">    <span class="comment">### 获取返回状态编码，判断请求是否成功</span></span><br><span class="line">    <span class="keyword">if</span> r.status_code == requests.codes.ok :</span><br><span class="line">        <span class="built_in">print</span>(r.status_code)</span><br><span class="line">        <span class="built_in">print</span>(r.headers.get(<span class="string">&#x27;content-type&#x27;</span>))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        r.raise_for_status() <span class="comment">#通过raise_for_status可以抛出一个异常。</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">###自动处理Cookie方法 , 通过session，每次都可以将Cookie值带上</span></span><br><span class="line">    s = requests.Session()</span><br><span class="line">    r = s.get(<span class="string">&quot;wwww.baidu.com&quot;</span>,allow_redirects=<span class="literal">True</span>)</span><br><span class="line">    datas = &#123;<span class="string">&#x27;name&#x27;</span>:<span class="string">&#x27;qiyi&#x27;</span>,<span class="string">&#x27;passwd&#x27;</span>:<span class="string">&#x27;123&#x27;</span>&#125;</span><br><span class="line">    <span class="comment"># 通过Session机制，可以保证每次都加上了cookie的值，进行请求</span></span><br><span class="line">    r = s.post(<span class="string">&#x27;wwww.baidu.com&#x27;</span>,data=datas,allow_redirects=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 通过allow_redirects可以设置是否允许重定向</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 通过r.history可以获取到历史信息，也就是访问成功之前的所有请求跳转信息</span></span><br><span class="line">    <span class="built_in">print</span>(r.history)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#设置超时参数，Timeout</span></span><br><span class="line">    r = requests.get(<span class="string">&#x27;www.baidu.com&#x27;</span>,timeout=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#代理设置，使用代理Proxy,可以为任意请求方法通过设置proxies参数来配置单个请求</span></span><br><span class="line">    proxies = &#123;</span><br><span class="line">        <span class="string">&quot;http&quot;</span>:<span class="string">&quot;http://0.10.1.10:3128&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https&quot;</span>:<span class="string">&quot;http://10.10.1.10:1080&quot;</span>,</span><br><span class="line">        <span class="comment">#&quot;http&quot;:&quot;http://user:pass@10.10.1.10:3128&quot; #这是代理中身份认证的用户名和密码，来设置代理</span></span><br><span class="line">    &#125;</span><br><span class="line">    requests.get(<span class="string">&quot;www.baidu.com&quot;</span>,proxies=proxies) <span class="comment">#设置代理ip</span></span><br></pre></td></tr></table></figure><h6 id="网页解析"><a href="#网页解析" class="headerlink" title="网页解析"></a>网页解析</h6><p>我们通过requets可以下载网页中的文本，那么我们怎么通过下载的文本获取到想要的信息呢？这里就需要使用到文本解析技术了，常用的方法有很多，我们这里采用BeautifulSoup库进行解决。BeautifulSoup具备的解析器如下所示：</p><p>BeautifulSoup将HTML文档转换成一个复杂的树形结构，每个节点都是一个python对象，所有对象可以归纳为四种。</p><blockquote><ol><li>Tag</li><li>NavigableString</li><li>BeautifulSoup</li><li>Comment</li></ol></blockquote><p>BeautifulSoup对网页的解析，主要是搜索指定标签，遍历标签元素，提取标签内容。对于解析文本的方法，可以参考如下代码，本质上就是调用API定位到要爬取到的数据信息。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">正则表达式：</span></span><br><span class="line"><span class="string">\b: 匹配单词的开始或结束</span></span><br><span class="line"><span class="string">^:  匹配字符串的开始</span></span><br><span class="line"><span class="string">$:  匹配字符串的结束</span></span><br><span class="line"><span class="string">\w: 匹配字母，数字，下划线或汉字</span></span><br><span class="line"><span class="string">\s: 匹配任意空白字符</span></span><br><span class="line"><span class="string">\d: 匹配数字</span></span><br><span class="line"><span class="string">. : 匹配除换行符以外的任意字符</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">字符串转义: 通过\进行转义</span></span><br><span class="line"><span class="string">数量匹配：</span></span><br><span class="line"><span class="string">*：零次或多次</span></span><br><span class="line"><span class="string">+： 一次或多次</span></span><br><span class="line"><span class="string">？：零次或一次</span></span><br><span class="line"><span class="string">&#123;n&#125;: n次</span></span><br><span class="line"><span class="string">&#123;n,&#125;: n次或更多次</span></span><br><span class="line"><span class="string">&#123;n,m&#125; 重复n-m次</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">分支条件：</span></span><br><span class="line"><span class="string">正则表达式通过 | 表示或的关系。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    这里采用BeautifulSoup(美味汁)进行文本解析</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line">r = requests.get(<span class="string">&quot;http://www.baidu.com&quot;</span>)</span><br><span class="line">r.encoding = <span class="string">&#x27;utf-8&#x27;</span></span><br><span class="line">html = r.text</span><br><span class="line"><span class="comment"># 可以直接打开，不知道解析器，一般采用lxml解析器</span></span><br><span class="line">soup = BeautifulSoup(html,<span class="string">&#x27;lxml&#x27;</span>,from_encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> 获取对象属性():</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#Tag 对象</span></span><br><span class="line">    <span class="comment">#Tag对象就像html标签一样，直接通过soup.标签名进行对象的提取</span></span><br><span class="line">    <span class="comment">#要获取tag对象的属性，通过标签.name获取标签的名称 ， 并且可以设置标签的名称</span></span><br><span class="line">    <span class="comment">#如果需要获取标签的属性，如href和class之类的属性，则通过标签.get(属性名)</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(soup.a) <span class="comment"># 根据标签获取</span></span><br><span class="line">    <span class="built_in">print</span>(soup.a.name) <span class="comment">#获取标签名称</span></span><br><span class="line">    <span class="built_in">print</span>(soup.a.get(<span class="string">&#x27;href&#x27;</span>)) <span class="comment"># 获取属性名称</span></span><br><span class="line">    <span class="built_in">print</span>(soup.a.attrs) <span class="comment"># 获取标签中的所有属性</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果要修改标签中的属性，怎么获取也同样可以怎么设置</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># BeautifulSoup用NavigableString类来包装Tag中的字符串，通过标签.string就可以获取到标签内部的文字</span></span><br><span class="line">    <span class="built_in">print</span>(soup.a.string)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">type</span>(soup.a.string))</span><br><span class="line"></span><br><span class="line">    <span class="comment">#BeautifulSoup对象表示的是一个文档的全部内容。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> 遍历():</span></span><br><span class="line">    <span class="comment">### 遍历操作， beautiful soup 对文档树的遍历</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    1. contents</span></span><br><span class="line"><span class="string">    2.  children</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># contents属性，可以将tag的子节点列表输出</span></span><br><span class="line">    <span class="built_in">print</span>(soup.head.contents)</span><br><span class="line">    <span class="comment"># children属性返回的是一个生成器。可以对Tag的子节点进行循环</span></span><br><span class="line">    <span class="comment"># 也就是通过children可以迭代遍历节点的所有子节点.</span></span><br><span class="line">    <span class="keyword">for</span> child <span class="keyword">in</span> soup.head.children:</span><br><span class="line">        <span class="built_in">print</span>(child)</span><br><span class="line">    <span class="comment"># 如果要递归遍历所有标签的孙子结点，则通过desendants属性，对所有tag的子孙节点进行循环</span></span><br><span class="line">    <span class="comment"># 标签的内容也属于标签的子节点</span></span><br><span class="line">    <span class="keyword">for</span> child <span class="keyword">in</span> soup.head.descendants:</span><br><span class="line">        <span class="built_in">print</span>(child)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取结点的内容</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># stirng , 如果标记唯一就返回标记的内容，而如果标记不唯一，可能返回None</span></span><br><span class="line">    <span class="built_in">print</span>(soup.a.string)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># strings属性主要用于tag中包含多个字符串的情况，可以循环遍历</span></span><br><span class="line">    <span class="keyword">for</span> string <span class="keyword">in</span> soup.strings:</span><br><span class="line">        <span class="built_in">print</span>(string)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># stripped_strings 可以去掉输出字符串包含的空格或空行</span></span><br><span class="line">    <span class="keyword">for</span> string <span class="keyword">in</span> soup.stripped_strings:</span><br><span class="line">        <span class="built_in">print</span>(string)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取父节点，通过parent属性</span></span><br><span class="line">    <span class="built_in">print</span>(soup.a.parent)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取节点的所有父辈节点，通过parents属性</span></span><br><span class="line">    <span class="keyword">for</span> parent <span class="keyword">in</span> soup.a.parents:</span><br><span class="line">        <span class="keyword">if</span> parent <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="built_in">print</span>(parent)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(parent.name)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取节点的兄弟节点,空白或换行也可也被视作一个节点</span></span><br><span class="line">    <span class="comment"># next_sibling获取下一个兄弟节点</span></span><br><span class="line">    <span class="built_in">print</span>(soup.a.next_sibling)</span><br><span class="line">    <span class="comment"># previous_sibling获取上一个兄弟节点</span></span><br><span class="line">    <span class="built_in">print</span>(soup.a.previous_sibling)</span><br><span class="line">    <span class="comment"># 通过next_siblings或者previous_siblings可以对当前兄弟节点迭代输出</span></span><br><span class="line">    <span class="keyword">for</span> sibling <span class="keyword">in</span> soup.a.next_siblings:</span><br><span class="line">        <span class="built_in">print</span>(sibling)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取节点的前后节点。前后节点是不区分层次结构的前后关系，如&lt;div&gt;&lt;a&gt;&lt;div&gt;,div的后一个节点就是a</span></span><br><span class="line">    <span class="comment"># next_element,previous_element,</span></span><br><span class="line">    <span class="built_in">print</span>(soup.a)</span><br><span class="line">    <span class="built_in">print</span>(soup.a.next_element)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果想遍历所有前后节点，通过next_elements和previous_elements进行遍历</span></span><br><span class="line">    <span class="keyword">for</span> element <span class="keyword">in</span> soup.a.next_elements:</span><br><span class="line">        <span class="built_in">print</span>(element)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 搜索文档树，搜索指定的内容</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> 搜索():</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># find_all()方法，搜索当前tag的所有tag子节点，判断是否满足搜索条件</span></span><br><span class="line">    <span class="comment"># find_add(name,attrs,recursive,txext,**kwargs)</span></span><br><span class="line">    <span class="comment"># name参数可以查找所有名字为name的标记,返回列表.一般用这个来找指定的标签</span></span><br><span class="line">    <span class="comment"># name参数可以是单独的字符，也可以是字符列表。</span></span><br><span class="line">    <span class="comment"># 可以自定义过滤器，用于匹配指定规则的标签</span></span><br><span class="line">    <span class="built_in">print</span>(soup.find_all(<span class="string">&#x27;a&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(soup.find_all([<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>]))</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">hasClass_Id</span>(<span class="params">tag</span>):</span></span><br><span class="line">        <span class="keyword">return</span> tag.has_attr(<span class="string">&#x27;class&#x27;</span>) <span class="keyword">and</span> tag.has_attr(<span class="string">&#x27;id&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(soup.find_all(hasClass_Id)) <span class="comment"># 寻找满足匹配规则的标签</span></span><br><span class="line">    <span class="comment"># 多条件过滤标签</span></span><br><span class="line">    <span class="comment"># 可以在find_all()中根据属性搜索指定的标签，并且可以将正则表达式作为搜索条件</span></span><br><span class="line">    <span class="built_in">print</span>(soup.find_all(<span class="string">&#x27;a&#x27;</span>,href=re.<span class="built_in">compile</span>(<span class="string">&#x27;elsie&#x27;</span>),<span class="built_in">id</span>=<span class="string">&#x27;12&#x27;</span>,class_=<span class="string">&#x27;sister&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">#如果要限制搜索数目，则通过limit参数进行限制</span></span><br><span class="line">    <span class="built_in">print</span>(soup.find_all(<span class="string">&#x27;a&#x27;</span>,limit=<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 限制只搜索直接节点，而不搜索子孙节点，设置recursive = False</span></span><br><span class="line">    <span class="built_in">print</span>(soup.find_all(<span class="string">&#x27;a&#x27;</span>,limit=<span class="number">5</span>),recursive=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># CSS选择器</span></span><br><span class="line">    <span class="comment"># 通过元素的CSS属性定位元素的位置</span></span><br><span class="line">    <span class="comment"># 根据name属性通过.class值 , 根据id属性通过#id值</span></span><br><span class="line">    <span class="comment"># 返回类型为list</span></span><br><span class="line">    <span class="comment">#找到所有a标签</span></span><br><span class="line">    soup.select(<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">    <span class="comment">#找到a标签，id为1</span></span><br><span class="line">    soup.select(<span class="string">&#x27;a#1&#x27;</span>)</span><br><span class="line">    <span class="comment">#根据name查询</span></span><br><span class="line">    soup.select(<span class="string">&#x27;.classs&#x27;</span>)</span><br><span class="line">    <span class="comment">#通过判断是否存在某个属性进行查找</span></span><br><span class="line">    soup.select(<span class="string">&#x27;a[href]&#x27;</span>)</span><br><span class="line">    <span class="comment">#通过属性值查找 ， test可以是待查找的字符串，可以通过正则表达式查询</span></span><br><span class="line">    <span class="comment">#href^= &quot;&quot; , href$= , href*= , 进行正则判断。</span></span><br><span class="line">    soup.select(<span class="string">&#x27;a[href=&quot;test&quot;]&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;网络爬虫：是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本。&lt;/p&gt;
&lt;p&gt;网络爬虫可以分为：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;通用网络爬虫&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;通过搜索引擎搜索关键词，然后从搜索引擎返回的数据
      
    
    </summary>
    
      <category term="爬虫" scheme="http://example.com/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="Python" scheme="http://example.com/tags/Python/"/>
    
      <category term="爬虫" scheme="http://example.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>Python爬虫与开发项目实战——第一回合</title>
    <link href="http://example.com/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E7%88%AC%E8%99%AB/Python%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E4%B8%8E%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/"/>
    <id>http://example.com/wiki/程序技术/Python/爬虫/Python爬虫开发与项目实战/</id>
    <published>2021-11-15T07:44:24.136Z</published>
    <updated>2021-11-17T02:40:05.260Z</updated>
    
    <content type="html"><![CDATA[<h5 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h5><font color="red" size=3>&nbsp;&nbsp;&nbsp;&nbsp;这一系列主要是对爬虫进一步深入了解,学习之前已经了解过爬虫，并编写过相应的代码，现在阅读书籍，进一步对爬虫的原理进行理解。大家可以通过该系列的开发过程，掌握爬虫的运用，以及进一步了解爬虫的原理。</font><ol><li><h6 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h6></li></ol><p>把内存中的变量变成可存储或可传输的过程，就是序列化。将内存中的变量序列化之后，可以把序列化后的内容写入磁盘，或者通过网络传输到别的机器上，实现程序状态的保存和共享。反过来，把变量内容从序列化的对象重新读取到内存，称为反序列化。</p><blockquote><p>也就是说，序列化就是保存了变量的一个快照(某个时刻的值)。反序列化就是根据保存的快照，将值赋值给变量，这样就回到了那个时刻(因为各个变量的值都一样)。<br>Python对序列化的支持：cPickle和pickle来实现序列化。一般都是先导入cPickle模块。实例代码如下:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### 导入序列化模块</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">import</span> cPickle <span class="keyword">as</span> pickle</span><br><span class="line"><span class="keyword">except</span> ImportError:</span><br><span class="line">    <span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    pickle实现序列化主要使用dumps方法或dump方法，</span></span><br><span class="line"><span class="string">    dumps方法可以将任意对象序列化成一个str，然后可以将这个str写入文件进行保存.</span></span><br><span class="line"><span class="string">    dump方法可以将序列化后的对象直接写入到文件中</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    pickle实现反序列化，主要通过loads或load方法，把序列化后的文件从磁盘上读取一个str，然后使用loads方法将str转化位对象</span></span><br><span class="line"><span class="string">    或者直接使用load方法将文件直接反序列化位对象</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment">#dumps</span></span><br><span class="line">d = <span class="built_in">dict</span>(url=<span class="string">&quot;index.html&quot;</span>,title=<span class="string">&quot;首页&quot;</span>,content=<span class="string">&quot;首页&quot;</span>)</span><br><span class="line"><span class="built_in">str</span> = pickle.dumps(d)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">str</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#dump</span></span><br><span class="line">f = <span class="built_in">open</span>(<span class="string">r&#x27;dump.txt&#x27;</span>,<span class="string">&#x27;wb&#x27;</span>)</span><br><span class="line">pickle.dump(d,f)</span><br><span class="line">f.close()</span><br><span class="line"></span><br><span class="line"><span class="comment">#通过load方法</span></span><br><span class="line">f = <span class="built_in">open</span>(<span class="string">r&#x27;dump.txt&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>)</span><br><span class="line">d = pickle.load(f)</span><br><span class="line">f.close()</span><br><span class="line"><span class="built_in">print</span>(d)</span><br></pre></td></tr></table></figure></p></blockquote><ol><li><h6 id="进程和多进程"><a href="#进程和多进程" class="headerlink" title="进程和多进程"></a>进程和多进程</h6></li></ol><p>python对多进程的方法：一种通过os模块的fork方法(适用于unix和linux操作系统)，一种通过multiprocessing模块(跨平台的实现方式)。这里主要采用Multiprocessing来创建多进程.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#multiprocessing模块创建多进程</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#通过Process类来描述一个进程对象，创建子进程时，只需要传入一个执行函数和函数参数，</span></span><br><span class="line"><span class="comment">#即可完成一个Process实例的创建，用strt()方法启动进程，用join方法实现进程间的同步</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#子进程要执行的代码</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_proc</span>(<span class="params">name</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Child process %s (%s) Running...&#x27;</span>%(name,os.getpid()))</span><br><span class="line"></span><br><span class="line"><span class="comment">##进程池任务</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_task</span>(<span class="params">name</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Task %s (pid=%s) is runing...&#x27;</span>%(name,os.getpid()))</span><br><span class="line">    time.sleep(random.random()*<span class="number">3</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Task %s end.&#x27;</span>%name)</span><br><span class="line"><span class="comment">#写数据进程执行的代码</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">proc_write</span>(<span class="params">q,urls</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Process(%s) is writing...&#x27;</span>%os.getpid())</span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">        q.put(url)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Put %s queue...&#x27;</span>%url)</span><br><span class="line">        time.sleep(random.random())</span><br><span class="line"><span class="comment">#读数据进程执行的代码</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">proc_read</span>(<span class="params">q</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Process(%s) is reading&#x27;</span>%os.getpid())</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        url = q.get(<span class="literal">True</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Get %s from queue.&#x27;</span>%url)</span><br><span class="line"><span class="function"><span class="keyword">def</span> 多进程():</span></span><br><span class="line">    <span class="comment"># print(&#x27;Parent process %s.&#x27;%os.getpid())</span></span><br><span class="line">    <span class="comment"># for i in range(5):</span></span><br><span class="line">    <span class="comment">#     p = Process(target=run_proc,args=(str(i),))#指定子进程要执行的方法，以及传递的参数</span></span><br><span class="line">    <span class="comment">#     print(&#x27;Process will start.&#x27;)</span></span><br><span class="line">    <span class="comment">#     p.start()</span></span><br><span class="line">    <span class="comment"># p.join()</span></span><br><span class="line">    <span class="comment"># print(&#x27;Process end&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 通过进程池创建多个进程</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Current process %s.&#x27;</span> % os.getpid())</span><br><span class="line">    p = Pool(processes=<span class="number">3</span>)  <span class="comment"># 创建进程池，指定进程池中进程的个数，默认位CPU核数</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        p.apply_async(run_task, args=(i,))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Waiting for all subprocess done ...&#x27;</span>)</span><br><span class="line">    p.close()  <span class="comment"># g关闭进程池，就不能继续向进程池中添加新的任务</span></span><br><span class="line">    p.join()  <span class="comment"># 使用join表示等待所有子进程结束</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 进程通信 通过Queue或者Pipe(一般用于两个进程通信)实现进程通信</span></span><br><span class="line">    <span class="comment"># 通过Queue进行get和put操作，可以设置blocked和timeout两个属性，blocked是设定操作是否阻塞</span></span><br><span class="line">    <span class="comment"># timeout是设置操作的等待时间。</span></span><br><span class="line">    q = Queue()  <span class="comment"># 创建消息队列</span></span><br><span class="line">    proc_write1 = Process(target=proc_write, args=(q, [<span class="string">&#x27;url_1&#x27;</span>, <span class="string">&#x27;url_2&#x27;</span>, <span class="string">&#x27;url_3&#x27;</span>]))</span><br><span class="line">    proc_write2 = Process(target=proc_write, args=(q, [<span class="string">&#x27;url_4&#x27;</span>, <span class="string">&#x27;url_5&#x27;</span>, <span class="string">&#x27;url_6&#x27;</span>]))</span><br><span class="line">    proc_reader = Process(target=proc_read, args=(q,))</span><br><span class="line">    <span class="comment"># 启动子进程proc_writer写入</span></span><br><span class="line">    proc_write1.start()</span><br><span class="line">    proc_write2.start()</span><br><span class="line">    <span class="comment"># 启动子进程读取</span></span><br><span class="line">    proc_reader.start()</span><br><span class="line">    <span class="comment"># 等待写入结束</span></span><br><span class="line">    proc_write1.join()</span><br><span class="line">    proc_write2.join()</span><br><span class="line">    <span class="comment"># 由于读取是死循环，所以只能强行终止</span></span><br><span class="line">    proc_reader.terminate()</span><br></pre></td></tr></table></figure></p><ol><li><h6 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h6></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#多线程</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">thread_run</span>(<span class="params">urls</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Current %s is running ...&#x27;</span>%threading.current_thread().name)</span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;%s ------&gt;&gt;&gt; %s&#x27;</span>%(threading.current_thread().name,url))</span><br><span class="line">        time.sleep(random.random())</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;%s ended.&#x27;</span>% threading.current_thread().name)</span><br><span class="line"></span><br><span class="line"><span class="comment">#继承创建线程类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyThread</span>(<span class="params">threading.Thread</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,name,urls</span>):</span></span><br><span class="line">        threading.Thread.__init__(self,name=name)</span><br><span class="line">        self.urls =urls</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Current %s is running ...&#x27;</span> % threading.current_thread().name)</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> self.urls:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;%s ------&gt;&gt;&gt; %s&#x27;</span> % (threading.current_thread().name, url))</span><br><span class="line">            time.sleep(random.random())</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;%s ended.&#x27;</span> % threading.current_thread().name)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;in&#x27;</span>)</span><br><span class="line">    <span class="string">&quot;&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        多线程，线程类似于执行多个不同的程序，多线程可以将允许时间长的任务放到后台处理。</span></span><br><span class="line"><span class="string">        Python对多线程的支持，thread和threading，一般我们使用threading模块</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;%s is running...&#x27;</span>%threading.current_thread().name)</span><br><span class="line">    t1 = threading.Thread(target=thread_run,name=<span class="string">&#x27;Thread_1&#x27;</span>,args=([<span class="string">&#x27;url_1&#x27;</span>,<span class="string">&#x27;url_2&#x27;</span>,<span class="string">&#x27;url_3&#x27;</span>],))</span><br><span class="line">    t2 = threading.Thread(target=thread_run, name=<span class="string">&#x27;Thread_2&#x27;</span>, args=([<span class="string">&#x27;url_4&#x27;</span>, <span class="string">&#x27;url_5&#x27;</span>, <span class="string">&#x27;url_6&#x27;</span>],))</span><br><span class="line">    t1.start()</span><br><span class="line">    t2.start()</span><br><span class="line">    t1.join()</span><br><span class="line">    t2.join()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;%s ended.&#x27;</span>%threading.current_thread().name)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#自定义线程类</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;%s is running...&#x27;</span> % threading.current_thread().name)</span><br><span class="line">    t1 = MyThread(  name=<span class="string">&#x27;Thread_1&#x27;</span>, urls=([<span class="string">&#x27;url_1&#x27;</span>, <span class="string">&#x27;url_2&#x27;</span>, <span class="string">&#x27;url_3&#x27;</span>]))</span><br><span class="line">    t2 = MyThread(  name=<span class="string">&#x27;Thread_2&#x27;</span>, urls=([<span class="string">&#x27;url_4&#x27;</span>, <span class="string">&#x27;url_5&#x27;</span>, <span class="string">&#x27;url_6&#x27;</span>]))</span><br><span class="line">    t1.start()</span><br><span class="line">    t2.start()</span><br><span class="line">    t1.join()</span><br><span class="line">    t2.join()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;%s ended.&#x27;</span> % threading.current_thread().name)</span><br><span class="line"></span><br><span class="line">    <span class="comment">##线程同步</span></span><br><span class="line">    <span class="comment">##一般通过Thread的Lock和RLock实现简单的线程同步，两个对象都有acquire和release方法</span></span><br><span class="line">    mylock = threading.RLock() <span class="comment">#创建一个锁</span></span><br><span class="line">    num = <span class="number">0</span></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">myThread1</span>(<span class="params">threading.Thread</span>):</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,name</span>):</span></span><br><span class="line">            threading.Thread.__init__(self,name=name)</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self</span>):</span></span><br><span class="line">            <span class="keyword">global</span> num</span><br><span class="line">            <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">                mylock.acquire()</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;%s locked,Number :%d&#x27;</span>%(threading.current_thread().name,num))</span><br><span class="line">                <span class="keyword">if</span> num &gt;=<span class="number">4</span> :</span><br><span class="line">                    mylock.release()</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&#x27;%s released, Number: %s&#x27;</span>%(threading.current_thread().name,num))</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                num += <span class="number">1</span></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;%s released Number %s&#x27;</span>%(threading.current_thread().name,num))</span><br><span class="line">                mylock.release()</span><br><span class="line">    thread1 = myThread1(<span class="string">&#x27;Thread_1&#x27;</span>)</span><br><span class="line">    thread2 = myThread1(<span class="string">&#x27;Thread_2&#x27;</span>)</span><br><span class="line">    thread1.start()</span><br><span class="line">    thread2.start()</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol><li>协程</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#各个协程执行的任务</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_task</span>(<span class="params">url</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Visis --&gt; %s&#x27;</span>%url)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        data  = urllib3.connection_from_url(url=url).urlopen(url=url,method=<span class="string">&quot;GET&quot;</span>).data</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;%s bytes received from %s.&#x27;</span>%(<span class="built_in">len</span>(data),url))</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;in&#x27;</span>)</span><br><span class="line">    <span class="comment"># 协程又称微线程(纤程),用户级的轻量级线程</span></span><br><span class="line">    <span class="comment">#协程能够保留上一次调用时的状态</span></span><br><span class="line">    <span class="comment">#Python对写出的支持通过gevent库，Python通过yield提供对协程的基本支持但是不完全，所以使用</span></span><br><span class="line">    <span class="comment">#gevent更加好</span></span><br><span class="line">    <span class="comment">#gevent实际上是greenlet在实现切换工作。如果出现io阻塞的时候，gevent会自动切换到没有阻塞的代码执行</span></span><br><span class="line">    <span class="comment">#所以gevent一直保持greenlet在允许</span></span><br><span class="line">    urls = [<span class="string">&#x27;https://github.com/&#x27;</span>,<span class="string">&#x27;https://www.python.org/&#x27;</span>,<span class="string">&#x27;http://www.baidu.com/&#x27;</span>] <span class="comment"># 各个协程访问的网址</span></span><br><span class="line">    greenlets = [gevent.spawn(run_task,url) <span class="keyword">for</span> url <span class="keyword">in</span> urls] <span class="comment"># 这里将各个协程加入到greenlets中</span></span><br><span class="line">    gevent.joinall(greenlets=greenlets) <span class="comment">#进行执行各个协程</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><ol><li>分布式进程</li></ol><p>分布式进程：分布式也就是将计算任务分布到多个计算机上进行运算，然后将结果返回。分布式进程也就是指，将Process进程分不到多台机器，利用多台机器的性能，完成复杂的任务。</p><p>对于分布式进程，通过multiprocessing模块的managers子模块，将多线程分布到多台机器上。</p><p>一般我们通过分布式处理任务，将某块的任务分配给某个机器执行，然后某个功能模块给其他模块执行。将任务分成多个计算机集群进行处理，提高速度。例如爬取图片，可以一个计算机专门爬取图片链接，然后多个计算机专门根据爬取到的图片链接下载图片。<br>将中间处理的结果，让其他机器进程都能访问的过程称为本地队列的网络化。过程如下所示：<br><img src="/images/分布式.PNG" alt="a5"></p><p>两个实现代码</p><p>taskManager.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> queue</span><br><span class="line"><span class="keyword">from</span> multiprocessing.managers <span class="keyword">import</span> BaseManager</span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> freeze_support</span><br><span class="line"></span><br><span class="line"><span class="comment">#服务进程</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#任务个数</span></span><br><span class="line">task_number = <span class="number">10</span></span><br><span class="line"><span class="comment">#定义收发队列</span></span><br><span class="line">task_queue = queue.Queue(task_number)</span><br><span class="line">result_queue = queue.Queue(task_number)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_task</span>():</span></span><br><span class="line">    <span class="keyword">return</span> task_queue</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_result</span>():</span></span><br><span class="line">    <span class="keyword">return</span> result_queue</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建类似的QueueManager</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QueueManager</span>(<span class="params">BaseManager</span>):</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">win_run</span>():</span></span><br><span class="line">    <span class="comment">#Windows下绑定调用接口</span></span><br><span class="line">    QueueManager.register(<span class="string">&#x27;get_task_queue&#x27;</span>,<span class="built_in">callable</span>=get_task)</span><br><span class="line">    QueueManager.register(<span class="string">&#x27;get_result_queue&#x27;</span>,<span class="built_in">callable</span>=get_result)</span><br><span class="line">    <span class="comment">#绑定端口并设置验证口令，Windows下需要填写IP地址</span></span><br><span class="line">    manager = QueueManager(address=(<span class="string">&#x27;127.0.0.1&#x27;</span>,<span class="number">8001</span>),authkey=<span class="string">&#x27;qiye&#x27;</span>.encode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line">    <span class="comment">#启动</span></span><br><span class="line">    manager.start()</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment">#通过网络获取任务队列和结果队列</span></span><br><span class="line">        task = manager.get_task_queue()</span><br><span class="line">        result = manager.get_result_queue()</span><br><span class="line">        <span class="comment">#添加任务</span></span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> [<span class="string">&#x27;ImageUrl_&#x27;</span>+<span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;put task %s...&#x27;</span>%url)</span><br><span class="line">            task.put(url)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;try get result...&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;result is %s &#x27;</span>%result.get(timeout=<span class="number">10</span>))</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Manager error&#x27;</span>)</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">            <span class="comment">#一定要关闭，否则会报管道未关闭的错误</span></span><br><span class="line">            manager.shutdown()</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment">#Windows多线程可能有问题，进行缓解</span></span><br><span class="line">    freeze_support()</span><br><span class="line">    win_run()</span><br></pre></td></tr></table></figure></p><p>taskWorker.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> multiprocessing.managers <span class="keyword">import</span>  BaseManager</span><br><span class="line"></span><br><span class="line"><span class="comment">#处理进程</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#创建类似的QueueManager</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QueueManager</span>(<span class="params">BaseManager</span>):</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="comment">#第一步使用Queuemanager注册用于获取Queueu的方法名称</span></span><br><span class="line">QueueManager.register(<span class="string">&#x27;get_task_queue&#x27;</span>)</span><br><span class="line">QueueManager.register(<span class="string">&#x27;get_result_queue&#x27;</span>)</span><br><span class="line"><span class="comment">#第二部连接到服务器</span></span><br><span class="line">server_addr =  <span class="string">&#x27;127.0.0.1&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Connect to server %s...&#x27;</span>%server_addr)</span><br><span class="line"><span class="comment">#端口哦和验证口令</span></span><br><span class="line">m = QueueManager(address=(server_addr,<span class="number">8001</span>),authkey=<span class="string">&#x27;qiye&#x27;</span>.encode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line"><span class="comment">#从网络链接</span></span><br><span class="line">m.connect()</span><br><span class="line"><span class="comment">#第三步获取Queue的对象</span></span><br><span class="line">task = m.get_task_queue()</span><br><span class="line">result = m.get_result_queue()</span><br><span class="line"><span class="comment">#第四步，从task队列获取任务，把结果写入到result队列</span></span><br><span class="line"><span class="keyword">while</span>(<span class="keyword">not</span> task.empty()):</span><br><span class="line">    image_url = task.get(<span class="literal">True</span>,timeout=<span class="number">5</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;run task download %s...&#x27;</span>%image_url)</span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line">    result.put(<span class="string">&quot;%s---&gt;success&quot;</span>%image_url)</span><br><span class="line"><span class="comment">#处理结束</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;worker exit .&#x27;</span>)</span><br></pre></td></tr></table></figure></p><ol><li>网络编程</li></ol><p>两台计算机之间的通信，实际上是两台计算机，端口之间的通信。当在浏览器浏览网页的时候，实际上就是本地计算机的一个端口进程和服务器的某个端口进程建立了连接，并进行通信。</p><p>一般通过Socket（套接字）,描述通信。Socket由ip+端口组成。Python提供了两个Socket模块。<br>Socket：提供了标准的BSD Sockets API<br>SocketServer: 提供了服务器中心类，可以简化网络服务器的开发。</p><blockquote><p>Socket类型<br>套接字格式为：socket(family,type[,protocal]),使用给定的地址族，套接字类型，协议编号（默认为0）来创建套接字。<br>套接字类型如下所示：<br><img src="/images/Socket类型.PNG" alt="a6"></p><p>Socket常用函数<br><img src="/images/Socket2.PNG" alt="a61"></p><p>TCP编程</p></blockquote><p>TCP-Server.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 网络编程包含两个部分：服务端和客户端</span></span><br><span class="line"><span class="comment"># TCP是面向连接的通信方式</span></span><br><span class="line"><span class="comment"># 主动发起连接的叫做客户端</span></span><br><span class="line"><span class="comment"># 被动响应连接的叫服务端</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建TCP服务端</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">1. 创建Socket,绑定Socket到本地IP与端口</span></span><br><span class="line"><span class="string">2. 开始监听连接</span></span><br><span class="line"><span class="string">3. 进入循环，不断接收客户端的连接请求</span></span><br><span class="line"><span class="string">4.接收传来的数据，并发送给对方数据</span></span><br><span class="line"><span class="string">5.传输完毕后，关闭Socket</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dealClient</span>(<span class="params">sock,addr</span>):</span></span><br><span class="line">    <span class="comment"># 第四步：接收传来的数据，并发送给对方数据</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Accept new connection from %s:%s...&#x27;</span>%(sock,addr))</span><br><span class="line">    sock.send(<span class="string">b&#x27;Hello,I am server!&#x27;</span>)<span class="comment">#发送数据</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        data = sock.recv(<span class="number">1024</span>) <span class="comment">#接收数据</span></span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> data <span class="keyword">or</span> data.decode(<span class="string">&#x27;utf-8&#x27;</span>) == <span class="string">&#x27;exit&#x27;</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;----&gt;&gt;&gt;%s!&#x27;</span>%data.decode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line">        sock.send((<span class="string">&#x27;Loop_Msg:%s!&#x27;</span>%data.decode(<span class="string">&#x27;utf-8&#x27;</span>)).encode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line">    <span class="comment">#关闭Socket</span></span><br><span class="line">    sock.close()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Connection from %s:%s closed.&#x27;</span>%(sock,addr))</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment">#第一步：创建基于IPv4和TCP协议的Socket</span></span><br><span class="line">    <span class="comment">#Socket绑定IP（127.0.0.1为本机IP）与端口</span></span><br><span class="line">    s = socket.socket(socket.AF_INET,socket.SOCK_STREAM)</span><br><span class="line">    s.bind((<span class="string">&#x27;127.0.0.1&#x27;</span>,<span class="number">9999</span>))</span><br><span class="line">    <span class="comment">#第二步：监听连接</span></span><br><span class="line">    s.listen(<span class="number">5</span>)<span class="comment">#最大连接数量</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Waiting for connection...&#x27;</span>)</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="comment">#第三步: 接收一个新连接</span></span><br><span class="line">        sock,addr = s.accept()</span><br><span class="line">        <span class="comment">#创建新线程来处理TCP连接</span></span><br><span class="line">        t = threading.Thread(target=dealClient,args=(sock,addr,))</span><br><span class="line">        t.start()</span><br><span class="line"></span><br></pre></td></tr></table></figure><br>TCP-Client.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#TCP客户端</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">1.创建Socket，连接远端地址</span></span><br><span class="line"><span class="string">2.连接后发送数据和接收数据</span></span><br><span class="line"><span class="string">3.传输完毕后，关闭Socket</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="comment">#初始化Socket</span></span><br><span class="line">s = socket.socket(socket.AF_INET,socket.SOCK_STREAM)</span><br><span class="line"><span class="comment">#连接目标的ip和端口</span></span><br><span class="line">s.connect((<span class="string">&#x27;127.0.0.1&#x27;</span>,<span class="number">9999</span>))</span><br><span class="line"><span class="comment">#接收消息</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;---&gt;&gt;&gt;&#x27;</span>+s.recv(<span class="number">1024</span>).decode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line"><span class="comment">#发送消息</span></span><br><span class="line">s.send(<span class="string">b&#x27;Hello,I am Client&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;---&gt;&#x27;</span>+s.recv(<span class="number">1024</span>).decode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line">s.send(<span class="string">b&#x27;exit&#x27;</span>)</span><br><span class="line"><span class="comment">#关闭Socket</span></span><br><span class="line">s.close()</span><br></pre></td></tr></table></figure></p><blockquote><p>UDP编程</p></blockquote><p>UDP-Server.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UDP 服务器端</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">UDP是面向无连接的协议。使用UDP协议时，不需要建立连接，只需要直到对方的IP地址和端口号，就可以直接发数据包。</span></span><br><span class="line"><span class="string">并不关心能够到达目的端。对于不要求可靠到达的数据，就可以使用UDP协议。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">服务端创建过程：</span></span><br><span class="line"><span class="string">    1. 创建Socket，绑定指定的ip和端口</span></span><br><span class="line"><span class="string">    2. 直接发送数据和接收数据</span></span><br><span class="line"><span class="string">    3. 关闭Socket</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建Socket,绑定指定IP和端口</span></span><br><span class="line"><span class="comment"># SOCK_DGRAM指定了这个Socket的类型是UDP，绑定端口和TCP示例一样</span></span><br><span class="line">s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)</span><br><span class="line">s.bind((<span class="string">&#x27;127.0.0.1&#x27;</span>, <span class="number">9999</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Bind UDP on 9999...&#x27;</span>)</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="comment"># 直接发送数据和接收数据</span></span><br><span class="line">    data, addr = s.recvfrom(<span class="number">1024</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Received from %s:%s. &#x27;</span> %(addr,data.decode(<span class="string">&#x27;utf-8&#x27;</span>)))</span><br><span class="line">    s.sendto(<span class="string">b&#x27;Hello,!&#x27;</span>, addr)</span><br><span class="line"></span><br></pre></td></tr></table></figure></p><p>DUP-Client.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#UDP的客户端</span></span><br><span class="line"><span class="comment"># UDP客户端，创建Socket即可与服务器数据交换。</span></span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line">s = socket.socket(socket.AF_INET,socket.SOCK_DGRAM)</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> [<span class="string">b&#x27;Hello&#x27;</span>,<span class="string">b&#x27;World&#x27;</span>]:</span><br><span class="line">    <span class="comment">#发送数据</span></span><br><span class="line">    s.sendto(data,(<span class="string">&#x27;127.0.0.1&#x27;</span>,<span class="number">9999</span>))</span><br><span class="line">    <span class="comment">#接收数据</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(s.recv(<span class="number">1024</span>).decode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">s.close()</span><br></pre></td></tr></table></figure><blockquote><p>小结</p></blockquote><p>两个计算机之间的通信是端口进程之间的通信。端口属于应用层。对于应用层之间的数据，通过运输层提供相应的数据。运输层的协议，有TCP和UDP传输协议。</p><p>对于TCP协议，是面向连接的，所以在使用tcp协议传送数据的时候，需要保证两个通信的主机建立了连接，然后再进行数据的传输。<br>&gt;</p><blockquote><p>  所以对于TCP而言，服务器和客户端的连接步骤<br>对于TCP服务器：</p><ol><li>创建Socket，绑定到对应端口</li><li>监听端口，检测是否有连接</li><li>如果有客户端连接，接收客户端连接，可以获得客户端的套接字</li><li>建立连接后，可以循环监听接收客户端发送的数据，也可发送数据给客户端</li><li>会话完毕，就可以关闭连接</li></ol><p>对于TCP客户端</p><ol><li>创建Socket</li><li>连接到服务器，然后建立连接</li><li>发送，接收数据</li><li>会话完毕，关闭连接</li></ol></blockquote><p>对于UDP协议，是面向无连接的，所以在使用UDP协议的时候，并不需要确定双方是否建立了连接，直接向对应的（地址，端口号），发送数据即可，不关心是否发送成功。同理，接收数据也是直接接收即可。因为发送的时候就是直接发到对应主机，然后接收直接接收即可。</p><blockquote><p>对于UDP服务器</p><ol><li>创建Socket,绑定端口</li><li>监听端口，查看是否有数据</li><li>接收到数据（data,addr），可以发送给数据到指定的addr</li></ol><p>对于UDP客户端</p><ol><li>创建Socket</li><li>向服务器(addr,post)发送数据</li><li>可以监听自己的计算机，是否有其他计算机发送的数据</li></ol><p>总结</p></blockquote><p>从上面TCP/UDP客户端和服务器的创建过程可以比较出，TCP需要确定连接，而对于UDP而言不需要确定是否连接成功。</p><ol><li>WEB前端基础</li></ol><blockquote><p>W3C标准</p></blockquote><p>W3C即万维网联盟，W3C标准是一系列标准的集合。</p><p>一个网页由三部分组成：结构(Structure),表现(Presentation),行为(Behavior)。对应</p><p>结构化标准语言：XHTML，XML<br>表现标准语言：CSS<br>行为标准：对象模型(如W3C DOM)，ECMAScript等。</p><p>HTML（超文本标记语言），也就是是一种标签语言。</p><p>CSS(层叠样式表): 用于解决内容和表现的分离。CSS主要由选择器+属性构成。选择器用于指定渲染元素，属性用于指定渲染效果。</p><p>JavaScript（轻量级脚本语言）</p><p>XPath: 一门在XML文档中查找信息的语言。</p><p>JSON：JavaScript对象表示法，用于存储和交换文本信息。</p><p>HTTP协议(超文本传输协议)，用于从www服务区传输超文本到本地浏览器的传送协议。HTTP协议永远都是客户端发起请求，服务器会送响应。</p><p>HTTP协议是一个无状态协议，同一个客户端的这次请求和上次请求没有对应关系。</p><p>HTTP状态码：</p><p>200—请求成功<br>301—资源网页被永久转移到其他URL<br>404—请求的资源不存在<br>500—内部服务器错误</p><p>1开头一般表示服务器收到请求，需要请求者继续执行操作<br>2开头一般表示请求操作成功<br>3开头一般表示重定向<br>4开头一般表示客户端错误<br>5开头一般表示服务器错误</p><blockquote><p>Cookie和Session都用于保存状态信息，Cookie保存在客户端，Session保存在服务器端。</p></blockquote><p>Cookie：服务器给每个Session分配一个唯一的JSESSIONID，并通过Cookie发送给客户端，当客户端发起新的请求的时候，将在Cookie头中携带JSESSIONID。这样服务器就能够找到这个客户端对应的Session。</p><p><img src="/images/Cookie.PNG" alt="a7"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h5 id=&quot;背景介绍&quot;&gt;&lt;a href=&quot;#背景介绍&quot; class=&quot;headerlink&quot; title=&quot;背景介绍&quot;&gt;&lt;/a&gt;背景介绍&lt;/h5&gt;&lt;font color=&quot;red&quot; size=3&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;这一系列主要是对爬虫进一步深入了
      
    
    </summary>
    
      <category term="爬虫" scheme="http://example.com/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="Python" scheme="http://example.com/tags/Python/"/>
    
      <category term="爬虫" scheme="http://example.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>4. Java对象与类</title>
    <link href="http://example.com/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Java/JavaSE/%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%AF%B9%E8%B1%A1%E4%B8%8E%E7%B1%BB/class/"/>
    <id>http://example.com/wiki/程序技术/Java/JavaSE/第四章-对象与类/class/</id>
    <published>2021-11-03T07:05:53.433Z</published>
    <updated>2021-11-15T07:43:27.465Z</updated>
    
    <content type="html"><![CDATA[<p>面向对象程序设计OOP(Object Oriented Programming)。</p><p>类用于描述对象所具有的属性和方法，具体的对象称为类的一个实例。</p><p>封装也就是将数据和行为组合在一个包中，并对对象的使用者隐藏了数据的实现方式。</p><p>对象的三个特性，行为，状态，标识。</p><p>对象的行为描述了对象具有哪些操作，对象的状态（状态也就是对象当前的特征信息）决定了在不同情况下相应的操作的响应，对象的标识描述了不同的实例对象。</p><blockquote><p>类之间的关系</p></blockquote><ol><li><p>依赖关系(uses-a)</p><p> 如果一个类A的方法使用了另一个类B，那么就形成了依赖关系。<br> A依赖于B。（过多的依赖会使得类之间的耦合度高）</p></li><li><p>聚合关系(has-a)</p><p> 如果类A包含一些类B，那么A和B是聚合关系。</p></li><li><p>继承关系(is-a)</p><p> 父类和子类的关系，也就是继承关系。</p></li></ol><p>UML（Unified Modeling Language,统一建模语言）中类关系的表示：<br><img src="/images/UML.PNG" alt="a1"></p><p>Java中的对象通过new进行创建，通过new创建一个新的对象变量。一个对象变量并没有实际包含一个对象，而仅仅引用一个对象。通过new 操作符的返回值也是一个引用。这可以理解为Java中所有的对象变量实际上就是一个指针，指向实际对象所在的地址。</p><blockquote><ol><li>更改器方法(get),访问器方法(set)</li></ol></blockquote><p>注意不要编写返回引用可变对象的访问器方法。如果返回了可变对象，那么在类外部对返回对象的改变，同时也会影响到类内部的变量。<br>如果需要返回一个可变对象的引用，首先因该对它进行克隆(clone)。对象的clone是指存放在另一个位置上的对象副本。<br>如果需要返回一个可变数据域的拷贝，就应该使用 clone。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Employee</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Employee other)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name.equals(other.name);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于上段代码，我们可以看出，在equals方法中，调用了other的私有变量。对于Javaa来说，类的方法可以访问该类的任何对象的遍私有变量。<br>类方法可以访问所属类的私有特性。</p><blockquote><ol><li>构造器</li></ol></blockquote><pre><code>•构造器与类同名•每个类可以有一个以上的构造器•构造器可以有 0 个、1 个或多个参数•构造器没有返回值•构造器总是伴随着 new 操作一起调用</code></pre><blockquote><ol><li>隐式参数与显示参数</li></ol></blockquote><p>以下列代码为例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">B</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span> a ;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">B</span><span class="params">(<span class="keyword">int</span> a)</span></span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.a = a ;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getA</span><span class="params">()</span></span>&#123;<span class="keyword">return</span> <span class="keyword">this</span>.a;&#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setA</span><span class="params">(<span class="keyword">int</span> a)</span></span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.a = a ;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>我们对于方法setA,可以看出对于参数a是显示的参数。而隐式参数是谁呢？隐式参数是调用该方法调用的类对象，通过关键字this表示隐式参数。</p><p>第一个参数称为隐式 （ implicit ) 参数， 是出现在方法名前的Employee 类对象。第二个参数位于方法名后面括号中的数值，这是一个显式 （ explicit)参数（ 有些人把隐式参数称为方法调用的目标或接收者。</p><p>也就是说，this表明该方法的调用者。</p><blockquote><ol><li>访问修饰符</li></ol></blockquote><div class="table-container"><table><thead><tr><th>修饰符</th><th>作用</th><th>作用域</th></tr></thead><tbody><tr><td>public</td><td>公开的</td><td>任意类都能访问</td></tr><tr><td>private</td><td>私有的</td><td>只能被定义它们的类使用</td></tr><tr><td>final</td><td>final 修饰符大都应用于基本 （primitive ) 类型域，或不可变（immutable)类的域（如果类中的每个方法都不会改变其对象， 这种类就是不可变的类)。</td></tr><tr><td>static</td><td>静态域（类域）和静态方法。对于静态域变量，该变量属于类，而不属于任何独立的对象，通过类就能够直接访问到静态域变量(公开的)，实例对象，也能够访问到该变量，但是该变量属于类，所有对象访问到的静态域对象都是一样的。对于静态域一般可以用于设置静态常量，通过类名就能引用，但是不会被修改。对于静态方法，加在方法名之前，静态方法可以通过类名直接调用，静态方法不属于单独的对象。静态方法不具有this参数，所以静态方法不能访问非静态域的实例域。</td></tr></tbody></table></div><p>在下面两种情下使用静态方法：</p><ol><li>一 方法不需要访问对象状态，其所需参数都是通过显式参数提供（例如：Math.pow) </li><li>一个方法只需要访问类的静态域（例如：Employee.getNextld）。</li></ol><h4 id="初始化数据域"><a href="#初始化数据域" class="headerlink" title="初始化数据域"></a>初始化数据域</h4><blockquote><p>默认域初始化</p></blockquote><p>如果在构造器中没有显式地给域赋予初值，那么就会被自动地赋为默认值： 数值为 0、布尔值为 false、 对象引用为 null。<br>尽量对对象进行赋初始值，而不是采用默认初始值</p><blockquote><p>构造器初始化<br>通过this可以调用同一个类的另一个构造器。如下所示：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Employee</span><span class="params">(String <span class="keyword">double</span>)</span></span>&#123;</span><br><span class="line">    <span class="comment">// calls Employee(String, double)</span></span><br><span class="line">    <span class="keyword">this</span>(<span class="string">&quot;Employee #&quot;</span> + nextld, s);</span><br><span class="line">    nextld++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>通过this，引用到了同一个Employee的另一个的构造函数，对类对象进行初始化。</p><p>在声明中赋值</p><p>在初始化块赋值</p></blockquote><p>初始块也就是通过{}包含的一段代码块。只要构造类的对象，这些块就会被执行。初始化块的执行顺序，首先运行初始化块，然后才运行构造器的主体部分。</p><p>对于静态域的初始化，需要加上关键字static<br>static{<br>    //进行初始化<br>}</p><blockquote><p>Java调用构造器的步骤</p></blockquote><ol><li>所有数据域被初始化默认值(0,false,null)</li><li>按照类声明中出现的次序，依次执行所有域初始化语句或初始化块。</li><li>如果构造器第一行调用了其它构造器，则调用其它构造器</li><li>执行这个构造器主体。</li></ol><p>构造器是最后执行的，先执行声明和代码块语句。</p><h4 id="Java参数调用"><a href="#Java参数调用" class="headerlink" title="Java参数调用"></a>Java参数调用</h4><p>方法参数共有两种类型：</p><ol><li>基本数据类型（数字、布尔值K</li><li>对象引用。</li></ol><p>Java 程序设计语言总是采用按值调用。也就是说， 方法得到的是所有参数值的一个拷贝，特别是，方法不能修改传递给它的任何参数变量的内容。一个方法，无法改变基本数据类型的参数，但是对象引用作为参数就不同了。对于引用参数就不一样了，方法得到的是对象引用的拷贝，对象引用及其他的拷贝同时引用同一个对象。</p><blockquote><p>总结</p></blockquote><ol><li>一个方法不能修改一个基本数据类型的参数（即数值型或布尔型）。</li><li>一个方法可以改变一个对象参数的状态。</li><li>一个方法不能让对象参数引用一个新的对象。（因为Java的引用对象，并不是真正的引用(只是值的传递),可以通过反证进行证明）</li></ol><h4 id="重载-overloading-和重写-overwrite"><a href="#重载-overloading-和重写-overwrite" class="headerlink" title="重载(overloading)和重写(overwrite)"></a>重载(overloading)和重写(overwrite)</h4><blockquote><p>重载</p></blockquote><p>如果多个方法（比如， StringBuilder 构造器方法）有相同的名字、 不同的参数，便产生了重载。对于不同的重载方法， 通过方法给出的参数类型和特定的方法调用所使用的值类型进行匹配来挑选相应的方法（返回值不作为特征）。。如果编译器找不到匹配的参数， 就会产生编译时错误，因为根本不存在匹配， 或者没有一个比其他的更好。（这个过程被称为重载解析（overloading resolution)。）</p><p>对于一个方法的签名(signature)，包含方法名，方法参数类型构成。方法签名=方法名(参数类型)。</p><blockquote><p>重写</p></blockquote><h4 id="Java的包"><a href="#Java的包" class="headerlink" title="Java的包"></a>Java的包</h4><p>Java允许使用包(package)将类组织起来，借助于包可以方便地组织自己的代码，并将自己的代码与别人提供的代码库分开管理。使用包的主要原因是确保类名的唯一性(全限定类名)，一般我们对包名的命名规则是以因特网域名的逆序形式作为包名，并且对于不同的项目使用不同的子包。</p><p>一个类可以使用所属包中的所有类，以及其他包中的公有类(public class)。</p><p>import语句不仅可以导入类，还增加了导入静态方法和静态域的功能。</p><blockquote><p>import static java.lang.System.*<br>通过上述语句就可以直接使用System类的静态方法和静态域，而不必加类名前缀。<br>这样就可以直接在程序中使用out.println(“hello world”);而不用加前缀。</p></blockquote><p>把一个类放到一个包中， 需要通过package 指定所属的包。如果没有设置，则类被放在默认的包(default package)。</p><blockquote><p>对于包的作用域</p></blockquote><p>对于标记public部分，可以被任意的类使用。标记为private部分，只能被定义它们的类使用。如果没有指定public或private，这个部分(类，方法或变量)可以被同一个包中的所有方法访问。</p><blockquote><p>类路径</p></blockquote><p>为了使类能够被多个程序共享，需要做到下面几点：</p><p>1 ) 把类放到一个目录中， 例如 /home/user/classdir。需要注意， 这个目录是包树状结构的基目录。如果希望将 com.horstmann.corejava.Employee 类添加到其中，这个Employee.class类文件就必须位于子目录 /home/user/classdir/com/horstmann/corejava 中。</p><p>2 ) 将 JAR 文件放在一个目录中，例如：/home/user/archives。</p><p>3 ) 设置类路径（classpath)。类路径是所有包含类文件的路径的集合。</p><h4 id="类路径包括："><a href="#类路径包括：" class="headerlink" title="类路径包括："></a>类路径包括：</h4><p>•基目录 /home/user/classdir或 c:\classes；</p><p>•当前目录 (.);</p><p>•JAR 文件 /home/user/archives/archive.jar或c:\archives\archive.jar </p><p>从 Java SE 6 开始，可以在 JAR 文件目录中指定通配符，如下：/home/user/dassdir:.:/home/aser/archives/<em><br>或者c:\classdir;.;c:\archives\</em></p><blockquote><p>假定虚拟机要搜寻 com.horstmann.corejava.Employee 类文件。它首先要查看存储在 jre/<br>lib 和jre/lib/ext 目录下的归档文件中所存放的系统类文件。显然，在那里找不到相应的类文件，然后再查看类路径。然后查找以下文件：</p><blockquote><p>•/home/user/classdir/com/horstmann/corejava/Employee.class<br>•com/horstmann/corejava/Employee.class 从当前目录开始<br>•com/horstmann/corejava/Employee.class inside /home/user/archives/archive.jar</p></blockquote><p>设置类路径</p></blockquote><p>如果需要指定类的路径，可以借助-classpath来指定类路径。</p><h4 id="文档注释"><a href="#文档注释" class="headerlink" title="文档注释"></a>文档注释</h4><blockquote><p>通过/<em>* </em>/开始注释。</p></blockquote><p>对于代码的描述性句子，一般在/<em>* </em>/第一行进行编写，对于概要性的句子，可以使用HTML修饰符进行修饰(但是不要使用h1标签),如果需要键入等宽代码，使用{@code}。</p><blockquote><p>方法主要使用的注释</p></blockquote><p>@param 变量描述</p><p>@return 返回值描述</p><p>@throws 抛出异常描述</p><blockquote><p>通用注释</p></blockquote><p>@author 姓名<br>@version 版本信息<br>@since 从哪个版本开始加入的<br>@deprecated 描述该类或方法或变量不再使用<br>@see 增加一个超级链接 , 可以通过全限定类名作为超链接<br>eg: @see com.itheima.Employee#raiseSalary(double ),链接指向Employee下的raiseSalary(double)方法</p><blockquote><p>总结</p></blockquote><p>所有Java对象都是在堆中构造的，构造器总是伴随着new操作符一起使用。</p><h4 id="类设计技巧"><a href="#类设计技巧" class="headerlink" title="类设计技巧"></a>类设计技巧</h4><ol><li>数据私有</li><li>对数据初始化</li><li>不要再类中使用过多的基本类型</li><li>不是所有的域都需要独立的get/set方法</li><li>将职责过多的类进行分解</li><li>类名和方法名要能够体现它们的职责，也就是见名知义</li><li>优先使用不可变的类</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;面向对象程序设计OOP(Object Oriented Programming)。&lt;/p&gt;
&lt;p&gt;类用于描述对象所具有的属性和方法，具体的对象称为类的一个实例。&lt;/p&gt;
&lt;p&gt;封装也就是将数据和行为组合在一个包中，并对对象的使用者隐藏了数据的实现方式。&lt;/p&gt;
&lt;p&gt;对象的
      
    
    </summary>
    
      <category term="JavaSE" scheme="http://example.com/categories/JavaSE/"/>
    
    
      <category term="JAVA" scheme="http://example.com/tags/JAVA/"/>
    
      <category term="JAVASE" scheme="http://example.com/tags/JAVASE/"/>
    
  </entry>
  
  <entry>
    <title>Anaconda配置</title>
    <link href="http://example.com/wiki/%E8%BD%AF%E4%BB%B6%E9%85%8D%E7%BD%AE/python/Anaconda/"/>
    <id>http://example.com/wiki/软件配置/python/Anaconda/</id>
    <published>2021-11-02T03:22:44.814Z</published>
    <updated>2021-11-02T03:25:18.217Z</updated>
    
    <content type="html"><![CDATA[<p>Anaconda下载地址：<a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/">https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/ </a>。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Anaconda下载地址：&lt;a href=&quot;https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/&quot;&gt;https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/ &lt;/a&gt;
      
    
    </summary>
    
      <category term="软件配置" scheme="http://example.com/categories/%E8%BD%AF%E4%BB%B6%E9%85%8D%E7%BD%AE/"/>
    
      <category term="python配置" scheme="http://example.com/categories/%E8%BD%AF%E4%BB%B6%E9%85%8D%E7%BD%AE/python%E9%85%8D%E7%BD%AE/"/>
    
    
      <category term="配置" scheme="http://example.com/tags/%E9%85%8D%E7%BD%AE/"/>
    
      <category term="python" scheme="http://example.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>hexo使用问题</title>
    <link href="http://example.com/wiki/%E8%BD%AF%E4%BB%B6%E9%85%8D%E7%BD%AE/hexo/%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"/>
    <id>http://example.com/wiki/软件配置/hexo/问题解决/</id>
    <published>2021-11-01T07:32:29.409Z</published>
    <updated>2021-11-02T03:22:35.748Z</updated>
    
    <content type="html"><![CDATA[<h3 id="如何解决wiki中图片显示不全"><a href="#如何解决wiki中图片显示不全" class="headerlink" title="如何解决wiki中图片显示不全"></a>如何解决wiki中图片显示不全</h3><p>只需要把图片放在images文件夹下， 然后通过/images/xxx.xx进行引用即可，这是通过绝对路径进行引用。如果要通过相对路径引用则每个md需要创建相应的文件夹存放图片，较为麻烦。</p><h3 id="如何解决wiki中mermaid流程图无法显示的问题"><a href="#如何解决wiki中mermaid流程图无法显示的问题" class="headerlink" title="如何解决wiki中mermaid流程图无法显示的问题"></a>如何解决wiki中mermaid流程图无法显示的问题</h3><ol><li>修改 /theme/Wikitten下的config.yml文件</li></ol><p>讲下列代码粘贴到文件末尾<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mermaid: <span class="comment">## mermaid url https://github.com/knsv/mermaid</span></span><br><span class="line">enable: true  </span><br><span class="line"><span class="comment"># default true</span></span><br><span class="line">version: <span class="string">&quot;7.1.2&quot;</span></span><br><span class="line"><span class="comment"># default v7.1.2</span></span><br><span class="line">options:  </span><br></pre></td></tr></table></figure></p><ol><li>下载mermaid</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install --save hexo-filter-mermaid-diagrams</span><br></pre></td></tr></table></figure><ol><li>找到Wikitten下layout下 common/footer.ejs ,替换如下代码</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&lt;footer id=<span class="string">&quot;footer&quot;</span>&gt;</span><br><span class="line">    &lt;% <span class="keyword">if</span> (theme.mermaid.enable) &#123; %&gt;</span><br><span class="line">        &lt;script src=<span class="string">&#x27;https://unpkg.com/mermaid@&lt;%= theme.mermaid.version %&gt;/dist/mermaid.min.js&#x27;</span>&gt;&lt;/script&gt;</span><br><span class="line">        &lt;script&gt;</span><br><span class="line">            <span class="keyword">if</span> (window.mermaid) &#123;</span><br><span class="line">                mermaid.initialize(&#123;</span><br><span class="line">                    theme: <span class="string">&#x27;forest&#x27;</span></span><br><span class="line">                &#125;);</span><br><span class="line">            &#125;</span><br><span class="line">        &lt;/script&gt;</span><br><span class="line">        &lt;% &#125; %&gt;</span><br><span class="line">            &lt;div <span class="class"><span class="keyword">class</span></span>=<span class="string">&quot;outer&quot;</span>&gt;</span><br><span class="line">                &lt;div id=<span class="string">&quot;footer-info&quot;</span> <span class="class"><span class="keyword">class</span></span>=<span class="string">&quot;inner&quot;</span>&gt;</span><br><span class="line">                    &lt;%= config.author || config.title %&gt; &amp;copy;</span><br><span class="line">                        &lt;%= date(<span class="keyword">new</span> Date(), <span class="string">&#x27;YYYY&#x27;</span>) %&gt;</span><br><span class="line">                            &lt;a rel=<span class="string">&quot;license&quot;</span> href=<span class="string">&quot;http://creativecommons.org/licenses/by-nc-nd/4.0/&quot;</span>&gt;&lt;img alt=<span class="string">&quot;Creative Commons License&quot;</span> style=<span class="string">&quot;border-width:0&quot;</span> src=<span class="string">&quot;https://i.creativecommons.org/l/by-nc-nd/4.0/80x15.png&quot;</span> /&gt;&lt;/a&gt;</span><br><span class="line">                            &lt;br&gt; Powered by &lt;a href=<span class="string">&quot;http://hexo.io/&quot;</span> target=<span class="string">&quot;_blank&quot;</span>&gt;Hexo&lt;/a&gt;. Theme - &lt;a href=<span class="string">&quot;https://github.com/zthxxx/hexo-theme-Wikitten&quot;</span>&gt;wikitten&lt;/a&gt;</span><br><span class="line">                            &lt;% <span class="keyword">if</span> (theme.plugins.busuanzi_count) &#123; %&gt;</span><br><span class="line">                                &lt;br&gt;</span><br><span class="line">                                &lt;span id=<span class="string">&quot;busuanzi_container_site_pv&quot;</span>&gt;&lt;i <span class="class"><span class="keyword">class</span></span>=<span class="string">&quot;fa fa-eye&quot;</span>&gt;&lt;/i&gt; &lt;span id=<span class="string">&quot;busuanzi_value_site_pv&quot;</span>&gt;&lt;/span&gt;&lt;/span&gt;</span><br><span class="line">                                &amp;nbsp;|&amp;nbsp;</span><br><span class="line">                                &lt;span id=<span class="string">&quot;busuanzi_container_site_pv&quot;</span>&gt;&lt;i <span class="class"><span class="keyword">class</span></span>=<span class="string">&quot;fa fa-user&quot;</span>&gt;&lt;/i&gt; &lt;span id=<span class="string">&quot;busuanzi_value_site_uv&quot;</span>&gt;&lt;/span&gt;&lt;/span&gt;</span><br><span class="line">                                &lt;% &#125; %&gt;</span><br><span class="line">                &lt;/div&gt;</span><br><span class="line">            &lt;/div&gt;</span><br><span class="line">&lt;/footer&gt;</span><br></pre></td></tr></table></figure><h3 id="解决Wiki无法渲染数学公式的问题"><a href="#解决Wiki无法渲染数学公式的问题" class="headerlink" title="解决Wiki无法渲染数学公式的问题"></a>解决Wiki无法渲染数学公式的问题</h3><ol><li>执行下列指令</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm uninstall hexo-renderer-marked --save</span><br><span class="line">npm install hexo-renderer-kramed --save</span><br></pre></td></tr></table></figure><ol><li>找到../node_modules/kramed/lib/rules/inline.js</li></ol><p>修改如下代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//escape: /^\\([\\`*&#123;&#125;\[\]()#$+\-.!_&gt;])/,      第11行，将其修改为</span></span><br><span class="line">escape: /^\\([`*\[\]()#$+\-.!_&gt;])/,</span><br><span class="line"><span class="comment">//em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,    第20行，将其修改为</span></span><br><span class="line">em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,</span><br></pre></td></tr></table></figure></p><ol><li>对需要使用MathJax公式的文章，修改文章标签,增加mathjax: true</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">mathjax: <span class="keyword">true</span></span><br><span class="line">---</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;如何解决wiki中图片显示不全&quot;&gt;&lt;a href=&quot;#如何解决wiki中图片显示不全&quot; class=&quot;headerlink&quot; title=&quot;如何解决wiki中图片显示不全&quot;&gt;&lt;/a&gt;如何解决wiki中图片显示不全&lt;/h3&gt;&lt;p&gt;只需要把图片放在images文件夹下
      
    
    </summary>
    
      <category term="软件配置" scheme="http://example.com/categories/%E8%BD%AF%E4%BB%B6%E9%85%8D%E7%BD%AE/"/>
    
      <category term="hexo" scheme="http://example.com/categories/%E8%BD%AF%E4%BB%B6%E9%85%8D%E7%BD%AE/hexo/"/>
    
    
      <category term="hexo" scheme="http://example.com/tags/hexo/"/>
    
      <category term="bug" scheme="http://example.com/tags/bug/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow2笔记-LeNet(经典卷积网络)</title>
    <link href="http://example.com/wiki/%E7%A8%8B%E5%BA%8F%E6%8A%80%E6%9C%AF/Python/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Tensorflow%E7%AC%94%E8%AE%B0/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/"/>
    <id>http://example.com/wiki/程序技术/Python/机器学习/Tensorflow笔记/经典卷积网络/</id>
    <published>2021-11-01T02:11:58.082Z</published>
    <updated>2021-11-02T02:56:20.465Z</updated>
    
    <content type="html"><![CDATA[<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>这里主要介绍卷积神经网络的经典网络，然后通过tensorflow进行实现（以上章的卷积神经网络实现代码为基础，进行实现）。</p><p>统计卷积网络神经网络层数一般只统计卷积计算层和全连接计算层。</p><blockquote><p>ImageNet</p></blockquote><p>ImageNet 是一个计算机视觉系统识别项目,是目前世界上图像识别最大的数据库。是美国斯坦福的计算机科学家，模拟人类的识别系统建立的。能够从图片识别物体。ImageNet是一个非常有前景的研究项目，未来用在机器人身上，就可以直接辨认物品和人了。</p><h3 id="经典卷积网络"><a href="#经典卷积网络" class="headerlink" title="经典卷积网络"></a>经典卷积网络</h3><pre class="mermaid">   graph LR    A(LeNet 1998) --> B(AlexNet 2012)    B --> C(VGGNet 2014)     C --> D(Inception Net 2014)     D --> E(ResNet 2015)</pre><h4 id="LeNet"><a href="#LeNet" class="headerlink" title="LeNet"></a>LeNet</h4><p>由Yann LeCun于1998年提出，卷积网络开篇之作。通过共享卷积核减少了网络的参数。LeNet如下所示(C5画错了是F5)</p><p><img src="/images/LeNet.PNG" alt="aaa"></p><p>LeNet提出的时候还没提出BN和Dropout层，所以LeNet网络不具有BN和Dropout层。</p><p>根据上图实现LeNet代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyLeNet</span>(<span class="params">Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MyLeNet, self).__init__()</span><br><span class="line">        self.c1 = Conv2D(filters=<span class="number">6</span>,kernel_size=(<span class="number">5</span>,<span class="number">5</span>),activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line">        self.p1 = MaxPool2D(pool_size=(<span class="number">2</span>,<span class="number">2</span>),strides=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.c2 = Conv2D(filters=<span class="number">16</span>,kernel_size=(<span class="number">5</span>,<span class="number">5</span>),activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line">        self.p2 = MaxPool2D(pool_size=(<span class="number">2</span>,<span class="number">2</span>),strides=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.flatten = Flatten()</span><br><span class="line">        self.f1 = Dense(<span class="number">120</span>,activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line">        self.f2 = Dense(<span class="number">84</span>,activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line">        self.f3 = Dense(<span class="number">10</span>,activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        x = self.c1(x)</span><br><span class="line">        x = self.p1(x)</span><br><span class="line">        x = self.c2(x)</span><br><span class="line">        x = self.p2(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 提取的特征作为神经网络的输入特征</span></span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        x = self.f1(x)</span><br><span class="line">        x = self.f2(x)</span><br><span class="line">        y = self.f3(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure><h4 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h4><p>AlexNet网络诞生于2012年，是Hinton代表作之一。使用relu激活函数，提升训练速度，使用Dropout缓解过拟合。<br><img src="/images/AlexNet.PNG" alt="a2"><br>AlexNet实现代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AlexNet</span>(<span class="params">Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(AlexNet, self).__init__()</span><br><span class="line">        <span class="comment"># 第一层</span></span><br><span class="line">        self.c1 = Conv2D(filters=<span class="number">96</span>,kernel_size=(<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">        self.b1 = BatchNormalization()</span><br><span class="line">        self.a1 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.p1 = MaxPool2D(pool_size=(<span class="number">3</span>,<span class="number">3</span>),strides=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#第二层</span></span><br><span class="line">        self.c2 = Conv2D(filters=<span class="number">256</span>,kernel_size=(<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">        self.b2 = BatchNormalization()</span><br><span class="line">        self.a2 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.p2 = MaxPool2D(pool_size=(<span class="number">3</span>,<span class="number">3</span>),strides=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#第三层</span></span><br><span class="line">        self.c3 = Conv2D(filters=<span class="number">384</span>,kernel_size=(<span class="number">3</span>,<span class="number">3</span>),padding=<span class="string">&#x27;same&#x27;</span>,activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#第四层</span></span><br><span class="line">        self.c4 = Conv2D(filters=<span class="number">384</span>,kernel_size=(<span class="number">3</span>,<span class="number">3</span>),padding=<span class="string">&#x27;same&#x27;</span>,activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#第五层</span></span><br><span class="line">        self.c5 = Conv2D(filters=<span class="number">256</span>,kernel_size=(<span class="number">3</span>,<span class="number">3</span>),padding=<span class="string">&#x27;same&#x27;</span>,activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.p3 = MaxPool2D(pool_size=(<span class="number">3</span>,<span class="number">3</span>),strides=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#神经网络计算层</span></span><br><span class="line">        self.flatten = Flatten()</span><br><span class="line">        self.f1 = Dense(<span class="number">2048</span>,activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.d1 = Dropout(<span class="number">0.5</span>)</span><br><span class="line">        self.f2 = Dense(<span class="number">84</span>,activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.d1 = Dropout(<span class="number">0.5</span>)</span><br><span class="line">        self.f3 = Dense(<span class="number">10</span>,activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        x = self.c1(x)</span><br><span class="line">        x = self.b1(x)</span><br><span class="line">        x = self.a1(x)</span><br><span class="line">        x = self.p1(x)</span><br><span class="line"></span><br><span class="line">        x = self.c2(x)</span><br><span class="line">        x = self.b2(x)</span><br><span class="line">        x = self.a2(x)</span><br><span class="line">        x = self.p2(x)</span><br><span class="line"></span><br><span class="line">        x = self.c3(x)</span><br><span class="line"></span><br><span class="line">        x = self.c4(x)</span><br><span class="line"></span><br><span class="line">        x = self.c5(x)</span><br><span class="line">        x = self.p3(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 提取的特征作为神经网络的输入特征</span></span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        x = self.f1(x)</span><br><span class="line">        x = self.d1(x)</span><br><span class="line">        x = self.f2(x)</span><br><span class="line">        x = self.d2(x)</span><br><span class="line">        y = self.f3(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure><h4 id="VGGNet"><a href="#VGGNet" class="headerlink" title="VGGNet"></a>VGGNet</h4><p>CGGNet诞生于2014年，当年ImageNet竞赛的亚军。使用小尺寸卷积核，在减少的参数的同时，提高了识别准确率。VGGNet网络结构框图如下所示。<br><img src="/images/VGGnet.PNG" alt="a3"></p><p>VGGNet的网络结构是：两次CBA，CBAPD，三次CBA , CBA,CBAPD。<br>实现代码如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VGGNet</span>(<span class="params">Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(VGGNet, self).__init__()</span><br><span class="line">        <span class="comment"># 首先重复两次CBA CBAPD</span></span><br><span class="line">        <span class="comment">#1</span></span><br><span class="line">        self.c1 = Conv2D(filters=<span class="number">64</span>,kernel_size=(<span class="number">3</span>,<span class="number">3</span>),padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b1 = BatchNormalization()</span><br><span class="line">        self.a1 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        self.c2 = Conv2D(filters=<span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b2 = BatchNormalization()</span><br><span class="line">        self.a2 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.p1 = MaxPool2D(pool_size=(<span class="number">2</span>,<span class="number">2</span>),strides=<span class="number">2</span>,padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.d1 = Dropout(<span class="number">0.2</span>)</span><br><span class="line">        <span class="comment">#2</span></span><br><span class="line">        self.c3 = Conv2D(filters=<span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b3 = BatchNormalization()</span><br><span class="line">        self.a3 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        self.c4 = Conv2D(filters=<span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b4 = BatchNormalization()</span><br><span class="line">        self.a4 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.p2 = MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>, padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.d2 = Dropout(<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 再重复三次 CBA CBA CBAPD</span></span><br><span class="line">        <span class="comment"># 1</span></span><br><span class="line">        self.c5 = Conv2D(filters=<span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b5 = BatchNormalization()</span><br><span class="line">        self.a5 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        self.c6 = Conv2D(filters=<span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b6 = BatchNormalization()</span><br><span class="line">        self.a6 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        self.c7 = Conv2D(filters=<span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b7 = BatchNormalization()</span><br><span class="line">        self.a7 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.p3 = MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>, padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.d3 = Dropout(<span class="number">0.2</span>)</span><br><span class="line">        <span class="comment"># 2</span></span><br><span class="line">        self.c8 = Conv2D(filters=<span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b8 = BatchNormalization()</span><br><span class="line">        self.a8 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        self.c9 = Conv2D(filters=<span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b9 = BatchNormalization()</span><br><span class="line">        self.a9 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        self.c10 = Conv2D(filters=<span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b10 = BatchNormalization()</span><br><span class="line">        self.a10 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.p4 = MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>, padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.d4 = Dropout(<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3</span></span><br><span class="line">        self.c11 = Conv2D(filters=<span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b11 = BatchNormalization()</span><br><span class="line">        self.a11 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        self.c12 = Conv2D(filters=<span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b12 = BatchNormalization()</span><br><span class="line">        self.a12 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        self.c13 = Conv2D(filters=<span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b13 = BatchNormalization()</span><br><span class="line">        self.a13 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.p5 = MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>, padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.d5 = Dropout(<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 三个全连接层</span></span><br><span class="line">        self.flatten = Flatten()</span><br><span class="line">        self.f1 = Dense(<span class="number">512</span>,activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.d6 = Dropout(<span class="number">0.2</span>)</span><br><span class="line">        self.f2 = Dense(<span class="number">512</span>,activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.d6 = Dropout(<span class="number">0.2</span>)</span><br><span class="line">        self.f3 = Dense(<span class="number">10</span>,activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        <span class="comment"># 两次CBA CBAPD</span></span><br><span class="line">        <span class="comment">#1</span></span><br><span class="line">        x = self.c1(x)</span><br><span class="line">        x = self.b1(x)</span><br><span class="line">        x = self.a1(x)</span><br><span class="line"></span><br><span class="line">        x = self.c2(x)</span><br><span class="line">        x = self.b2(x)</span><br><span class="line">        x = self.a2(x)</span><br><span class="line">        x = self.p1(x)</span><br><span class="line">        x = self.d1(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#2</span></span><br><span class="line">        x = self.c3(x)</span><br><span class="line">        x = self.b3(x)</span><br><span class="line">        x = self.a3(x)</span><br><span class="line"></span><br><span class="line">        x = self.c4(x)</span><br><span class="line">        x = self.b4(x)</span><br><span class="line">        x = self.a4(x)</span><br><span class="line">        x = self.p2(x)</span><br><span class="line">        x = self.d2(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#三次 CBA CBA CBAPD</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 1</span></span><br><span class="line">        x = self.c5(x)</span><br><span class="line">        x = self.b5(x)</span><br><span class="line">        x = self.a5(x)</span><br><span class="line"></span><br><span class="line">        x = self.c6(x)</span><br><span class="line">        x = self.b6(x)</span><br><span class="line">        x = self.a6(x)</span><br><span class="line"></span><br><span class="line">        x = self.c7(x)</span><br><span class="line">        x = self.b7(x)</span><br><span class="line">        x = self.a7(x)</span><br><span class="line">        x = self.p3(x)</span><br><span class="line">        x = self.d3(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2</span></span><br><span class="line">        x = self.c8(x)</span><br><span class="line">        x = self.b8(x)</span><br><span class="line">        x = self.a8(x)</span><br><span class="line"></span><br><span class="line">        x = self.c9(x)</span><br><span class="line">        x = self.b9(x)</span><br><span class="line">        x = self.a9(x)</span><br><span class="line"></span><br><span class="line">        x = self.c10(x)</span><br><span class="line">        x = self.b10(x)</span><br><span class="line">        x = self.a10(x)</span><br><span class="line">        x = self.p4(x)</span><br><span class="line">        x = self.d4(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3</span></span><br><span class="line"></span><br><span class="line">        x = self.c11(x)</span><br><span class="line">        x = self.b11(x)</span><br><span class="line">        x = self.a11(x)</span><br><span class="line"></span><br><span class="line">        x = self.c12(x)</span><br><span class="line">        x = self.b12(x)</span><br><span class="line">        x = self.a12(x)</span><br><span class="line"></span><br><span class="line">        x = self.c13(x)</span><br><span class="line">        x = self.b13(x)</span><br><span class="line">        x = self.a13(x)</span><br><span class="line">        x = self.p5(x)</span><br><span class="line">        x = self.d5(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 提取的特征作为神经网络的输入特征</span></span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        x = self.f1(x)</span><br><span class="line">        x = self.d5(x)</span><br><span class="line">        x = self.f2(x)</span><br><span class="line">        x = self.d6(x)</span><br><span class="line">        y = self.f3(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure></p><h4 id="Inception-Net"><a href="#Inception-Net" class="headerlink" title="Inception Net"></a>Inception Net</h4><p>InceptionNet诞生于2014年。当年ImageNet冠军。Inception引入了Inception结构快。<br>同一层网络使用不同尺寸的卷积核，提升了模型感知力，使用了批标准化，缓解了梯度消失。</p><blockquote><p>Inception结构快如图所示</p></blockquote><p><img src="/images/inter.PNG" alt="a14"></p><p>从图中可以看出，Inception包含四个卷积过程，分成四个不同的卷积核进行卷积操作。</p><blockquote><ol><li>1×1的卷积核</li><li>1×1的卷积核+3×3的卷积核</li><li>1×1的卷积核+5×5的卷积核</li><li>3×3的最大池+1×1的卷积核</li><li>最后将四个部分的输出结果，按照深度方向堆叠在一起，作为一个Inception结构快输出。</li></ol></blockquote><h4 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h4><p>ResNet（何凯明）于2015年提出，是当时的ImageNet竞赛冠军。ResNet提出了层间残差跳连，引入了前方信息，缓解梯度消失，使神经网络层数增加称为可能。</p><blockquote><p>单纯堆叠神经网络层数，会使神经网络模型退化，以致于后面的特征丢失了前边特征的原本模样。</p></blockquote><p>ResNet块的结构如下所示：<br><img src="/images/ResNet块.PNG" alt="ar"></p><p>ResNet的输出值包括两部分组成，一部分是由卷积过程提取出的特征输出F(x)，另一部分是直接由输入X得到的恒等映射X组成。将F(x)和x的对应元素相加得到输出特征H(x)。这样可以缓解神经网络堆叠导致的退化。使得神经网络层数增加称为可能。</p><p>对于X到跳过卷积层直接到输出特征有两种处理方式。</p><p><img src="/images/两种ResNet块.PNG" alt="ar1"></p><blockquote><ol><li>不做任何处理<br>H(x) = F(x) + x<br>由于不做任何处理，所以维度没有改变。</li><li>通过函数W(x)进行处理，其中W是1×1的卷积操作，用于调整X的维度。<br>H(x) = F(x) + W(x)<br>其中通过卷积步长可以改变输出特征图尺寸，通过卷积核的个数可以改变特征图的深度（类似Inception结构，多个卷积核，该变深度）。</li></ol></blockquote><p>ResNet网络结构如下所示：</p><p><img src="/images/ResNet.PNG" alt="ar1"></p><p>实现代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResentBlock</span>(<span class="params">Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,filters,strides=<span class="number">1</span>,residual_path=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(ResentBlock, self).__init__()</span><br><span class="line">        self.filters = filters</span><br><span class="line">        self.strides = strides</span><br><span class="line">        self.residual_path = residual_path</span><br><span class="line"></span><br><span class="line">        self.c1 = Conv2D(filters,(<span class="number">3</span>,<span class="number">3</span>),strides=strides,padding=<span class="string">&#x27;same&#x27;</span>,use_bias=<span class="literal">False</span>)</span><br><span class="line">        self.b1 = BatchNormalization()</span><br><span class="line">        self.a1 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        self.c2 = Conv2D(filters,(<span class="number">3</span>,<span class="number">3</span>),strides=<span class="number">1</span>,padding=<span class="string">&#x27;same&#x27;</span>,use_bias=<span class="literal">False</span>)</span><br><span class="line">        self.b2 = BatchNormalization()</span><br><span class="line"></span><br><span class="line">        <span class="comment">#fesiders_path 为True时候，对输入进行采样，都用1×1的卷积核做卷积操作，保证x能和F(x)维度相同，顺利相加</span></span><br><span class="line">        <span class="keyword">if</span> residual_path:</span><br><span class="line">            self.down_c1 = Conv2D(filters,(<span class="number">1</span>,<span class="number">1</span>),strides=strides,padding=<span class="string">&#x27;same&#x27;</span>,use_bias=<span class="literal">False</span>)</span><br><span class="line">            self.down_b1 = BatchNormalization()</span><br><span class="line">        self.a2 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self,inputs</span>):</span></span><br><span class="line">        residual = inputs <span class="comment"># residual等于输入本身</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#将输入通过卷积层，BN层，激活层计算F(x)</span></span><br><span class="line">        x = self.c1(inputs)</span><br><span class="line">        x = self.b1(x)</span><br><span class="line">        x = self.a1(x)</span><br><span class="line"></span><br><span class="line">        x = self.c2(x)</span><br><span class="line">        y = self.b2(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.residual_path:</span><br><span class="line">            residual = self.down_c1(inputs)</span><br><span class="line">            residual = self.down_b1(residual)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 最后输出是两部分的和，即F(x)+x或F(x)+W(x),然后再过激活函数。</span></span><br><span class="line">        out = self.a2(y + residual)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="comment"># 由一层卷积网络+八个ResNet块组成</span></span><br><span class="line"><span class="comment"># 神经网络由一个全连接层构成</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResNet</span>(<span class="params">Model</span>):</span></span><br><span class="line">    <span class="comment"># block_list表示每个block有几个卷积层</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,block_list,initial_filters=<span class="number">64</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(ResNet, self).__init__()</span><br><span class="line">        self.num_blocks = <span class="built_in">len</span>(block_list)</span><br><span class="line">        self.block_list = block_list</span><br><span class="line">        self.out_filters = initial_filters</span><br><span class="line">        <span class="comment"># 对应图中第一个卷几层</span></span><br><span class="line">        self.c1 = Conv2D(self.out_filters,(<span class="number">3</span>,<span class="number">3</span>),strides=<span class="number">1</span>,padding=<span class="string">&#x27;same&#x27;</span>,use_bias=<span class="literal">False</span>,kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>)</span><br><span class="line">        self.b1 = BatchNormalization()</span><br><span class="line">        self.a1 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.blocks = tf.keras.models.Sequential()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对应图中的八个ResNet块</span></span><br><span class="line">        <span class="comment">#构建ResNet网络结构 4*2 = 8</span></span><br><span class="line">        <span class="keyword">for</span> block_id <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(block_list)):<span class="comment">#第几个resnet block</span></span><br><span class="line">            <span class="keyword">for</span> layer_id <span class="keyword">in</span> <span class="built_in">range</span>(block_list[block_id]):<span class="comment"># 第几个卷层</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> block_id != <span class="number">0</span> <span class="keyword">and</span> layer_id == <span class="number">0</span> : <span class="comment">#对除第一个block以外的每个Block的输入进行采样</span></span><br><span class="line">                    block = ResentBlock(self.out_filters,strides=<span class="number">2</span>,residual_path=<span class="literal">True</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    block = ResentBlock(self.out_filters,residual_path=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">                self.blocks.add(block)  <span class="comment"># 将构建好的blcok加入到renset</span></span><br><span class="line">            self.out_filters *=<span class="number">2</span>  <span class="comment">#下一个block卷积核数是上一个block的两倍</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 平均池</span></span><br><span class="line">        self.p1 = tf.keras.layers.GlobalAveragePooling2D()</span><br><span class="line">        <span class="comment"># 全连接层</span></span><br><span class="line">        self.f1 = tf.keras.layers.Dense(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self,inputs</span>):</span></span><br><span class="line">        x = self.c1(inputs)</span><br><span class="line">        x = self.b1(x)</span><br><span class="line">        x = self.a1(x)</span><br><span class="line">        x = self.blocks(x)</span><br><span class="line">        x = self.p1(x)</span><br><span class="line">        y = self.f1(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">model = ResNet([<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>])</span><br></pre></td></tr></table></figure></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol><li>LeNet<br>通过共享卷积核，减少网络参数</li><li>AlexNet<br> 通过使用relu激活函数，提升训练速度。<br> 使用Dropout缓解过拟合。</li><li>VGGNet<br> 小尺寸卷积核减少参数，网络结构规整，适合并行加速。</li><li>InceptionNet<br> 一层内使用不同尺寸卷积核，提升感知力。使用批标准化，缓解梯度消失。</li><li>ResNet<br> 层间残差跳连，引入前方信息，缓解模型退化，使神经网络层数加深成为可能。</li></ol><blockquote><p>训练优化</p></blockquote><p>&nbsp;&nbsp;&nbsp;&nbsp;一些训练方法和超参数的设定对模型训练结果的影响是相当显著的，如数据增强（对训练集图像进行旋转、偏移、翻转等多种操作，目的是增强训练集的随机性）、学习率策略（一般的策略是在训练过程中逐步减小学习率）、Batch size 的大小设置（每个 batch 包含训练集图片的数量）、模型参数初始化的方式等等。。所以，在神经网络的训练中，除了选择合适的模型以外，如何更好地训练一个模型也是一个非常值得探究的问题。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h3&gt;&lt;p&gt;这里主要介绍卷积神经网络的经典网络，然后通过tensorflow进行实现（以上章的卷积神经网络实现代码为基础，进行实现）。&lt;/p&gt;
&lt;p&gt;统
      
    
    </summary>
    
      <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="TensorFlow2" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/TensorFlow2/"/>
    
    
      <category term="TensorFlow2" scheme="http://example.com/tags/TensorFlow2/"/>
    
      <category term="CNN" scheme="http://example.com/tags/CNN/"/>
    
  </entry>
  
</feed>
